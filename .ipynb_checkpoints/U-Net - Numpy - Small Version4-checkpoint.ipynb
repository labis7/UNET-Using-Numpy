{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load from /home/USER/data/mnist or elsewhere; download if missing.\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "    \"\"\"\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist\n",
    "        path = os.path.join(os.path.expanduser('~'), 'data', 'mnist')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        with gzip.open(path) as f:\n",
    "            # First 16 bytes are magic_number, n_imgs, n_rows, n_cols\n",
    "            pixels = np.frombuffer(f.read(), 'B', offset=16)\n",
    "        return pixels.reshape(-1, 1, 28, 28).astype('float32') / 255\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        with gzip.open(path) as f:\n",
    "            # First 8 bytes are magic_number, n_labels\n",
    "            integer_labels = np.frombuffer(f.read(), 'B', offset=8)\n",
    "        def _onehot(integer_labels):\n",
    "            \"\"\"Return matrix whose rows are onehot encodings of integers.\"\"\"\n",
    "            n_rows = len(integer_labels)\n",
    "            n_cols = integer_labels.max() + 1\n",
    "            onehot = np.zeros((n_rows, n_cols), dtype='uint8')\n",
    "            onehot[np.arange(n_rows), integer_labels] = 1\n",
    "            return onehot\n",
    "\n",
    "        return _onehot(integer_labels)\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(os.path.join(path, files[0]))\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(os.path.join(path, files[1]))\n",
    "    print(\"Test Images  : Loading . . .\")\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    print(\"Test Labels  : Loading . . .\")\n",
    "    test_labels = _labels(os.path.join(path, files[3]))\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return train_images[0:2,:,:,:], train_labels[0:2,:] #, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are ready to gzip!\n",
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Test Images  : Loading . . .\n",
      "Test Labels  : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_label= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "#print(train_images.shape)\n",
    "temp = np.zeros((train_images.shape[0],1,128,128))\n",
    "for i in range(train_images.shape[0]):\n",
    "    #print(cv2.resize(train_images[i,0,:,:], (128,128)).shape)\n",
    "    temp[i,0,:,:]=cv2.resize(train_images[i,0,:,:], (128,128)).reshape(1,1,128,128)\n",
    "#print(train_images.shape)\n",
    "train_images= train_labels = temp\n",
    "print(train_labels.shape) \n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "#plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tone up\n",
    "train_labels[train_labels>0.8] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[1].squeeze(), cmap='Greys_r');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Convolution Architecture - Downsampling/Upsampling  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f,trim ):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    trimf = trim\n",
    "    trimb = trim*5\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trimf #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trimb\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \n",
    "    return filters, bias, f_dc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "\n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(np.multiply(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] , f[z, :, :, :])) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "\n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "    #print(arr.shape)\n",
    "    try:\n",
    "        idx = np.nanargmax(arr)\n",
    "        #print (idx)\n",
    "    except:\n",
    "        idx = 0\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h + a, _w + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "        print(\"Warning: Extra crop needed and handled!(%d --> %d)\" %(dim, img2.shape[1]))\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def NLLLoss(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[1]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] >= logs[:,i,j]):#Gray and above\n",
    "                out[:,i,j] = logs[:,i,j]/targets[:,i,j] \n",
    "            else:\n",
    "                out[:,i,j] = (1 - logs[:,i,j])/(1 - targets[:,i,j]) # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    res = out.sum()/mylen\n",
    "    return -np.log(res), res\n",
    "\n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "def normalize(output):\n",
    "    output[output<-10]=-4\n",
    "    output[output>10] = 4\n",
    "    return output\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch`\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, mode, params_values): \n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    trim= 0.00001\n",
    "    if(mode == 'train'):\n",
    "        filters,bias, f_dc = init_filters(4,16,trim) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "        ##Final 1x1 filter\n",
    "        trimf = trim\n",
    "        trimb = trim*5\n",
    "        out_f = np.random.randn(1,16,1,1)*trimf\n",
    "        out_b = np.random.randn(out_f.shape[0],1)*trimb  \n",
    "        out_fb = [out_f, out_b]\n",
    "        #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "        #image shape: (channels, height, width)\n",
    "    else:\n",
    "        [filters, bias, f_dc, out_fb] = params_values \n",
    "        [out_f, out_b] = out_fb\n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7]= bias \n",
    "    \n",
    "\n",
    "    f1_dc = f_dc[0][0]\n",
    "    b1_dc = f_dc[0][1]\n",
    "    f2_dc = f_dc[1][0]\n",
    "    b2_dc = f_dc[1][1]\n",
    "    f3_dc = f_dc[2][0]\n",
    "    b3_dc = f_dc[2][1]\n",
    "    \n",
    "    \n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]  \n",
    "\n",
    "            \n",
    "\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    prev_cost = 1000\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        \n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        batch = 2\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            print('Batch: {}'.format(int(c/batch +1)))\n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.9  #0.9\n",
    "            beta2= 0.99 #0.99\n",
    "            #lr = learning_rate\n",
    "            batch_size= batch\n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            cost = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            #Special setup for LR\n",
    "            if(e<4):\n",
    "                lr=0.03\n",
    "            ####TODO:Possible solution for unstable future results(from ~1x10-5 --> 0.98 possibility and back again),\n",
    "            #is to reduce dynamically the learning rate(this problem can also be reduced by making trims even smaller)\n",
    "            \n",
    "            if((e < 20)and(mode == 'train')):\n",
    "                \n",
    "                df =  []\n",
    "                db =  []\n",
    "                dfb=  []\n",
    "                for i in filters:\n",
    "                    v1 = np.zeros(i[0].shape)\n",
    "                    v2 = np.zeros(i[1].shape)\n",
    "                    s1 = np.zeros(i[0].shape)\n",
    "                    s2 = np.zeros(i[1].shape)\n",
    "                    v_a = [v1, v2]\n",
    "                    s_a = [s1, s2]\n",
    "                    v_adam.append(v_a)\n",
    "                    s_adam.append(s_a)\n",
    "\n",
    "                    df1_t = np.zeros(i[0].shape)\n",
    "                    df2_t = np.zeros(i[1].shape)\n",
    "                    f_temp = [df1_t, df2_t]\n",
    "                    df.append(f_temp)\n",
    "\n",
    "                for i in bias:\n",
    "                    bv1 = np.zeros(i[0].shape)\n",
    "                    bv2 = np.zeros(i[1].shape)\n",
    "                    bs1 = np.zeros(i[0].shape)\n",
    "                    bs2 = np.zeros(i[1].shape)    \n",
    "                    bv_a = [bv1, bv2]\n",
    "                    bs_a = [bs1, bs2]\n",
    "                    bv_adam.append(bv_a)\n",
    "                    bs_adam.append(bs_a)\n",
    "\n",
    "\n",
    "                    db1_t = np.zeros(i[0].shape)\n",
    "                    db2_t = np.zeros(i[1].shape)\n",
    "                    b_temp = [db1_t, db2_t]\n",
    "                    db.append(b_temp)\n",
    "\n",
    "                for i in f_dc:\n",
    "                    fdc_v1 = np.zeros(i[0].shape)\n",
    "                    bdc_v2 = np.zeros(i[1].shape)\n",
    "                    fdc_s1 = np.zeros(i[0].shape)\n",
    "                    bdc_s2 = np.zeros(i[1].shape)    \n",
    "                    fdc_v_a = [fdc_v1, bdc_v2]\n",
    "                    fdc_s_a = [fdc_s1, bdc_s2]\n",
    "                    fdc_v_adam.append(fdc_v_a)\n",
    "                    fdc_s_adam.append(fdc_s_a)\n",
    "\n",
    "\n",
    "                    df1_t = np.zeros(i[0].shape)\n",
    "                    db1_t = np.zeros(i[1].shape)\n",
    "                    fb_temp = [df1_t, db1_t]\n",
    "                    dfb.append(fb_temp)\n",
    "                    \n",
    "                    \n",
    "                [df1,df2,df3,df4,df5,df6,df7] = df\n",
    "                [db1,db2,db3,db4,db5,db6,db7] = db \n",
    "                [dfb1_dc, dfb2_dc, dfb3_dc]    = dfb\n",
    "\n",
    "\n",
    "                #Final layer 1x1 filter setup\n",
    "\n",
    "                v_out_f = np.zeros(out_f.shape)\n",
    "                s_out_f = np.zeros(out_f.shape)\n",
    "                bv_out_b = np.zeros(out_b.shape)\n",
    "                bs_out_b = np.zeros(out_b.shape)\n",
    "\n",
    "\n",
    "\n",
    "                dout_f = np.zeros(out_f.shape)\n",
    "                dout_b = np.zeros(out_b.shape)\n",
    "\n",
    "            ######################################\n",
    "\n",
    "\n",
    "            #timestamp1 = time.time()\n",
    "\n",
    "          \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print('Image: {}/{}'.format((b+1),batch))\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                params = [f1[0], b1[0]]  \n",
    "                conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "                conv1_1[conv1_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f1[1], b1[1]]\n",
    "                conv1_2 = conv(conv1_1, params, 1)\n",
    "                conv1_2[conv1_2<=0] = 0 #Relu\n",
    "                ##################################### conv1_2: 32x32x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (32-2)/2+1  = 16 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f2[0], b2[0]]  \n",
    "                conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv2_1[conv2_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f2[1], b2[1]]\n",
    "                conv2_2 = conv(conv2_1, params, 1)\n",
    "                conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "                #####################################  16x16x32\n",
    "                \n",
    "                pl2 = maxpool(conv2_2, 2, 2) #   pl1 : (16-2)/2+1  = 8 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 3rd Big Layer ###########\n",
    "                params = [f3[0], b3[0]]  \n",
    "                conv3_1 = conv(pl2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f3[1], b3[1]]\n",
    "                conv3_2 = conv(conv3_1, params, 1)\n",
    "                conv3_2[conv3_2<=0] = 0 #Relu             \n",
    "                #####################################  8x8x64\n",
    "                         \n",
    "                pl3 = maxpool(conv3_2, 2, 2) #   pl1 : (8-2)/2+1  = 4   4x4x64\n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "            \n",
    "                ########### 4th Big Layer ###########\n",
    "                params = [f4[0], b4[0]]  \n",
    "                conv4_1 = conv(pl3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv4_1[conv4_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f4[1], b4[1]]\n",
    "                conv4_2 = conv(conv4_1, params, 1)\n",
    "                conv4_2[conv4_2<=0] = 0 #Relu              \n",
    "                #####################################  4x4x128\n",
    "                \n",
    "                ##################################### \n",
    "                ##################################### \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[0][0], f_dc[0][1]] # deconv filter, deconv bias\n",
    "                dc1, new_in1 = convTransp(conv4_2, params, 1, 0)   #result:   =  8x8x64 , \n",
    "                #Concat dc1 with conv3_2 \n",
    "                c1 = concat(dc1, conv3_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          8x8x128     \n",
    "                params = [f5[0], b5[0]]  \n",
    "                conv5_1 = conv(c1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv5_1[conv5_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f5[1], b5[1]]\n",
    "                conv5_2 = conv(conv5_1, params, 1)\n",
    "                conv5_2[conv5_2<=0] = 0 #Relu   \n",
    "                #####################################    8x8x64\n",
    "                \n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[1][0], f_dc[1][1]] # deconv filter, deconv bias\n",
    "                dc2, new_in2 = convTransp(conv5_2, params, 1, 0)   #result:   =  16x16x32 , \n",
    "                #Concat dc2 with conv1_2 \n",
    "                c2 = concat(dc2, conv2_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          16x16x64     \n",
    "                params = [f6[0], b6[0]]  \n",
    "                conv6_1 = conv(c2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv6_1[conv6_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f6[1], b6[1]]\n",
    "                conv6_2 = conv(conv6_1, params, 1)\n",
    "                conv6_2[conv6_2<=0] = 0 #Relu   \n",
    "                #####################################    16x16x32\n",
    "                \n",
    "                                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[2][0], f_dc[2][1]] # deconv filter, deconv bias\n",
    "                dc3, new_in3 = convTransp(conv6_2, params, 1, 0)   #result:   =  32x32x16 , \n",
    "                #Concat dc2 with conv1_2 \n",
    "                c3 = concat(dc3, conv1_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 3rd Big dc Layer ###########          32x32x32  \n",
    "                params = [f7[0], b7[0]]  \n",
    "                conv7_1 = conv(c3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv7_1[conv7_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f7[1], b7[1]]\n",
    "                conv7_2 = conv(conv7_1, params, 1)\n",
    "                conv7_2[conv7_2<=0] = 0 #Relu   \n",
    "                #####################################    32x32x16\n",
    "                \n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 32x32x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv7_2, params, 1, 0) #output.shape: 32x32x1\n",
    "                \n",
    "                \n",
    "                output = normalize(output)\n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                print(Y_hat[:,0:3,0:3])\n",
    "                #label crop is needed\n",
    "                #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "                cost_,accuracy_ = NLLLoss(Y_hat, Y_t[b])\n",
    "                cost += cost_\n",
    "                accuracy += accuracy_\n",
    "                if(mode == 'predict'):\n",
    "                    print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "                    return\n",
    "                #print(cost/(b+1), prev_cost)\n",
    "                #if(((cost-prev_cost)>0.2)and((e+1) == epochs)):\n",
    "                #    e=e-1\n",
    "                #    print(\"\\n\\n-------------Epoch skipped!--------------\\n\\n\")\n",
    "                #    continue\n",
    "                #prev_cost = cost\n",
    "                \n",
    "                #accuracy += get_accuracy_value(Y_hat, Y_t[b])\n",
    "                #print(accuracy/(b+1))\n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t[b]\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv7_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv7_2, out_f, conv_s) #\n",
    "                #pack data\n",
    "                \n",
    "                \n",
    "                dconv7_2[conv7_2<=0] = 0             \n",
    "                dconv7_1, df7_2, db7_2 = convolutionBackward(dconv7_2, conv7_1, f7[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv7_1[conv7_1<=0] = 0\n",
    "                conc_dconv6, df7_1, db7_1 = convolutionBackward(dconv7_1, c3, f7[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv6, dconv1_2 = crop2half(conc_dconv6)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv6_2, df3_dc, db3_dc = convTranspBackward(dconv6, new_in3, f_dc[2][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv6_2[conv6_2<=0] = 0\n",
    "                dconv6_1, df6_2, db6_2 = convolutionBackward(dconv6_2, conv6_1, f6[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv6_1[conv6_1<=0] = 0\n",
    "                conc_dconv5, df6_1, db6_1 = convolutionBackward(dconv6_1, c2, f6[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv5, dconv2_2 = crop2half(conc_dconv5)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv5_2, df2_dc, db2_dc = convTranspBackward(dconv5, new_in2, f_dc[1][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv5_2[conv5_2<=0] = 0\n",
    "                dconv5_1, df5_2, db5_2 = convolutionBackward(dconv5_2, conv5_1, f5[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv5_1[conv5_1<=0] = 0\n",
    "                conc_dconv4, df5_1, db5_1 = convolutionBackward(dconv5_1, c1, f5[0], conv_s) #\n",
    "                \n",
    "                dconv4, dconv3_2 = crop2half(conc_dconv4)\n",
    "                dconv4_2, df1_dc, db1_dc = convTranspBackward(dconv4, new_in1, f_dc[0][0], conv_s)\n",
    "                \n",
    "                dconv4_2[conv4_2<=0] = 0\n",
    "                dconv4_1, df4_2, db4_2 = convolutionBackward(dconv4_2, conv4_1, f4[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv4_1[conv4_1<=0] = 0\n",
    "                dpl3, df4_1, db4_1 = convolutionBackward(dconv4_1, pl3, f4[0], conv_s) #\n",
    "                \n",
    "                dconv3_2 += maxpoolBackward(dpl3, conv3_2, f=2 , s=2)\n",
    "                \n",
    "                \n",
    "                dconv3_2[conv3_2<=0] = 0\n",
    "                dconv3_1, df3_2, db3_2 = convolutionBackward(dconv3_2, conv3_1, f3[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv3_1[conv3_1<=0] = 0\n",
    "                dpl2, df3_1, db3_1 = convolutionBackward(dconv3_1, pl2, f3[0], conv_s) #\n",
    "                \n",
    "                dconv2_2 += maxpoolBackward(dpl2, conv2_2, f=2 , s=2)\n",
    "                \n",
    "                dconv2_2[conv2_2<=0] = 0\n",
    "                dconv2_1, df2_2, db2_2 = convolutionBackward(dconv2_2, conv2_1, f2[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv2_1[conv2_1<=0] = 0\n",
    "                dpl1, df2_1, db2_1 = convolutionBackward(dconv2_1, pl1, f2[0], conv_s) #\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)\n",
    "                \n",
    "                dconv1_2[conv1_2<=0] = 0\n",
    "                dconv1_1, df1_2, db1_2 = convolutionBackward(dconv1_2, conv1_1, f1[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv1_1[conv1_1<=0] = 0\n",
    "                _, df1_1, db1_1 = convolutionBackward(dconv1_1, X_t[b], f1[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                #[df1,df2,df3,df4,df5,df6,df7] = df\n",
    "                #[db1,db2,db3,db4,db5,df6,df7] = db \n",
    "                #dfb1_dc,dfb2_dc, dfb3_dc     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                df4[0] += df4_1\n",
    "                df4[1] += df4_2\n",
    "                df5[0] += df5_1\n",
    "                df5[1] += df5_2\n",
    "                df6[0] += df6_1\n",
    "                df6[1] += df6_2\n",
    "                df7[0] += df7_1\n",
    "                df7[1] += df7_2\n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                db4[0] += db4_1\n",
    "                db4[1] += db4_2\n",
    "                db5[0] += db5_1\n",
    "                db5[1] += db5_2\n",
    "                db6[0] += db6_1\n",
    "                db6[1] += db6_2\n",
    "                db7[0] += db7_1\n",
    "                db7[1] += db7_2\n",
    "\n",
    "                dfb1_dc[0] += df1_dc\n",
    "                dfb1_dc[1] += db1_dc\n",
    "                dfb2_dc[0] += df2_dc\n",
    "                dfb2_dc[1] += db2_dc\n",
    "                dfb3_dc[0] += df3_dc\n",
    "                dfb3_dc[1] += db3_dc\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "\n",
    "\n",
    "      \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in range(len(filters)):\n",
    "                v_adam[i][0] = beta1*v_adam[i][0] + (1-beta1)*df[i][0]/batch_size #f1\n",
    "                s_adam[i][0] = beta2*s_adam[i][0] + (1-beta2)*(df[i][0]/batch_size)**2 #f1  \n",
    "                filters[i][0] -= lr*v_adam[i][0]/np.sqrt(s_adam[i][0] + 1e-8)\n",
    "                \n",
    "                v_adam[i][1] = beta1*v_adam[i][1] + (1-beta1)*df[i][1]/batch_size #f2\n",
    "                s_adam[i][1] = beta2*s_adam[i][1] + (1-beta2)*(df[i][1]/batch_size)**2  #f2\n",
    "                filters[i][1] -= lr*v_adam[i][1]/np.sqrt(s_adam[i][1] + 1e-8)\n",
    "                \n",
    "            for i in range(len(bias)):\n",
    "                bv_adam[i][0] = beta1*bv_adam[i][0] + (1-beta1)*db[i][0]/batch_size #b1\n",
    "                bs_adam[i][0] = beta2*bs_adam[i][0] + (1-beta2)*(db[i][0]/batch_size)**2  #b1\n",
    "                bias[i][0] -= lr*bv_adam[i][0]/np.sqrt(bs_adam[i][0] + 1e-8)\n",
    "                \n",
    "                bv_adam[i][1] = beta1*bv_adam[i][1] + (1-beta1)*db[i][1]/batch_size #b2\n",
    "                bs_adam[i][1] = beta2*bs_adam[i][1] + (1-beta2)*(db[i][1]/batch_size)**2  #b2\n",
    "                bias[i][1] -= lr*bv_adam[i][1]/np.sqrt(bs_adam[i][1] + 1e-8)\n",
    "            \n",
    "            for i in range(len(f_dc)):\n",
    "                fdc_v_adam[i][0] = beta1*fdc_v_adam[i][0] + (1-beta1)*dfb[i][0]/batch_size #f1\n",
    "                fdc_s_adam[i][0] = beta2*fdc_s_adam[i][0] + (1-beta2)*(dfb[i][0]/batch_size)**2  #f1\n",
    "                f_dc[i][0] -= lr*fdc_v_adam[i][0]/np.sqrt(fdc_s_adam[i][0] + 1e-8)\n",
    "                \n",
    "                fdc_v_adam[i][1] = beta1*fdc_v_adam[i][1] + (1-beta1)*dfb[i][1]/batch_size #b2\n",
    "                fdc_s_adam[i][1] = beta2*fdc_s_adam[i][1] + (1-beta2)*(dfb[i][1]/batch_size)**2  #b2\n",
    "                f_dc[i][1] -= lr*fdc_v_adam[i][1]/np.sqrt(fdc_s_adam[i][1] + 1e-8)    \n",
    "            \n",
    "            v_out_f = beta1*v_out_f + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out_f = beta2*s_out_f + (1 - beta2)*(dout_f/batch_size)**2  #f\n",
    "            out_fb[0] -= lr*v_out_f/np.sqrt(s_out_f + 1e-8)\n",
    "            \n",
    "            bv_out_b = beta1*bv_out_b + (1 - beta1)*dout_b/batch_size #b\n",
    "            bs_out_b = beta2*bs_out_b + (1 - beta2)*(dout_b/batch_size)**2  #b\n",
    "            out_fb[1] -= lr*bv_out_b/np.sqrt(bs_out_b + 1e-8)\n",
    "            \n",
    "            '''\n",
    "                        for i in range(len(filters)):\n",
    "                filters[i][0] -= lr*df[i][0]\n",
    "                bias[i][0] -= lr*db[i][0]\n",
    "            \n",
    "            \n",
    "            f_dc[0][0] -= lr*df1_dc\n",
    "            f_dc[0][1] -= lr*db1_dc\n",
    "            \n",
    "            out_fb[0] -= lr*dout_f\n",
    "            out_fb[1] -= lr*dout_b\n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            #print(\"Batch:{}\".format(c+12))\n",
    "            \n",
    "           \n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            '''\n",
    "            #print(\"Cost : {:.5f}\".format(cost/batch))\n",
    "            #print(\"Accuracy : {:.5f}%\".format((accuracy*100)/batch))\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        \n",
    "        print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "    #pack filters\n",
    "    params_values = [filters, bias, f_dc, out_fb]\n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/2\n"
     ]
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values = train(train_images, train_labels, 10, 0.0001, True, 'train',0) #0.05 stable LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.01798621 0.01798621 0.01798621]\n",
      "  [0.01798621 0.01798621 0.01798621]\n",
      "  [0.01798621 0.01798621 0.01798621]]]\n",
      "Epoch:     1   -   cost: 0.29   -   Accuracy: 75.08%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(train_images[0].reshape(1,1,128,128), train_labels[0].reshape(1,1,128,128), 10, 0.0001, True, 'predict', params_values) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
