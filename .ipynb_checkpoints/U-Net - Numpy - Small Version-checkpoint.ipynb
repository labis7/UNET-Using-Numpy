{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\salt\n",
    "        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    #os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\"\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "    \"\"\"\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/images/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(32, 32)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,32,32).astype('float32')#/255\n",
    "        return pixels[:1,:,:,:]\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        \n",
    "        folder = path + \"/labels/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(32, 32)) for f in os.listdir(folder)]\n",
    "        #onlyfiles = [cv2.resize(image.imread(folder+f),(32, 32)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,32,32).astype('float32') #/255\n",
    "        return pixels[:1,:,:,:]\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(path)\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(path)\n",
    "    \"\"\"\"\n",
    "    print(\"Test Images  : Loading . . .\")\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    print(\"Test Labels  : Loading . . .\")\n",
    "    test_labels = _labels(os.path.join(path, files[3])) \n",
    "    \"\"\"\n",
    "    print(\"Done!\")\n",
    "    return train_images, train_labels #, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 32, 32)\n",
      "(1, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "#train_images=cv2.resize(train_images[0,:,:], (32,32)).reshape(1,1,32,32)\n",
    "print(train_images.shape)\n",
    "#train_labels = train_images\n",
    "print(train_labels.shape) # ONE-HOT !!!\n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "#plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_labels[0].squeeze(), cmap=plt.get_cmap('gray'), vmin=0, vmax=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Convolution Architecture - Downsampling/Upsampling  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f ,trim):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    \n",
    "    trimf = trim\n",
    "    trimb = trim*5\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    \"\"\"\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trimf #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trimb\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \"\"\"\n",
    "    trimbr = trim\n",
    "    locbr = 0\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.normal(loc = locbr, scale = trimbr , size = f1) #np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.normal(loc = locbr, scale = trimbr , size = (f1.shape[0],1)) #np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.normal(loc = locbr, scale = trimbr , size = f2)\n",
    "        b2 = np.random.normal(loc = locbr, scale = trimbr , size = (f2.shape[0],1))\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc =  np.random.normal(loc = locbr, scale = trimbr , size = (n_f,ch_in,2,2))#upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.normal(loc = locbr, scale = trimbr , size = (fdc.shape[0],1))\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.normal(loc = locbr, scale = trimbr , size = (n_f, ch_in, 3, 3))\n",
    "        b1 = np.random.normal(loc = locbr, scale = trimbr , size = (f1.shape[0],1))\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.normal(loc = locbr, scale = trimbr , size = f2)\n",
    "        b2 = np.random.normal(loc = locbr, scale = trimbr , size = (f2.shape[0],1))\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "    return filters, bias, f_dc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "\n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(np.multiply(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] , f[z, :, :, :])) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    #filt =np.rot90(filt, 2)  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!! A T T E N T I O N !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "def convTransp1(image, params, s = 2, pad = 1):\n",
    "    [f, b] = params\n",
    "    n_f, n_c, f_s, _ = f.shape\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2\n",
    "    res = np.zeros((n_f, target_dim, target_dim))\n",
    "    temp =np.zeros((n_c, target_dim, target_dim))\n",
    "    for z in range(n_f):\n",
    "        for _h in range(input_s):      \n",
    "            for _w in range(input_s):\n",
    "                temp[:, _h*s:_h*s+f_s, _w*s:_w*s+f_s] += image[:, _h, _w].reshape(n_c,1,1)*f[z,:,:,:] #bias will be added at the end\n",
    "        res[z] = np.sum(temp , axis = 0) + b[z]\n",
    "    return res, image\n",
    "\n",
    "def convTranspBackward1(dconv_prev, new_in, filt, s = 2):\n",
    "    n_f, n_c, f_s, _ = filt.shape\n",
    "    _, input_s, _ = new_in.shape\n",
    "    #final_dim = (new_in.shape[1] - 2)//2 + 1 \n",
    "    dc_s=dconv_prev.shape[1]\n",
    "    temp = np.zeros((n_c,dc_s,dc_s))\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    dconv_in = np.zeros(new_in.shape)\n",
    "    db = np.zeros((n_f,1))\n",
    "    for z in range(n_f):\n",
    "        for _h in range(input_s):      \n",
    "            for _w in range(input_s): \n",
    "                dfilt[z] += dconv_prev[z, _h*s:_h*s+f_s, _w*s:_w*s+f_s]*new_in[:,_h,_w].reshape(n_c,1,1)\n",
    "                temp[:, _h*s:_h*s+f_s, _w*s:_w*s+f_s] += dconv_prev[z, _h*s:_h*s+f_s, _w*s:_w*s+f_s] * filt[z]\n",
    "                for ch in range(n_c):\n",
    "                    dconv_in[ch, _h, _w] += np.sum(temp[ch, _h*s:_h*s+f_s, _w*s:_w*s+f_s])\n",
    "        db[z] = np.sum(dconv_prev[z])        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "    \n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    [f, b]=params\n",
    "    f = np.rot90(f, 1, (2,3))\n",
    "    params = [f, b]\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    \n",
    "    ### OR just: np.pad(image[:,:,:],2,'constant') # Important, we must loop with respect to the 1st dim\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "    #print(arr.shape)\n",
    "    try:\n",
    "        idx = np.nanargmax(arr)\n",
    "        #print (idx)\n",
    "    except:\n",
    "        idx = 0\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h + a, _w + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "        print(\"Warning: Extra crop needed and handled!(%d --> %d)\" %(dim, img2.shape[1]))\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def Cross_Entropy(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[2]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] >= logs[:,i,j]):#Gray and above\n",
    "                out[:,i,j] = logs[:,i,j]/targets[:,i,j] \n",
    "            else:\n",
    "                out[:,i,j] = (1 - logs[:,i,j])/(1 - targets[:,i,j]) # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    res =out.sum()/mylen\n",
    "    return -np.log(res),res\n",
    "\n",
    "\n",
    "def Dice_Coef(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[2]\n",
    "    #Apply Dice coefficient\n",
    "    numerator = (logs*targets)\n",
    "    denominator = logs + targets\n",
    "    loss = 1 - (2*np.sum(numerator))/(np.sum(denominator))\n",
    "    return loss, np.exp(-loss)\n",
    "                \n",
    "    \n",
    "    \n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "def normalize(output):\n",
    "    output[output<-4]=-4\n",
    "    output[output>4] = 4\n",
    "    return output\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_forward(X, gamma_, beta_, eps=1e-5):\n",
    "    \"\"\"\n",
    "    # extract the dimensions\n",
    "    C, H, W = X.shape\n",
    "    # mini-batch mean\n",
    "    mean = nd.mean(X, axis=(1,2))\n",
    "    # mini-batch variance\n",
    "    variance = nd.mean((X - mean.reshape((C, 1, 1))) ** 2, axis=(1, 2))\n",
    "    # normalize\n",
    "    X_hat = (X - mean.reshape((C, 1, 1))) * 1.0 / nd.sqrt(variance.reshape((C, 1, 1)) + eps)\n",
    "    #if is_training:\n",
    "    # while training, we normalize the data using its mean and variance\n",
    "    X_hat = (X - mean.reshape((C, 1, 1))) * 1.0 / nd.sqrt(variance.reshape((C, 1, 1)) + eps)\n",
    "    #else:\n",
    "    # while testing, we normalize the data using the pre-computed mean and variance\n",
    "    #    X_hat = (X - _BN_MOVING_MEANS[scope_name].reshape((1, C, 1, 1))) * 1.0 \\\n",
    "    #        / nd.sqrt(_BN_MOVING_VARS[scope_name].reshape((1, C, 1, 1)) + eps)\n",
    "    # scale and shift\n",
    "    out = gamma.reshape((C, 1, 1)) * X_hat + beta.reshape((C, 1, 1))\n",
    "    \"\"\"\n",
    "    C_all=X.shape[0]\n",
    "    \n",
    "    if(C_all == 1):\n",
    "        batch = 1\n",
    "    else:\n",
    "        batch =2\n",
    "    C= batch\n",
    "    \n",
    "    mu_= np.zeros(C_all//batch)\n",
    "    var_=np.zeros(C_all//batch)\n",
    "    xmu_=np.zeros((C_all,X.shape[1],X.shape[2]))\n",
    "    sqrtvar_= np.zeros(C_all//batch)\n",
    "    ivar_= np.zeros(C_all//batch)\n",
    "    xhat_= np.zeros((C_all,X.shape[1],X.shape[2]))\n",
    "    #gammax_= np.zeros((C_all,1,1))\n",
    "    out_= np.zeros((C_all,X.shape[1],X.shape[2]))\n",
    "    \n",
    "    \n",
    "    for i in range(0, C_all, batch):\n",
    "        \n",
    "        x = X[i:i+C,:,:]\n",
    "        gamma = gamma_[i//batch]  #there is a gamma,beta for each batch of channels\n",
    "        beta = beta_[i//batch]\n",
    "        ###################################################################\n",
    "        _, H, W = x.shape  #WAS N, D\n",
    "\n",
    "        #step1: calculate mean\n",
    "        mu = np.mean(x) #scalar\n",
    "        #print(mu)\n",
    "\n",
    "        #step2: subtract mean vector of every trainings example\n",
    "        xmu = (x - mu)\n",
    "        #step3: following the lower branch - calculation denominator\n",
    "        #step4: calculate variance\n",
    "        var = np.mean(xmu ** 2)\n",
    "\n",
    "        #step5: add eps for numerical stability, then sqrt\n",
    "        sqrtvar = np.sqrt(var + eps)\n",
    "\n",
    "        #step6: invert sqrtwar\n",
    "        ivar = 1./sqrtvar\n",
    "\n",
    "        #step7: execute normalization\n",
    "        xhat = xmu * ivar\n",
    "\n",
    "        #step8: Nor the two transformation steps\n",
    "        gammax = gamma * xhat\n",
    "        #gamma,beta : scalar\n",
    "        #step9\n",
    "        out = gammax + beta\n",
    "        \n",
    "        xhat_[i:i+C,:,:]   =xhat   #.copy()\n",
    "        #gamma_[i:i+2,:,:]  =gamma\n",
    "        xmu_[i:i+C,:,:]    =xmu\n",
    "        ivar_[i//batch]  =ivar\n",
    "        sqrtvar_[i//batch]=sqrtvar\n",
    "        var_[i//batch]   =var\n",
    "        out_[i:i+C,:,:]   =out\n",
    "    #store intermediate\n",
    "    cache = (xhat_,gamma_,xmu_,ivar_,sqrtvar_,var_,eps)\n",
    "    return out_, cache\n",
    "\n",
    "def batchnorm_backward(dout_, cache):\n",
    "\n",
    "    #unfold the variables stored in cache\n",
    "    xhat_,gamma_,xmu_,ivar_,sqrtvar_,var_,eps = cache\n",
    "\n",
    "    \n",
    "    C_all =dout_.shape[0]\n",
    "    if(C_all == 1):\n",
    "        C = 1\n",
    "    else:\n",
    "        C = 2\n",
    "    \n",
    "    batch = C\n",
    "    dx_    = np.zeros((C_all,dout_.shape[1],dout_.shape[2]))\n",
    "    dgamma_= np.zeros(C_all//batch)\n",
    "    dbeta_ = np.zeros(C_all//batch)\n",
    "    \n",
    "    for i in range(0, C_all, batch): \n",
    "        dout = dout_[i:i+C,:,:]\n",
    "        xhat   =xhat_[i:i+C,:,:]\n",
    "        gamma  = gamma_[i//batch]\n",
    "        xmu    =xmu_[i:i+C,:,:]\n",
    "        ivar   =ivar_[i//batch]\n",
    "        sqrtvar=sqrtvar_[i//batch]\n",
    "        var    =var_[i//batch]\n",
    "        \n",
    "        #get the dimensions of the input/output\n",
    "        _, H, W = dout.shape #N,D = dout.shape\n",
    "\n",
    "        #step9\n",
    "        dbeta = np.sum(dout)\n",
    "        dgammax = dout #not necessary, but more understandable\n",
    "\n",
    "        #step8\n",
    "        dgamma = np.sum(dgammax*xhat)\n",
    "        dxhat = dgammax * gamma\n",
    "\n",
    "        #step7\n",
    "        divar = np.sum(dxhat*xmu)\n",
    "        dxmu1 = dxhat * ivar\n",
    "\n",
    "        #step6\n",
    "        dsqrtvar = -1. /(sqrtvar**2) * divar\n",
    "\n",
    "        #step5\n",
    "        dvar = 0.5 * 1. /np.sqrt(var+eps) * dsqrtvar\n",
    "\n",
    "        #step4\n",
    "        dsq = 1./(batch*H*W) * np.ones((C,H,W)) * dvar  #1./C\n",
    "\n",
    "        #step3\n",
    "        dxmu2 = 2 * xmu * dsq\n",
    "\n",
    "        #step2\n",
    "        dx1 = (dxmu1 + dxmu2)\n",
    "        dmu = -1 * np.sum(dxmu1+dxmu2)\n",
    "\n",
    "        #step1\n",
    "        dx2 =  1./(batch*H*W) *np.ones((C,H,W)) * dmu #1. /C *\n",
    "\n",
    "        #step0\n",
    "        dx = dx1 + dx2\n",
    "        dx_[i:i+C,:,:]    = dx\n",
    "        dgamma_[i//batch]= dgamma\n",
    "        dbeta_[i//batch] = dbeta\n",
    "\n",
    "    return dx_, dgamma_.reshape(C_all//batch,1), dbeta_.reshape(C_all//batch,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch`\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, verbose=True, callback=None):\n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    trim = 0.01\n",
    "    filters,bias, f_dc = init_filters(2,16,trim) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "    if(dropout>0): \n",
    "        print('Dropout Enabled! Value:{}'.format(dropout))\n",
    "    \n",
    "    ##Final 1x1 filter\n",
    "    trimf = trim\n",
    "    trimb = trim\n",
    "    out_f = np.random.randn(1,16,1,1)*trimf\n",
    "    out_b = np.random.randn(out_f.shape[0],1)*trimb  \n",
    "    out_fb = [out_f, out_b]\n",
    "    #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "\n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]  \n",
    "\n",
    "            \n",
    "\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "    [f1,f2,f3] = filters\n",
    "    [b1,b2,b3]= bias \n",
    "    \n",
    "    f1_dc = f_dc[0][0]\n",
    "    b1_dc = f_dc[0][1]\n",
    "    \n",
    "    \n",
    "    trimbr = 0.01\n",
    "    locbr = 0\n",
    "    norm_batch = 2\n",
    "    \n",
    "    t_1,_ = b1\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma1_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) #MAKE IT FLOAT\n",
    "    beta1_1  = np.random.normal( scale = trimbr , size = gb_size)\n",
    "    gamma1_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta1_2  = np.random.normal( scale = trimbr , size = gb_size)\n",
    "    tempg_1 = [gamma1_1,gamma1_2]\n",
    "    tempb_1 = [beta1_1,beta1_2]\n",
    "    \n",
    "    t_1,_ = b2\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma2_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta2_1  = np.random.normal( scale = trimbr , size = gb_size)\n",
    "    gamma2_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta2_2  = np.random.normal(scale = trimbr , size = gb_size)  \n",
    "    tempg_2 = [gamma2_1,gamma2_2]\n",
    "    tempb_2 = [beta2_1,beta2_2]\n",
    "    \n",
    "    t_1,_ = b3\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma3_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta3_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma3_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta3_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_3 = [gamma3_1,gamma3_2]\n",
    "    tempb_3 = [beta3_1,beta3_2]\n",
    "    \n",
    "    ga =[tempg_1,tempg_2,tempg_3]\n",
    "    be =[tempb_1,tempb_2,tempb_3]\n",
    "    \n",
    "    gamma_out = np.random.normal(loc = locbr, scale = trimbr , size = (out_b.shape[0]//norm_batch,1))\n",
    "    beta_out =   np.random.normal(scale = trimbr , size = (out_b.shape[0]//norm_batch,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    t_1,_ = b1\n",
    "    gb_size =t_1.shape[0]\n",
    "    gamma1_1 = np.random.randn(gb_size)*trimbr\n",
    "    beta1_1  = np.random.randn(gb_size)*trimbr\n",
    "    gamma1_2 =  np.random.randn(gb_size)*trimbr\n",
    "    beta1_2  =np.random.randn(gb_size)*trimbr\n",
    "    \n",
    "    t_1,_ = b2\n",
    "    gb_size =t_1.shape[0]\n",
    "    gamma2_1 = np.random.randn(gb_size)*trimbr\n",
    "    beta2_1  = np.random.randn(gb_size)*trimbr\n",
    "    gamma2_2 = np.random.randn(gb_size)*trimbr\n",
    "    beta2_2  = np.random.randn(gb_size)*trimbr  \n",
    "    \n",
    "    t_1,_ = b3\n",
    "    gb_size =t_1.shape[0]\n",
    "    gamma3_1 = np.random.randn(gb_size)*trimbr \n",
    "    beta3_1  = np.random.randn(gb_size)*trimbr\n",
    "    gamma3_2 = np.random.randn(gb_size)*trimbr \n",
    "    beta3_2  = np.random.randn(gb_size)*trimbr\n",
    "    \n",
    "    gamma_out = np.random.randn(out_b.shape[0])*trimbr\n",
    "    beta_out =  np.random.randn(out_b.shape[0])*trimbr\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        batch = 1\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            print('Batch: {}'.format(int(c/batch +1)))\n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.9\n",
    "            beta2= 0.99\n",
    "            lr = learning_rate\n",
    "            batch_size= batch\n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            cost = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            \n",
    "            gv_adam =[]\n",
    "            gs_adam =[]\n",
    "            dgamma =[]\n",
    "            for i in ga:\n",
    "                gv1 = np.zeros(i[0].shape)\n",
    "                gv2 = np.zeros(i[1].shape)\n",
    "                gs1 = np.zeros(i[0].shape)\n",
    "                gs2 = np.zeros(i[1].shape)\n",
    "                gv_a = [gv1, gv2]\n",
    "                gs_a = [gs1, gs2]\n",
    "                gv_adam.append(gv_a)\n",
    "                gs_adam.append(gs_a)\n",
    "                \n",
    "            bev_adam =[]\n",
    "            bes_adam =[]\n",
    "            dbeta =[]\n",
    "            for i in ga:\n",
    "                bev1 = np.zeros(i[0].shape)\n",
    "                bev2 = np.zeros(i[1].shape)\n",
    "                bes1 = np.zeros(i[0].shape)\n",
    "                bes2 = np.zeros(i[1].shape)\n",
    "                bev_a = [bev1, bev2]\n",
    "                bes_a = [bes1, bes2]\n",
    "                bev_adam.append(bev_a)\n",
    "                bes_adam.append(bes_a)\n",
    "            \n",
    "            gamma_out_v_adam = np.zeros(gamma_out.shape) \n",
    "            gamma_out_s_adam = np.zeros(gamma_out.shape)\n",
    "            beta_out_v_adam = np.zeros(beta_out.shape) \n",
    "            beta_out_s_adam = np.zeros(beta_out.shape)\n",
    "            \n",
    "            df =  []\n",
    "            db =  []\n",
    "            dfb=  []\n",
    "            for i in filters:\n",
    "                v1 = np.zeros(i[0].shape)\n",
    "                v2 = np.zeros(i[1].shape)\n",
    "                s1 = np.zeros(i[0].shape)\n",
    "                s2 = np.zeros(i[1].shape)\n",
    "                v_a = [v1, v2]\n",
    "                s_a = [s1, s2]\n",
    "                v_adam.append(v_a)\n",
    "                s_adam.append(s_a)\n",
    "\n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                df2_t = np.zeros(i[1].shape)\n",
    "                f_temp = [df1_t, df2_t]\n",
    "                df.append(f_temp)\n",
    "\n",
    "            for i in bias:\n",
    "                bv1 = np.zeros(i[0].shape)\n",
    "                bv2 = np.zeros(i[1].shape)\n",
    "                bs1 = np.zeros(i[0].shape)\n",
    "                bs2 = np.zeros(i[1].shape)    \n",
    "                bv_a = [bv1, bv2]\n",
    "                bs_a = [bs1, bs2]\n",
    "                bv_adam.append(bv_a)\n",
    "                bs_adam.append(bs_a)\n",
    "\n",
    "\n",
    "                db1_t = np.zeros(i[0].shape)\n",
    "                db2_t = np.zeros(i[1].shape)\n",
    "                b_temp = [db1_t, db2_t]\n",
    "                db.append(b_temp)\n",
    "\n",
    "            for i in f_dc:\n",
    "                fdc_v1 = np.zeros(i[0].shape)\n",
    "                bdc_v2 = np.zeros(i[1].shape)\n",
    "                fdc_s1 = np.zeros(i[0].shape)\n",
    "                bdc_s2 = np.zeros(i[1].shape)    \n",
    "                fdc_v_a = [fdc_v1, bdc_v2]\n",
    "                fdc_s_a = [fdc_s1, bdc_s2]\n",
    "                fdc_v_adam.append(fdc_v_a)\n",
    "                fdc_s_adam.append(fdc_s_a)\n",
    "\n",
    "\n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                db1_t = np.zeros(i[1].shape)\n",
    "                fb_temp = [df1_t, db1_t]\n",
    "                dfb.append(fb_temp)\n",
    "\n",
    "\n",
    "            #Final layer 1x1 filter setup\n",
    "\n",
    "            v_out_f = np.zeros(out_f.shape)\n",
    "            s_out_f = np.zeros(out_f.shape)\n",
    "            bv_out_b = np.zeros(out_b.shape)\n",
    "            bs_out_b = np.zeros(out_b.shape)\n",
    "\n",
    "\n",
    "\n",
    "            dout_f = np.zeros(out_f.shape)\n",
    "            dout_b = np.zeros(out_b.shape)\n",
    "\n",
    "            ######################################\n",
    "\n",
    "\n",
    "            #timestamp1 = time.time()\n",
    "\n",
    "\n",
    "            [df1,df2,df3] = df\n",
    "            [db1,db2,db3] = db \n",
    "            dfb1_dc     = dfb\n",
    "            \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print('Image: {}/{}'.format((b+1),batch))\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                params = [f1[0], b1[0]]  \n",
    "                conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "                conv1_1, batchcache1_1 = batchnorm_forward(conv1_1, ga[0][0], be[0][0])                \n",
    "                conv1_1[conv1_1<=0] = 0 #Relu \n",
    "                params = [f1[1], b1[1]]\n",
    "                conv1_2 = conv(conv1_1, params, 1)\n",
    "                conv1_2, batchcache1_2 = batchnorm_forward(conv1_2, ga[0][1], be[0][1])\n",
    "                conv1_2[conv1_2<=0] = 0 #Relu\n",
    "                \n",
    "                ##################################### conv1_2: 32x32x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (32-2)/2+1  = 16 \n",
    "                if(dropout>0):\n",
    "                    ## Dropout ##\n",
    "                    d = (np.random.rand(pl1.shape[0],pl1.shape[1],pl1.shape[2])<dropout)\n",
    "                    d = d*1 #Bool --> int(0s and 1s)\n",
    "                    pl1 = d*pl1\n",
    "                    #############\n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f2[0], b2[0]]  \n",
    "                conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv2_1, batchcache2_1 = batchnorm_forward(conv2_1, ga[1][0], be[1][0])\n",
    "                conv2_1[conv2_1<=0] = 0 #Relu\n",
    "                params = [f2[1], b2[1]]\n",
    "                conv2_2 = conv(conv2_1, params, 1)\n",
    "                conv2_2, batchcache2_2 = batchnorm_forward(conv2_2, ga[1][1], be[1][1])\n",
    "                conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "                #####################################  16x16x32\n",
    "\n",
    "          \n",
    "                ##################################### \n",
    "                ##################################### \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[0][0], f_dc[0][1]] # deconv filter, deconv bias\n",
    "                dc1, new_in1 = convTransp(conv2_2, params, 1, 0)   #result:   =  32x32x16 , # conv5_2 requires NO crop\n",
    "                #Concat dc6 with conv2_2 so we get 32 channels (32x32x32)\n",
    "                c1 = concat(dc1, conv1_2) # 1st one is the right one size  \n",
    "                if(dropout>0):\n",
    "                    ## Dropout ##\n",
    "                    d = (np.random.rand(c1.shape[0],c1.shape[1],c1.shape[2])<dropout)\n",
    "                    d = d*1 #Bool --> int(0s and 1s)\n",
    "                    c1 = d*c1\n",
    "                    #############\n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          32x32x32     \n",
    "                params = [f3[0], b3[0]]  \n",
    "                conv3_1 = conv(c1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv3_1, batchcache3_1 = batchnorm_forward(conv3_1, ga[2][0], be[2][0])\n",
    "                conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f3[1], b3[1]]\n",
    "                conv3_2 = conv(conv3_1, params, 1)\n",
    "                conv3_2, batchcache3_2 = batchnorm_forward(conv3_2, ga[2][1], be[2][1])\n",
    "                conv3_2[conv3_2<=0] = 0 #Relu   \n",
    "                #####################################    32x32x16\n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 128x128x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv3_2, params, 1, 0) #output.shape: 32x32x1\n",
    "                #output, batchcache_out = batchnorm_forward(output, gamma_out, beta_out)\n",
    "             \n",
    "                \n",
    "                #output = normalize(output)\n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                #print(Y_hat[:,20:25,19:23])\n",
    "                #label crop is needed\n",
    "                #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                plt.imshow(Y_hat.squeeze(), cmap='Greys_r');#cmap=plt.get_cmap('gray'), vmin=0, vmax=1);\n",
    "                cost_,accuracy_ =  Dice_Coef(Y_hat, Y_t[b])#NLLLoss(Y_hat, Y_t[b])\n",
    "                cost += cost_\n",
    "                accuracy += accuracy_\n",
    "                #if (accuracy>0.88):\n",
    "                #    return Y_hat\n",
    "                #print(accuracy/(b+1))\n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t[b]\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                #dZ_prev, dgamma_out, dbeta_out = batchnorm_backward(dZ_prev, batchcache_out)\n",
    "                dconv3_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv3_2, out_f, conv_s) #\n",
    "                #pack data\n",
    "                \n",
    "\n",
    "                dconv3_2[conv3_2<=0] = 0  \n",
    "                dconv3_2, dgamma3_2, dbeta3_2 = batchnorm_backward(dconv3_2, batchcache3_2)\n",
    "                dconv3_1, df3_2, db3_2 = convolutionBackward(dconv3_2, conv3_1, f3[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv3_1[conv3_1<=0] = 0\n",
    "                dconv3_1, dgamma3_1, dbeta3_1 = batchnorm_backward(dconv3_1, batchcache3_1)\n",
    "                conc_dconv3, df3_1, db3_1 = convolutionBackward(dconv3_1, c1, f3[0], conv_s) #\n",
    "                dga3= [dgamma3_1,dgamma3_2]\n",
    "                dbe3= [dbeta3_1,dbeta3_2]\n",
    "                \n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv3, dconv1_2 = crop2half(conc_dconv3)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv2_2, df1_dc, db1_dc = convTranspBackward(dconv3, new_in1, f_dc[0][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv2_2[conv2_2<=0] = 0\n",
    "                dconv2_2, dgamma2_2, dbeta2_2 = batchnorm_backward(dconv2_2, batchcache2_2)\n",
    "                dconv2_1, df2_2, db2_2 = convolutionBackward(dconv2_2, conv2_1, f2[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv2_1[conv2_1<=0] = 0\n",
    "                dconv2_1, dgamma2_1, dbeta2_1 = batchnorm_backward(dconv2_1, batchcache2_1)\n",
    "                dpl1, df2_1, db2_1 = convolutionBackward(dconv2_1, pl1, f2[0], conv_s) #\n",
    "                dga2= [dgamma2_1,dgamma2_2]\n",
    "                dbe2= [dbeta2_1,dbeta2_2]\n",
    "                \n",
    "                mmx =maxpoolBackward(dpl1, conv1_2, f=2 , s=2)\n",
    "                #print(dconv1_2[:5,5:9,13:16])\n",
    "                #print(mmx[:5,5:9,13:16])\n",
    "                #print(dconv1_2[:,20:25,19:23])\n",
    "                #print(np.mean(mmx, axis = (1,2)))\n",
    "                #print(np.mean(dconv1_2, axis = (1,2)))\n",
    "                #group normalization with fixed gprint(np.mean(conv3_2, axis = (1,2)))\n",
    "                \n",
    "                dconv1_2 += mmx\n",
    "                \n",
    "                dconv1_2[conv1_2<=0] = 0\n",
    "                dconv1_2, dgamma1_2, dbeta1_2 = batchnorm_backward(dconv1_2, batchcache1_2)\n",
    "                dconv1_1, df1_2, db1_2 = convolutionBackward(dconv1_2, conv1_1, f1[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv1_1[conv1_1<=0] = 0\n",
    "                dconv1_1, dgamma1_1, dbeta1_1 = batchnorm_backward(dconv1_1, batchcache1_1)\n",
    "                _, df1_1, db1_1 = convolutionBackward(dconv1_1, X_t[b], f1[0], conv_s) #\n",
    "                dga1= [dgamma1_1,dgamma1_2]\n",
    "                dbe1= [dbeta1_1,dbeta1_2]\n",
    "                \n",
    "                dgamma = [dga1, dga2,dga3]\n",
    "                dbeta = [dbe1, dbe2,dbe3]\n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                [df1,df2,df3] = df\n",
    "                [db1,db2,db3] = db \n",
    "                dfb1_dc     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                \n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                \n",
    "\n",
    "                #dfb1_dc[0] += df1_dc\n",
    "                #dfb1_dc[1] += db1_dc\n",
    "\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "\n",
    "\n",
    "      \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in range(len(ga)):\n",
    "                mytrim = 10\n",
    "                ga[i][0] -= lr*mytrim*dgamma[i][0]\n",
    "                ga[i][1] -= lr*mytrim*dgamma[i][1]\n",
    "                \n",
    "                be[i][0] -= lr*mytrim*dbeta[i][0]\n",
    "                be[i][1] -= lr*mytrim*dbeta[i][1]\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            for i in range(len(ga)):\n",
    "                gv_adam[i][0] = beta1*gv_adam[i][0] + (1-beta1)*dgamma[i][0]/batch_size \n",
    "                gs_adam[i][0] = beta2*gs_adam[i][0] + (1-beta2)*(dgamma[i][0]/batch_size)**2 \n",
    "                ga[i][0] -= lr*gv_adam[i][0]/np.sqrt(gs_adam[i][0] + 1e-7)\n",
    "                gv_adam[i][1] = beta1*gv_adam[i][1] + (1-beta1)*dgamma[i][1]/batch_size \n",
    "                gs_adam[i][1] = beta2*gs_adam[i][1] + (1-beta2)*(dgamma[i][1]/batch_size)**2 \n",
    "                ga[i][1] -= lr*gv_adam[i][1]/np.sqrt(gs_adam[i][1] + 1e-7)\n",
    "                \n",
    "                \n",
    "                bev_adam[i][0] = beta1*bev_adam[i][0] + (1-beta1)*dbeta[i][0]/batch_size\n",
    "                bes_adam[i][0] = beta2*bes_adam[i][0] + (1-beta2)*(dbeta[i][0]/batch_size)**2 \n",
    "                be[i][0] -= lr*bev_adam[i][0]/np.sqrt(bes_adam[i][0] + 1e-7)\n",
    "                bev_adam[i][1] = beta1*bev_adam[i][1] + (1-beta1)*dbeta[i][1]/batch_size\n",
    "                bes_adam[i][1] = beta2*bes_adam[i][1] + (1-beta2)*(dbeta[i][1]/batch_size)**2\n",
    "                be[i][1] -= lr*bev_adam[i][1]/np.sqrt(bes_adam[i][1] + 1e-7)\n",
    "            \n",
    "            #gamma_out_v_adam =  beta1*gamma_out_v_adam + (1-beta1)*dgamma_out/batch_size\n",
    "            #gamma_out_s_adam =  beta1*gamma_out_s_adam + (1-beta1)*(dgamma_out/batch_size)**2\n",
    "            #gamma_out -=        lr*gamma_out_v_adam/np.sqrt(gamma_out_s_adam + 1e-7)\n",
    "            #beta_out_v_adam  = beta1*beta_out_v_adam + (1-beta1)*dbeta_out/batch_size\n",
    "            #beta_out_s_adam  = beta1*beta_out_s_adam + (1-beta1)*(dbeta_out/batch_size)**2\n",
    "            #beta_out =         lr*beta_out_v_adam/np.sqrt(beta_out_s_adam + 1e-7)\n",
    "            \"\"\"\n",
    " \n",
    "            for i in range(len(filters)):\n",
    "                v_adam[i][0] = beta1*v_adam[i][0] + (1-beta1)*df[i][0]/batch_size #f1\n",
    "                s_adam[i][0] = beta2*s_adam[i][0] + (1-beta2)*(df[i][0]/batch_size)**2 #f1\n",
    "                filters[i][0] -= lr*v_adam[i][0]/np.sqrt(s_adam[i][0] + 1e-7)\n",
    "                \n",
    "                v_adam[i][1] = beta1*v_adam[i][1] + (1-beta1)*df[i][1]/batch_size #f2\n",
    "                s_adam[i][1] = beta2*s_adam[i][1] + (1-beta2)*(df[i][1]/batch_size)**2  #f2\n",
    "                filters[i][1] -= lr*v_adam[i][1]/np.sqrt(s_adam[i][1] + 1e-7)\n",
    "                \n",
    "            for i in range(len(bias)):\n",
    "                bv_adam[i][0] = beta1*bv_adam[i][0] + (1-beta1)*db[i][0]/batch_size #b1\n",
    "                bs_adam[i][0] = beta2*bs_adam[i][0] + (1-beta2)*(db[i][0]/batch_size)**2  #b1\n",
    "                bias[i][0] -= lr*bv_adam[i][0]/np.sqrt(bs_adam[i][0] + 1e-7)\n",
    "                \n",
    "                bv_adam[i][1] = beta1*bv_adam[i][1] + (1-beta1)*db[i][1]/batch_size #b2\n",
    "                bs_adam[i][1] = beta2*bs_adam[i][1] + (1-beta2)*(db[i][1]/batch_size)**2  #b2\n",
    "                bias[i][1] -= lr*bv_adam[i][1]/np.sqrt(bs_adam[i][1] + 1e-7)\n",
    "            \n",
    "            for i in range(len(f_dc)):\n",
    "                fdc_v_adam[i][0] = beta1*fdc_v_adam[i][0] + (1-beta1)*dfb[i][0]/batch_size #f1\n",
    "                fdc_s_adam[i][0] = beta2*fdc_s_adam[i][0] + (1-beta2)*(dfb[i][0]/batch_size)**2  #f1\n",
    "                f_dc[i][0] -= lr*fdc_v_adam[i][0]/np.sqrt(fdc_s_adam[i][0] + 1e-7)\n",
    "                \n",
    "                fdc_v_adam[i][1] = beta1*fdc_v_adam[i][1] + (1-beta1)*dfb[i][1]/batch_size #b2\n",
    "                fdc_s_adam[i][1] = beta2*fdc_s_adam[i][1] + (1-beta2)*(dfb[i][1]/batch_size)**2  #b2\n",
    "                f_dc[i][1] -= lr*fdc_v_adam[i][1]/np.sqrt(fdc_s_adam[i][1] + 1e-7)    \n",
    "            \n",
    "            v_out_f = beta1*v_out_f + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out_f = beta2*s_out_f + (1 - beta2)*(dout_f/batch_size)**2  #f\n",
    "            out_fb[0] -= lr*v_out_f/np.sqrt(s_out_f + 1e-7)\n",
    "            \n",
    "            bv_out_b = beta1*bv_out_b + (1 - beta1)*dout_b/batch_size #b\n",
    "            bs_out_b = beta2*bs_out_b + (1 - beta2)*(dout_b/batch_size)**2  #b\n",
    "            out_fb[1] -= lr*bv_out_b/np.sqrt(bs_out_b + 1e-7)\n",
    "            \n",
    "            '''\n",
    "            lr = learning_rate\n",
    "            gamma1_1 -= lr*dgamma1_1\n",
    "            beta1_1  -= lr*dbeta1_1\n",
    "            gamma1_2 -= lr*dgamma1_2\n",
    "            beta1_2  -= lr*dbeta1_2\n",
    "\n",
    "            gamma2_1 -= lr*dgamma2_1\n",
    "            beta2_1  -= lr*dbeta2_1\n",
    "            gamma2_2 -= lr*dgamma2_2\n",
    "            beta2_2  -= lr*dbeta2_2\n",
    "\n",
    "            gamma3_1 -= lr*dgamma3_1\n",
    "            beta3_1  -= lr*dbeta3_1\n",
    "            gamma3_2 -= lr*dgamma3_2\n",
    "            beta3_2  -= lr*dbeta3_2\n",
    "\n",
    "            gamma_out-= lr*dgamma_out\n",
    "            beta_out  -= lr*dbeta_out\n",
    "            \n",
    "                        for i in range(len(filters)):\n",
    "                filters[i][0] -= lr*df[i][0]\n",
    "                bias[i][0] -= lr*db[i][0]\n",
    "            \n",
    "            \n",
    "            f_dc[0][0] -= lr*df1_dc\n",
    "            f_dc[0][1] -= lr*db1_dc\n",
    "            \n",
    "            out_fb[0] -= lr*dout_f\n",
    "            out_fb[1] -= lr*dout_b\n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            #print(\"Batch:{}\".format(c+12))\n",
    "            \n",
    "           \n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            '''\n",
    "            #print(\"Cost : {:.5f}\".format(cost/batch))\n",
    "            #print(\"Accuracy : {:.5f}%\".format((accuracy*100)/batch))\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        if(verbose):\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "    #pack filters\n",
    "    params_values = [filters, bias, f_dc, out_fb]\n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     1   -   cost: 0.75   -   Accuracy: 47.04%\n",
      "Epoch: {2}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     2   -   cost: 0.75   -   Accuracy: 47.01%\n",
      "Epoch: {3}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     3   -   cost: 0.76   -   Accuracy: 46.88%\n",
      "Epoch: {4}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     4   -   cost: 0.76   -   Accuracy: 46.54%\n",
      "Epoch: {5}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     5   -   cost: 0.78   -   Accuracy: 45.88%\n",
      "Epoch: {6}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     6   -   cost: 0.70   -   Accuracy: 49.76%\n",
      "Epoch: {7}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     7   -   cost: 0.84   -   Accuracy: 43.36%\n",
      "Epoch: {8}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     8   -   cost: 0.76   -   Accuracy: 46.70%\n",
      "Epoch: {9}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     9   -   cost: 0.73   -   Accuracy: 48.32%\n",
      "Epoch: {10}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    10   -   cost: 0.69   -   Accuracy: 50.25%\n",
      "Epoch: {11}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    11   -   cost: 0.62   -   Accuracy: 53.85%\n",
      "Epoch: {12}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    12   -   cost: 0.59   -   Accuracy: 55.56%\n",
      "Epoch: {13}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    13   -   cost: 0.69   -   Accuracy: 50.18%\n",
      "Epoch: {14}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    14   -   cost: 0.58   -   Accuracy: 55.89%\n",
      "Epoch: {15}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    15   -   cost: 0.62   -   Accuracy: 53.66%\n",
      "Epoch: {16}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    16   -   cost: 0.80   -   Accuracy: 44.95%\n",
      "Epoch: {17}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    17   -   cost: 0.57   -   Accuracy: 56.57%\n",
      "Epoch: {18}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    18   -   cost: 0.56   -   Accuracy: 57.38%\n",
      "Epoch: {19}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    19   -   cost: 0.55   -   Accuracy: 57.43%\n",
      "Epoch: {20}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    20   -   cost: 0.57   -   Accuracy: 56.80%\n",
      "Epoch: {21}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    21   -   cost: 0.57   -   Accuracy: 56.31%\n",
      "Epoch: {22}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    22   -   cost: 0.59   -   Accuracy: 55.47%\n",
      "Epoch: {23}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    23   -   cost: 0.59   -   Accuracy: 55.67%\n",
      "Epoch: {24}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    24   -   cost: 0.81   -   Accuracy: 44.71%\n",
      "Epoch: {25}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    25   -   cost: 0.55   -   Accuracy: 57.60%\n",
      "Epoch: {26}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    26   -   cost: 0.56   -   Accuracy: 57.07%\n",
      "Epoch: {27}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    27   -   cost: 0.60   -   Accuracy: 54.92%\n",
      "Epoch: {28}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    28   -   cost: 0.54   -   Accuracy: 58.22%\n",
      "Epoch: {29}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    29   -   cost: 0.57   -   Accuracy: 56.79%\n",
      "Epoch: {30}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    30   -   cost: 0.55   -   Accuracy: 57.94%\n",
      "Epoch: {31}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    31   -   cost: 0.57   -   Accuracy: 56.48%\n",
      "Epoch: {32}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    32   -   cost: 0.52   -   Accuracy: 59.38%\n",
      "Epoch: {33}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    33   -   cost: 0.55   -   Accuracy: 57.72%\n",
      "Epoch: {34}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    34   -   cost: 0.49   -   Accuracy: 60.97%\n",
      "Epoch: {35}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    35   -   cost: 0.45   -   Accuracy: 63.72%\n",
      "Epoch: {36}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    36   -   cost: 0.49   -   Accuracy: 61.05%\n",
      "Epoch: {37}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    37   -   cost: 0.40   -   Accuracy: 67.32%\n",
      "Epoch: {38}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    38   -   cost: 0.61   -   Accuracy: 54.55%\n",
      "Epoch: {39}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    39   -   cost: 0.49   -   Accuracy: 61.21%\n",
      "Epoch: {40}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    40   -   cost: 0.47   -   Accuracy: 62.40%\n",
      "Epoch: {41}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    41   -   cost: 0.46   -   Accuracy: 63.06%\n",
      "Epoch: {42}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    42   -   cost: 0.43   -   Accuracy: 64.90%\n",
      "Epoch: {43}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    43   -   cost: 0.42   -   Accuracy: 65.58%\n",
      "Epoch: {44}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    44   -   cost: 0.40   -   Accuracy: 67.16%\n",
      "Epoch: {45}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    45   -   cost: 0.49   -   Accuracy: 61.23%\n",
      "Epoch: {46}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    46   -   cost: 0.39   -   Accuracy: 67.79%\n",
      "Epoch: {47}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    47   -   cost: 0.39   -   Accuracy: 67.58%\n",
      "Epoch: {48}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    48   -   cost: 0.37   -   Accuracy: 69.30%\n",
      "Epoch: {49}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    49   -   cost: 0.51   -   Accuracy: 60.27%\n",
      "Epoch: {50}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    50   -   cost: 0.40   -   Accuracy: 67.00%\n",
      "Epoch: {51}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    51   -   cost: 0.51   -   Accuracy: 59.78%\n",
      "Epoch: {52}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    52   -   cost: 0.62   -   Accuracy: 53.84%\n",
      "Epoch: {53}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    53   -   cost: 0.49   -   Accuracy: 61.08%\n",
      "Epoch: {54}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    54   -   cost: 0.45   -   Accuracy: 63.63%\n",
      "Epoch: {55}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    55   -   cost: 0.37   -   Accuracy: 69.20%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values = train(train_images, train_labels, 55, 0.02, 0) #0.05 stable LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b5f86b8d50cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'squeeze'"
     ]
    }
   ],
   "source": [
    "plt.imshow(params_values.squeeze(), cmap=plt.get_cmap('gray'), vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-d1175c062e01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m###### Prediction ######\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mYt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtemp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "###### Prediction ######\n",
    "Yt = test_labels.T\n",
    "temp1 = []\n",
    "for i in range(Yt.shape[1]):\n",
    "        for j in range(Yt.shape[0]):\n",
    "            if(Yt[j][i]==1):\n",
    "                temp1.append(j)\n",
    "Yt=np.array(temp1)\n",
    "Y_test_hat, _ = full_forward_propagation(np.transpose(test_images), params_values, NN_ARCHITECTURE)#multiple?!\n",
    "\n",
    "Yht = np.array(Y_test_hat.T)\n",
    "#x_log=np.log( np.exp(Yh) / np.sum(np.exp(Yh), axis = 1) )  #(60000,10) , we need to add along columns so we get sum of 1 on every example-row\n",
    "num = np.exp(Yht)\n",
    "den = np.sum(np.exp(Yht), axis = 1)\n",
    "for i in range(Yht.shape[0]): #60000\n",
    "                #for j in range(Yh.shape[1]): #10\n",
    "                Yht[i][:] = np.log(num[i][:] / den[i])  \n",
    "\n",
    "#cost = get_cost_value(Yht, Yt)\n",
    "\n",
    "#cost_history.append(cost)\n",
    "accuracy = get_accuracy_value(Y_test_hat, test_labels.T)\n",
    "#accuracy_history.append(accuracy)\n",
    "print(\"Accuracy: {:.5f}%\".format( accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
