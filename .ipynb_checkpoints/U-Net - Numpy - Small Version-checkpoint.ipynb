{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load from /home/USER/data/mnist or elsewhere; download if missing.\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "    \"\"\"\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist\n",
    "        path = os.path.join(os.path.expanduser('~'), 'data', 'mnist')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        with gzip.open(path) as f:\n",
    "            # First 16 bytes are magic_number, n_imgs, n_rows, n_cols\n",
    "            pixels = np.frombuffer(f.read(), 'B', offset=16)\n",
    "        return pixels.reshape(-1, 1, 28, 28).astype('float32') / 255\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        with gzip.open(path) as f:\n",
    "            # First 8 bytes are magic_number, n_labels\n",
    "            integer_labels = np.frombuffer(f.read(), 'B', offset=8)\n",
    "        def _onehot(integer_labels):\n",
    "            \"\"\"Return matrix whose rows are onehot encodings of integers.\"\"\"\n",
    "            n_rows = len(integer_labels)\n",
    "            n_cols = integer_labels.max() + 1\n",
    "            onehot = np.zeros((n_rows, n_cols), dtype='uint8')\n",
    "            onehot[np.arange(n_rows), integer_labels] = 1\n",
    "            return onehot\n",
    "\n",
    "        return _onehot(integer_labels)\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(os.path.join(path, files[0]))\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(os.path.join(path, files[1]))\n",
    "    print(\"Test Images  : Loading . . .\")\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    print(\"Test Labels  : Loading . . .\")\n",
    "    test_labels = _labels(os.path.join(path, files[3]))\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return train_images[0,:,:,:], train_labels[0,:] #, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are ready to gzip!\n",
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Test Images  : Loading . . .\n",
      "Test Labels  : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labelsa= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 32, 32)\n",
      "(1, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "train_images=cv2.resize(train_images[0,:,:], (32,32)).reshape(1,1,32,32)\n",
    "print(train_images.shape)\n",
    "train_labels = train_images\n",
    "print(train_labels.shape) # ONE-HOT !!!\n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "#plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_labels[0].squeeze(), cmap='Greys_r');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Convolution Architecture - Downsampling/Upsampling  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f ):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    trim = 0.1\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trim\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trim\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trim #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trim\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trim\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trim\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \n",
    "    return filters, bias, f_dc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "\n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(np.multiply(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] , f[z, :, :, :])) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "\n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "    #print(arr.shape)\n",
    "    try:\n",
    "        idx = np.nanargmax(arr)\n",
    "        #print (idx)\n",
    "    except:\n",
    "        idx = 0\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h + a, _w + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "        print(\"Warning: Extra crop needed and handled!(%d --> %d)\" %(dim, img2.shape[1]))\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def NLLLoss(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[1]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] == 1):\n",
    "                out[:,i,j] = logs[:,i,j] #in that case the propab. is correct with targen being the 1\n",
    "            else:\n",
    "                out[:,i,j] = 1 - logs[:,i,j] # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    return -np.log(out.sum()/mylen)\n",
    "\n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "def normalize(output):\n",
    "    output[output<-10]=-4\n",
    "    output[output>10] = 4\n",
    "    return output\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch`\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, verbose=True, callback=None):\n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    filters,bias, f_dc = init_filters(2,16) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "    ##Final 1x1 filter\n",
    "    trim = 0.1\n",
    "    out_f = np.random.randn(1,16,1,1)*trim\n",
    "    out_b = np.random.randn(out_f.shape[0],1)*trim  \n",
    "    out_fb = [out_f, out_b]\n",
    "    #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "\n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]  \n",
    "\n",
    "            \n",
    "\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "    [f1,f2,f3] = filters\n",
    "    [b1,b2,b3]= bias \n",
    "    \n",
    "    f1_dc = f_dc[0][0]\n",
    "    b1_dc = f_dc[0][1]\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        batch = 1\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            print('Batch: {}'.format(int(c/batch +1)))\n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.95\n",
    "            beta2= 0.99\n",
    "            lr = learning_rate\n",
    "            batch_size= batch\n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            cost = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            df =  []\n",
    "            db =  []\n",
    "            dfb=  []\n",
    "            for i in filters:\n",
    "                v1 = np.zeros(i[0].shape)\n",
    "                v2 = np.zeros(i[1].shape)\n",
    "                s1 = np.zeros(i[0].shape)\n",
    "                s2 = np.zeros(i[1].shape)\n",
    "                v_a = [v1, v2]\n",
    "                s_a = [s1, s2]\n",
    "                v_adam.append(v_a)\n",
    "                s_adam.append(s_a)\n",
    "                \n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                df2_t = np.zeros(i[1].shape)\n",
    "                f_temp = [df1_t, df2_t]\n",
    "                df.append(f_temp)\n",
    "                \n",
    "            for i in bias:\n",
    "                bv1 = np.zeros(i[0].shape)\n",
    "                bv2 = np.zeros(i[1].shape)\n",
    "                bs1 = np.zeros(i[0].shape)\n",
    "                bs2 = np.zeros(i[1].shape)    \n",
    "                bv_a = [bv1, bv2]\n",
    "                bs_a = [bs1, bs2]\n",
    "                bv_adam.append(bv_a)\n",
    "                bs_adam.append(bs_a)\n",
    "                \n",
    "                \n",
    "                db1_t = np.zeros(i[0].shape)\n",
    "                db2_t = np.zeros(i[1].shape)\n",
    "                b_temp = [db1_t, db2_t]\n",
    "                db.append(b_temp)\n",
    "            \n",
    "            for i in f_dc:\n",
    "                fdc_v1 = np.zeros(i[0].shape)\n",
    "                bdc_v2 = np.zeros(i[1].shape)\n",
    "                fdc_s1 = np.zeros(i[0].shape)\n",
    "                bdc_s2 = np.zeros(i[1].shape)    \n",
    "                fdc_v_a = [fdc_v1, bdc_v2]\n",
    "                fdc_s_a = [fdc_s1, bdc_s2]\n",
    "                fdc_v_adam.append(fdc_v_a)\n",
    "                fdc_s_adam.append(fdc_s_a)\n",
    "                \n",
    "                \n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                db1_t = np.zeros(i[1].shape)\n",
    "                fb_temp = [df1_t, db1_t]\n",
    "                dfb.append(fb_temp)\n",
    "            \n",
    "            \n",
    "            #Final layer 1x1 filter setup\n",
    "\n",
    "            v_out_f = np.zeros(out_f.shape)\n",
    "            s_out_f = np.zeros(out_f.shape)\n",
    "            bv_out_b = np.zeros(out_b.shape)\n",
    "            bs_out_b = np.zeros(out_b.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            dout_f = np.zeros(out_f.shape)\n",
    "            dout_b = np.zeros(out_b.shape)\n",
    "            \n",
    "            ######################################\n",
    "            \n",
    "            \n",
    "            #timestamp1 = time.time()\n",
    "            \n",
    "            \n",
    "            [df1,df2,df3] = df\n",
    "            [db1,db2,db3] = db \n",
    "            dfb1_dc     = dfb\n",
    "            \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print('Image: {}/{}'.format((b+1),batch))\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                params = [f1[0], b1[0]]  \n",
    "                conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "                conv1_1[conv1_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f1[1], b1[1]]\n",
    "                conv1_2 = conv(conv1_1, params, 1)\n",
    "                conv1_2[conv1_2<=0] = 0 #Relu\n",
    "                ##################################### conv1_2: 32x32x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (32-2)/2+1  = 16 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f2[0], b2[0]]  \n",
    "                conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv2_1[conv2_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f2[1], b2[1]]\n",
    "                conv2_2 = conv(conv2_1, params, 1)\n",
    "                conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "                #####################################  16x16x32\n",
    "\n",
    "          \n",
    "                ##################################### \n",
    "                ##################################### \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f1_dc, b1_dc] # deconv filter, deconv bias\n",
    "                dc1, new_in1 = convTransp(conv2_2, params, 1, 0)   #result:   =  32x32x16 , # conv5_2 requires NO crop\n",
    "                #Concat dc6 with conv2_2 so we get 32 channels (32x32x32)\n",
    "                c1 = concat(dc1, conv1_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          32x32x32     \n",
    "                params = [f3[0], b3[0]]  \n",
    "                conv3_1 = conv(c1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f3[1], b3[1]]\n",
    "                conv3_2 = conv(conv3_1, params, 1)\n",
    "                conv3_2[conv3_2<=0] = 0 #Relu   \n",
    "                #####################################    32x32x16\n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 128x128x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv3_2, params, 1, 0) #output.shape: 32x32x1\n",
    "                \n",
    "                \n",
    "                output = normalize(output)\n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                print(Y_hat[:,0:10,0:10])\n",
    "                #label crop is needed\n",
    "                #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "                cost += NLLLoss(Y_hat, Y_t[b])\n",
    "                print(cost/(b+1))\n",
    "                \n",
    "                accuracy += get_accuracy_value(Y_hat, Y_t[b])\n",
    "                print(accuracy/(b+1))\n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t[b]\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv3_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv3_2, out_f, conv_s) #\n",
    "                #pack data\n",
    "                \n",
    "                \n",
    "                dconv3_2[conv3_2<=0] = 0             \n",
    "                dconv3_1, df3_2, db3_2 = convolutionBackward(dconv3_2, conv3_1, f3[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv3_1[conv3_1<=0] = 0\n",
    "                conc_dconv3, df3_1, db3_1 = convolutionBackward(dconv3_1, c1, f3[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv3, dconv1_2 = crop2half(conc_dconv3)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv2_2, df1_dc, db1_dc = convTranspBackward(dconv3, new_in1, f1_dc, conv_s)\n",
    "                #pack data\n",
    "                print(df1_dc.shape)\n",
    "                dconv2_2[conv2_2<=0] = 0\n",
    "                dconv2_1, df2_2, db2_2 = convolutionBackward(dconv2_2, conv2_1, f2[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv2_1[conv2_1<=0] = 0\n",
    "                dpl1, df2_1, db2_1 = convolutionBackward(dconv2_1, pl1, f2[0], conv_s) #\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)\n",
    "                \n",
    "                dconv1_2[conv1_2<=0] = 0\n",
    "                dconv1_1, df1_2, db1_2 = convolutionBackward(dconv1_2, conv1_1, f1[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv1_1[conv1_1<=0] = 0\n",
    "                _, df1_1, db1_1 = convolutionBackward(dconv1_1, X_t[b], f1[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                [df1,df2,df3] = df\n",
    "                [db1,db2,db3] = db \n",
    "                dfb1_dc     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                \n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                \n",
    "\n",
    "                #dfb1_dc[0] += df1_dc\n",
    "                #dfb1_dc[1] += db1_dc\n",
    "\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "            \n",
    "            for i in range(len(filters)):\n",
    "                filters[i][0] -= lr*df[i][0]\n",
    "                bias[i][0] -= lr*db[i][0]\n",
    "            \n",
    "            \n",
    "            f1_dc -= lr*df1_dc\n",
    "            b1_dc -= lr*db1_dc\n",
    "            \n",
    "            out_fb[0] -= lr*dout_f\n",
    "            out_fb[1] -= lr*dout_b\n",
    "            \n",
    "            \n",
    "            ''''\n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in range(len(filters)):\n",
    "                v_adam[i][0] = beta1*v_adam[i][0] + (1-beta1)*df[i][0]/batch_size #f1\n",
    "                s_adam[i][0] = beta2*s_adam[i][0] + (1-beta2)*(df[i][0]/batch_size)**2 #f1\n",
    "                filters[i][0] -= lr*v_adam[i][0]/np.sqrt(s_adam[i][0] + 1e-7)\n",
    "                \n",
    "                v_adam[i][1] = beta1*v_adam[i][1] + (1-beta1)*df[i][1]/batch_size #f2\n",
    "                s_adam[i][1] = beta2*s_adam[i][1] + (1-beta2)*(df[i][1]/batch_size)**2  #f2\n",
    "                filters[i][1] -= lr*v_adam[i][1]/np.sqrt(s_adam[i][1] + 1e-7)\n",
    "                \n",
    "            for i in range(len(bias)):\n",
    "                bv_adam[i][0] = beta1*bv_adam[i][0] + (1-beta1)*db[i][0]/batch_size #b1\n",
    "                bs_adam[i][0] = beta2*bs_adam[i][0] + (1-beta2)*(db[i][0]/batch_size)**2  #b1\n",
    "                bias[i][0] -= lr*bv_adam[i][0]/np.sqrt(bs_adam[i][0] + 1e-7)\n",
    "                \n",
    "                bv_adam[i][1] = beta1*bv_adam[i][1] + (1-beta1)*db[i][1]/batch_size #b2\n",
    "                bs_adam[i][1] = beta2*bs_adam[i][1] + (1-beta2)*(db[i][1]/batch_size)**2  #b2\n",
    "                bias[i][1] -= lr*bv_adam[i][1]/np.sqrt(bs_adam[i][1] + 1e-7)\n",
    "            \n",
    "            for i in range(len(f_dc)):\n",
    "                fdc_v_adam[i][0] = beta1*fdc_v_adam[i][0] + (1-beta1)*dfb[i][0]/batch_size #f1\n",
    "                fdc_s_adam[i][0] = beta2*fdc_s_adam[i][0] + (1-beta2)*(dfb[i][0]/batch_size)**2  #f1\n",
    "                f_dc[i][0] -= lr*fdc_v_adam[i][0]/np.sqrt(fdc_s_adam[i][0] + 1e-7)\n",
    "                \n",
    "                fdc_v_adam[i][1] = beta1*fdc_v_adam[i][1] + (1-beta1)*dfb[i][1]/batch_size #b2\n",
    "                fdc_s_adam[i][1] = beta2*fdc_s_adam[i][1] + (1-beta2)*(dfb[i][1]/batch_size)**2  #b2\n",
    "                f_dc[i][1] -= lr*fdc_v_adam[i][1]/np.sqrt(fdc_s_adam[i][1] + 1e-7)    \n",
    "            \n",
    "            v_out_f = beta1*v_out_f + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out_f = beta2*s_out_f + (1 - beta2)*(dout_f/batch_size)**2  #f\n",
    "            out_fb[0] -= lr*v_out_f/np.sqrt(s_out_f + 1e-7)\n",
    "            \n",
    "            bv_out_b = beta1*bv_out_b + (1 - beta1)*dout_b/batch_size #b\n",
    "            bs_out_b = beta2*bs_out_b + (1 - beta2)*(dout_b/batch_size)**2  #b\n",
    "            out_fb[1] -= lr*bv_out_b/np.sqrt(bs_out_b + 1e-7)\n",
    "            \n",
    "            \n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            #print(\"Batch:{}\".format(c+12))\n",
    "            \n",
    "           \n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            \n",
    "            '''\n",
    "            print(\"Cost : {:.5f}\".format(cost/batch))\n",
    "            print(\"Accuracy : {:.5f}%\".format((accuracy*100)/batch))\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        if(verbose):\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "    #pack filters\n",
    "    params_values = [filters, bias, f_dc, out_fb]\n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-0.07775749 -0.1066585  -0.06605893 -0.09449999 -0.06491498\n",
      "   -0.09481492 -0.06552419 -0.09523343 -0.06559605 -0.09563384]\n",
      "  [-0.12323185 -0.12328048 -0.11372834 -0.12374038 -0.12721235\n",
      "   -0.12357531 -0.12981665 -0.12292693 -0.12876747 -0.12196497]\n",
      "  [-0.07549355 -0.1130056  -0.0692747  -0.10488375 -0.0598653\n",
      "   -0.10927761 -0.06145422 -0.10636175 -0.05952099 -0.10358019]\n",
      "  [-0.10723804 -0.12971968 -0.10679929 -0.13167982 -0.1148181\n",
      "   -0.1295632  -0.11266393 -0.12801655 -0.11175136 -0.12455576]\n",
      "  [-0.06551568 -0.1130157  -0.06621747 -0.1092292  -0.05560736\n",
      "   -0.11790657 -0.04872033 -0.11083083 -0.03802658 -0.10903341]\n",
      "  [-0.10365681 -0.12590887 -0.10706877 -0.12631276 -0.11669362\n",
      "   -0.11984261 -0.1119536  -0.1225172  -0.11909414 -0.12436768]\n",
      "  [-0.06332726 -0.11129874 -0.06536465 -0.10940882 -0.05622898\n",
      "   -0.12194343 -0.05880229 -0.12013691 -0.05974122 -0.12315309]\n",
      "  [-0.10340776 -0.12666261 -0.10619106 -0.12087533 -0.10689136\n",
      "   -0.12079947 -0.11520135 -0.1386396  -0.1341638  -0.1484054 ]\n",
      "  [-0.0629451  -0.11003511 -0.06378543 -0.09993364 -0.05675381\n",
      "   -0.10865736 -0.05683994 -0.11038706 -0.06828085 -0.12703738]\n",
      "  [-0.10330616 -0.12702611 -0.10478484 -0.12099394 -0.10687864\n",
      "   -0.1169192  -0.10597513 -0.10581916 -0.13335722 -0.12663239]]]\n",
      "0.6410682158629963\n",
      "0.7060546875\n",
      "(16, 32, 2, 2)\n",
      "Cost : 0.64107\n",
      "Accuracy : 70.60547%\n",
      "Epoch:     1   -   cost: 0.64   -   Accuracy: 70.61%\n",
      "Epoch: {2}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-0.24138264 -0.26479754 -0.23207914 -0.26236056 -0.23144067\n",
      "   -0.26230354 -0.23212414 -0.26328297 -0.23227082 -0.26363546]\n",
      "  [-0.29929402 -0.31106498 -0.31832029 -0.31407956 -0.32989843\n",
      "   -0.31070181 -0.33215746 -0.31096229 -0.33173118 -0.3107214 ]\n",
      "  [-0.25790143 -0.3069221  -0.27416756 -0.30290137 -0.26723026\n",
      "   -0.30907536 -0.26922989 -0.30617471 -0.26683717 -0.30157287]\n",
      "  [-0.3079548  -0.33354152 -0.3303882  -0.34658224 -0.33704303\n",
      "   -0.34301415 -0.3365369  -0.34340594 -0.33529996 -0.34138374]\n",
      "  [-0.25160621 -0.30623771 -0.27466089 -0.30721716 -0.26563262\n",
      "   -0.31461539 -0.25749549 -0.30893112 -0.24440759 -0.30669325]\n",
      "  [-0.30362261 -0.32859746 -0.32841314 -0.34380235 -0.33658769\n",
      "   -0.33476237 -0.33622976 -0.3396122  -0.34487793 -0.34660867]\n",
      "  [-0.249698   -0.30423485 -0.27297646 -0.30707972 -0.2636325\n",
      "   -0.32021027 -0.26338068 -0.31666319 -0.25223442 -0.31936412]\n",
      "  [-0.30213464 -0.3293692  -0.32913875 -0.34060637 -0.33210226\n",
      "   -0.3361777  -0.33657573 -0.34887382 -0.35619344 -0.37660543]\n",
      "  [-0.2494638  -0.30334307 -0.27183432 -0.30379616 -0.26720192\n",
      "   -0.31338773 -0.26609571 -0.31973372 -0.27182894 -0.34047832]\n",
      "  [-0.30185439 -0.32964904 -0.32715723 -0.34265779 -0.3311206\n",
      "   -0.33419911 -0.33548806 -0.32647429 -0.36524543 -0.35784706]]]\n",
      "0.5446231539664186\n",
      "0.7060546875\n",
      "(16, 32, 2, 2)\n",
      "Cost : 0.54462\n",
      "Accuracy : 70.60547%\n",
      "Epoch:     2   -   cost: 0.54   -   Accuracy: 70.61%\n",
      "Epoch: {3}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-0.38261871 -0.40449966 -0.37452301 -0.40435894 -0.37668732\n",
      "   -0.40430004 -0.37589933 -0.40539044 -0.37567098 -0.40562736]\n",
      "  [-0.46431181 -0.4834735  -0.49962354 -0.48944476 -0.50998495\n",
      "   -0.48531013 -0.51143329 -0.48512595 -0.51092185 -0.48498666]\n",
      "  [-0.42682506 -0.48873957 -0.45884458 -0.4895399  -0.46896306\n",
      "   -0.49658643 -0.47049139 -0.4926289  -0.4688285  -0.48699159]\n",
      "  [-0.49074468 -0.51592419 -0.52837684 -0.53808002 -0.53536058\n",
      "   -0.53366123 -0.53493618 -0.53277852 -0.53491497 -0.53331388]\n",
      "  [-0.42145511 -0.49413658 -0.45843507 -0.49490638 -0.46578596\n",
      "   -0.50201382 -0.45430013 -0.4968887  -0.44043527 -0.49485232]\n",
      "  [-0.48344959 -0.5104861  -0.52566912 -0.53429564 -0.53124967\n",
      "   -0.52659636 -0.53248492 -0.53124251 -0.54116765 -0.53985218]\n",
      "  [-0.41813506 -0.49098583 -0.45763232 -0.49497585 -0.46281801\n",
      "   -0.50875711 -0.45713721 -0.50277379 -0.4426961  -0.50361   ]\n",
      "  [-0.48163565 -0.51161404 -0.52543859 -0.53153308 -0.52744963\n",
      "   -0.52725186 -0.53335544 -0.53789619 -0.5593739  -0.57604455]\n",
      "  [-0.417783   -0.4898845  -0.4554564  -0.49137919 -0.46673219\n",
      "   -0.50419511 -0.45755729 -0.51143942 -0.47207817 -0.53930131]\n",
      "  [-0.48127596 -0.51161477 -0.52342519 -0.53194065 -0.5260606\n",
      "   -0.52409656 -0.52956479 -0.51834002 -0.56767202 -0.5656247 ]]]\n",
      "0.4667239743181624\n",
      "0.7060546875\n",
      "(16, 32, 2, 2)\n",
      "Cost : 0.46672\n",
      "Accuracy : 70.60547%\n",
      "Epoch:     3   -   cost: 0.47   -   Accuracy: 70.61%\n",
      "Epoch: {4}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-0.50471773 -0.53319217 -0.50370417 -0.53508116 -0.50621381\n",
      "   -0.53527516 -0.50512631 -0.53659252 -0.50500205 -0.53668747]\n",
      "  [-0.62348672 -0.65589612 -0.67262599 -0.65957491 -0.68405951\n",
      "   -0.65451013 -0.68548152 -0.65371175 -0.68498698 -0.65342771]\n",
      "  [-0.59082654 -0.67608996 -0.66029661 -0.67413333 -0.66730552\n",
      "   -0.68807623 -0.66974855 -0.68345786 -0.66702636 -0.68114886]\n",
      "  [-0.66134186 -0.69463059 -0.72090243 -0.72625204 -0.72839317\n",
      "   -0.72123514 -0.72742911 -0.72006437 -0.72664157 -0.72109357]\n",
      "  [-0.5892896  -0.68100892 -0.65912511 -0.68677501 -0.66752561\n",
      "   -0.69595584 -0.65571475 -0.68687519 -0.64039329 -0.68496154]\n",
      "  [-0.65379555 -0.68955654 -0.71739092 -0.72206786 -0.72138333\n",
      "   -0.71287439 -0.72212304 -0.71685699 -0.73049139 -0.72596602]\n",
      "  [-0.5844554  -0.67529056 -0.6580712  -0.68580541 -0.66230773\n",
      "   -0.69292429 -0.65854632 -0.68240035 -0.6397051  -0.68071514]\n",
      "  [-0.65154596 -0.69131977 -0.7175211  -0.71857381 -0.71939835\n",
      "   -0.71478488 -0.72395166 -0.7319249  -0.75322304 -0.77011381]\n",
      "  [-0.58422546 -0.67478759 -0.655461   -0.67528311 -0.66457714\n",
      "   -0.68652775 -0.65779818 -0.69618721 -0.67420008 -0.74307809]\n",
      "  [-0.65102408 -0.69152321 -0.71522207 -0.71986264 -0.71865561\n",
      "   -0.71110512 -0.72219123 -0.7032498  -0.76370041 -0.77623164]]]\n",
      "0.3994181006610971\n",
      "0.7060546875\n",
      "(16, 32, 2, 2)\n",
      "Cost : 0.39942\n",
      "Accuracy : 70.60547%\n",
      "Epoch:     4   -   cost: 0.40   -   Accuracy: 70.61%\n",
      "Epoch: {5}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-0.61542365 -0.6484238  -0.61995026 -0.65234729 -0.62308299\n",
      "   -0.65283045 -0.621717   -0.65407166 -0.62150326 -0.65421576]\n",
      "  [-0.76617026 -0.81631691 -0.83438793 -0.83196941 -0.84596586\n",
      "   -0.81310066 -0.84683889 -0.81168465 -0.84601373 -0.81117338]\n",
      "  [-0.74297066 -0.85261774 -0.84497921 -0.8602634  -0.84666678\n",
      "   -0.8767449  -0.85015746 -0.87278497 -0.84796594 -0.86983112]\n",
      "  [-0.81705181 -0.88091744 -0.90332283 -0.90690739 -0.91219348\n",
      "   -0.90121538 -0.91034028 -0.89993007 -0.90849107 -0.90009628]\n",
      "  [-0.74218928 -0.85421494 -0.84644767 -0.87287643 -0.85195971\n",
      "   -0.88350626 -0.84360598 -0.87316225 -0.8279426  -0.87203631]\n",
      "  [-0.80920121 -0.87507398 -0.89889366 -0.90198588 -0.90289642\n",
      "   -0.89174506 -0.90319415 -0.89378834 -0.90901554 -0.90298896]\n",
      "  [-0.73694845 -0.84760998 -0.84520063 -0.87115073 -0.84620707\n",
      "   -0.88083676 -0.84515914 -0.86427289 -0.82587126 -0.8577905 ]\n",
      "  [-0.80632089 -0.87572703 -0.89937167 -0.89709167 -0.90228762\n",
      "   -0.89441413 -0.9045535  -0.92680932 -0.93311519 -0.9599247 ]\n",
      "  [-0.73671772 -0.84729026 -0.84347499 -0.86179351 -0.84979861\n",
      "   -0.87408558 -0.84383808 -0.88076675 -0.85833999 -0.92966906]\n",
      "  [-0.80566069 -0.87574786 -0.89696414 -0.89759921 -0.90080308\n",
      "   -0.88849964 -0.90339316 -0.89128093 -0.94489757 -0.97426075]]]\n",
      "0.34376605521068865\n",
      "0.7060546875\n",
      "(16, 32, 2, 2)\n",
      "Cost : 0.34377\n",
      "Accuracy : 70.60547%\n",
      "Epoch:     5   -   cost: 0.34   -   Accuracy: 70.61%\n",
      "Epoch: {6}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-0.71120242 -0.74788663 -0.72088086 -0.75356549 -0.72411047\n",
      "   -0.75440873 -0.7228109  -0.7556325  -0.72244127 -0.75590496]\n",
      "  [-0.88877934 -0.95763529 -0.97664908 -0.98422238 -0.98953741\n",
      "   -0.95497542 -0.99038769 -0.95430619 -0.98928587 -0.95357496]\n",
      "  [-0.86955756 -1.00524855 -1.00291037 -1.02328623 -1.00320979\n",
      "   -1.04056835 -1.00677178 -1.0366629  -1.00412144 -1.03294009]\n",
      "  [-0.9524425  -1.04667548 -1.06622683 -1.07239594 -1.07539184\n",
      "   -1.0628748  -1.07301584 -1.06196324 -1.0709326  -1.06112609]\n",
      "  [-0.8727587  -1.00698084 -1.01073855 -1.03837767 -1.01530019\n",
      "   -1.04953723 -1.00751034 -1.03799034 -0.99053488 -1.03804235]\n",
      "  [-0.94365561 -1.03950079 -1.06003685 -1.06688153 -1.06580048\n",
      "   -1.05235566 -1.06267337 -1.05432283 -1.06768995 -1.06258796]\n",
      "  [-0.86804234 -1.00085105 -1.00909779 -1.03704744 -1.0091005\n",
      "   -1.04781598 -1.00972725 -1.03094485 -0.98856382 -1.02015107]\n",
      "  [-0.94053287 -1.03848009 -1.06063344 -1.06132058 -1.06526212\n",
      "   -1.06091373 -1.06423955 -1.09753646 -1.09056502 -1.12677307]\n",
      "  [-0.86817853 -1.00094325 -1.00861466 -1.02725328 -1.01277618\n",
      "   -1.04119765 -1.008247   -1.04653543 -1.01861733 -1.08934094]\n",
      "  [-0.93978257 -1.03817161 -1.05810273 -1.06714006 -1.06373574\n",
      "   -1.04712259 -1.06269014 -1.05588786 -1.10211121 -1.14309974]]]\n",
      "0.3003781106791939\n",
      "0.7060546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 32, 2, 2)\n",
      "Cost : 0.30038\n",
      "Accuracy : 70.60547%\n",
      "Epoch:     6   -   cost: 0.30   -   Accuracy: 70.61%\n",
      "Epoch: {7}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-0.78969955 -0.83040552 -0.80458972 -0.83805423 -0.80762122\n",
      "   -0.83922087 -0.80663016 -0.8404477  -0.80642096 -0.84080992]\n",
      "  [-0.9897672  -1.07669172 -1.09951716 -1.11182533 -1.1099239\n",
      "   -1.07925445 -1.11072135 -1.08078904 -1.10922191 -1.07966358]\n",
      "  [-0.97465726 -1.13218474 -1.13542818 -1.16066662 -1.13595189\n",
      "   -1.17900396 -1.13974489 -1.17461369 -1.13706139 -1.17002339]\n",
      "  [-1.06419251 -1.18402237 -1.21435441 -1.21791089 -1.21139718\n",
      "   -1.20073746 -1.20887351 -1.19899866 -1.20569149 -1.19577896]\n",
      "  [-0.98072616 -1.13551912 -1.14986973 -1.17810504 -1.15260393\n",
      "   -1.18926033 -1.14471861 -1.17656489 -1.12747272 -1.17690673]\n",
      "  [-1.05369224 -1.17591683 -1.20040549 -1.21215936 -1.20155164\n",
      "   -1.19090261 -1.19664599 -1.19687301 -1.19942396 -1.20383403]\n",
      "  [-0.97551989 -1.12930526 -1.14770288 -1.17618592 -1.14599737\n",
      "   -1.18804946 -1.14777812 -1.16848122 -1.12306906 -1.15301193]\n",
      "  [-1.05136652 -1.17404599 -1.20136734 -1.20578706 -1.20239032\n",
      "   -1.20692751 -1.19890979 -1.23848367 -1.22094096 -1.26171739]\n",
      "  [-0.97543274 -1.12927875 -1.14722554 -1.16613535 -1.15005383\n",
      "   -1.18047392 -1.14490425 -1.18309127 -1.1491539  -1.21784977]\n",
      "  [-1.05093253 -1.17405444 -1.19875016 -1.2115479  -1.20092389\n",
      "   -1.18938041 -1.19527231 -1.19311306 -1.23094252 -1.27792504]]]\n",
      "0.26806525448793006\n",
      "0.7060546875\n",
      "(16, 32, 2, 2)\n",
      "Cost : 0.26807\n",
      "Accuracy : 70.60547%\n",
      "Epoch:     7   -   cost: 0.27   -   Accuracy: 70.61%\n",
      "Epoch: {8}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-0.85392484 -0.89840811 -0.87350616 -0.90783153 -0.87654899\n",
      "   -0.90934255 -0.87578229 -0.9105472  -0.87557577 -0.91101185]\n",
      "  [-1.07357092 -1.17578055 -1.20576559 -1.21845889 -1.21071186\n",
      "   -1.18506248 -1.21129366 -1.18665471 -1.20952218 -1.18535641]\n",
      "  [-1.06208909 -1.2411169  -1.24873534 -1.27640335 -1.24809332\n",
      "   -1.29557153 -1.25230158 -1.29156786 -1.24923982 -1.28622732]\n",
      "  [-1.15577195 -1.29765106 -1.33536312 -1.34033565 -1.32495067\n",
      "   -1.31779926 -1.32207952 -1.31842092 -1.3186482  -1.30946753]\n",
      "  [-1.06999132 -1.24560257 -1.26684858 -1.29601868 -1.26928335\n",
      "   -1.30799747 -1.26078949 -1.29517385 -1.24306509 -1.29380062]\n",
      "  [-1.14437209 -1.28888965 -1.32133318 -1.33294    -1.31521504\n",
      "   -1.31214509 -1.30904394 -1.31608301 -1.30977853 -1.32186857]\n",
      "  [-1.06481061 -1.23859629 -1.26401221 -1.29338791 -1.26156184\n",
      "   -1.30650272 -1.26429778 -1.28484557 -1.23572402 -1.26468868]\n",
      "  [-1.1419602  -1.28702302 -1.3236839  -1.3266314  -1.31765712\n",
      "   -1.32940254 -1.31169898 -1.3576002  -1.32937147 -1.37328639]\n",
      "  [-1.06473248 -1.23866539 -1.2632468  -1.28307525 -1.26563892\n",
      "   -1.29779358 -1.25997623 -1.29755087 -1.25639463 -1.32230031]\n",
      "  [-1.14146505 -1.28700395 -1.32168828 -1.3323302  -1.31615918\n",
      "   -1.31118807 -1.30694545 -1.30848575 -1.3356881  -1.3854605 ]]]\n",
      "0.24354681486410515\n",
      "0.7060546875\n",
      "(16, 32, 2, 2)\n",
      "Cost : 0.24355\n",
      "Accuracy : 70.60547%\n",
      "Epoch:     8   -   cost: 0.24   -   Accuracy: 70.61%\n",
      "Epoch: {9}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-0.90586204 -0.95380185 -0.92955738 -0.96473217 -0.9326228\n",
      "   -0.96659355 -0.93209404 -0.96775161 -0.93197897 -0.96840512]\n",
      "  [-1.14184942 -1.25713663 -1.29286644 -1.3060026  -1.29324264\n",
      "   -1.27215686 -1.29364294 -1.27384743 -1.29154716 -1.27231161]\n",
      "  [-1.13356928 -1.3309095  -1.34244019 -1.37199962 -1.34068721\n",
      "   -1.39211962 -1.34516881 -1.38815065 -1.34208711 -1.38230202]\n",
      "  [-1.23016772 -1.39118305 -1.43464413 -1.44146916 -1.41830836\n",
      "   -1.41939438 -1.41504446 -1.41978972 -1.41125812 -1.40807339]\n",
      "  [-1.14280157 -1.33650402 -1.36351703 -1.39336389 -1.36575063\n",
      "   -1.40608671 -1.35703131 -1.39314967 -1.33847841 -1.39025091]\n",
      "  [-1.21801907 -1.38183235 -1.42056573 -1.4333229  -1.40895369\n",
      "   -1.41236748 -1.40127206 -1.41455674 -1.39953506 -1.41658544]\n",
      "  [-1.13766459 -1.32932015 -1.36077388 -1.39041318 -1.35682008\n",
      "   -1.40374488 -1.35854844 -1.37823108 -1.32484163 -1.35208398]\n",
      "  [-1.21548223 -1.37988157 -1.42305406 -1.42648235 -1.41285995\n",
      "   -1.42955312 -1.40319357 -1.45294211 -1.41419717 -1.45959742]\n",
      "  [-1.13764875 -1.3293565  -1.35978469 -1.37999325 -1.36087241\n",
      "   -1.39362855 -1.35306125 -1.38895693 -1.33969095 -1.40013213]\n",
      "  [-1.21489549 -1.3799327  -1.42146604 -1.43148325 -1.41097553\n",
      "   -1.41206439 -1.40052146 -1.40063211 -1.41651118 -1.46708115]]]\n",
      "0.22535814849034175\n",
      "0.7060546875\n",
      "(16, 32, 2, 2)\n",
      "Cost : 0.22536\n",
      "Accuracy : 70.60547%\n",
      "Epoch:     9   -   cost: 0.23   -   Accuracy: 70.61%\n",
      "Epoch: {10}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-0.94750871 -0.99857886 -0.97466085 -1.01084191 -0.97774729\n",
      "   -1.01304794 -0.97744721 -1.01420475 -0.9774615  -1.01497194]\n",
      "  [-1.19650561 -1.32330366 -1.36299544 -1.37651348 -1.3601611\n",
      "   -1.3423786  -1.36056868 -1.34430707 -1.35817739 -1.34268032]\n",
      "  [-1.1910616  -1.40328669 -1.41874427 -1.44938053 -1.41537972\n",
      "   -1.47014158 -1.42041356 -1.46602171 -1.41724924 -1.46012625]\n",
      "  [-1.28990241 -1.4667257  -1.51444548 -1.52328792 -1.49625948\n",
      "   -1.50158816 -1.49454587 -1.50201724 -1.49099377 -1.48941227]\n",
      "  [-1.20121343 -1.40980568 -1.44190125 -1.47183249 -1.44379036\n",
      "   -1.48528963 -1.43501332 -1.47229127 -1.41578106 -1.46875097]\n",
      "  [-1.27722399 -1.45684252 -1.50020374 -1.51444705 -1.48672821\n",
      "   -1.493179   -1.4755561  -1.49355393 -1.47184426 -1.49229954]\n",
      "  [-1.19600151 -1.40250417 -1.43900134 -1.46881679 -1.43392158\n",
      "   -1.48243085 -1.43457109 -1.45377277 -1.39580831 -1.41951918]\n",
      "  [-1.27457066 -1.45476483 -1.50279168 -1.50700131 -1.49153246\n",
      "   -1.51006903 -1.48175126 -1.52874167 -1.48025945 -1.52585962]\n",
      "  [-1.19606725 -1.40251863 -1.43790998 -1.45876333 -1.43839478\n",
      "   -1.4709153  -1.42775255 -1.46092735 -1.40437376 -1.45761148]\n",
      "  [-1.27389888 -1.45489442 -1.50115535 -1.51192255 -1.48798553\n",
      "   -1.49339204 -1.47782582 -1.47404257 -1.47865225 -1.52759801]]]\n",
      "0.21184965355224403\n",
      "0.7060546875\n",
      "(16, 32, 2, 2)\n",
      "Cost : 0.21185\n",
      "Accuracy : 70.60547%\n",
      "Epoch:    10   -   cost: 0.21   -   Accuracy: 70.61%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values = train(train_images, train_labels, 50, 0.01, True) #0.05 stable LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-d1175c062e01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m###### Prediction ######\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mYt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtemp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "###### Prediction ######\n",
    "Yt = test_labels.T\n",
    "temp1 = []\n",
    "for i in range(Yt.shape[1]):\n",
    "        for j in range(Yt.shape[0]):\n",
    "            if(Yt[j][i]==1):\n",
    "                temp1.append(j)\n",
    "Yt=np.array(temp1)\n",
    "Y_test_hat, _ = full_forward_propagation(np.transpose(test_images), params_values, NN_ARCHITECTURE)#multiple?!\n",
    "\n",
    "Yht = np.array(Y_test_hat.T)\n",
    "#x_log=np.log( np.exp(Yh) / np.sum(np.exp(Yh), axis = 1) )  #(60000,10) , we need to add along columns so we get sum of 1 on every example-row\n",
    "num = np.exp(Yht)\n",
    "den = np.sum(np.exp(Yht), axis = 1)\n",
    "for i in range(Yht.shape[0]): #60000\n",
    "                #for j in range(Yh.shape[1]): #10\n",
    "                Yht[i][:] = np.log(num[i][:] / den[i])  \n",
    "\n",
    "#cost = get_cost_value(Yht, Yt)\n",
    "\n",
    "#cost_history.append(cost)\n",
    "accuracy = get_accuracy_value(Y_test_hat, test_labels.T)\n",
    "#accuracy_history.append(accuracy)\n",
    "print(\"Accuracy: {:.5f}%\".format( accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
