{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load from /home/USER/data/mnist or elsewhere; download if missing.\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\salt\n",
    "        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    #os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\"\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "    \"\"\"\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/images/\"\n",
    "        onlyfiles = [cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,101,101).astype('float32')/255\n",
    "        return pixels[:,:,0:100,0:100]\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        \n",
    "        folder = path + \"/labels/\"\n",
    "        onlyfiles = [image.imread(folder+f) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,101,101).astype('float32')/255\n",
    "        return pixels[:,:,0:100,0:100]\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(path)\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(path)\n",
    "    \"\"\"\"\n",
    "    print(\"Test Images  : Loading . . .\")\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    print(\"Test Labels  : Loading . . .\")\n",
    "    test_labels = _labels(os.path.join(path, files[3])) \n",
    "    \"\"\"\n",
    "    print(\"Done!\")\n",
    "    return train_images , train_labels #, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1, 100, 100)\n",
      "(4000, 1, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape) # ONE-HOT !!!\n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Convolution Architecture - Downsampling/Upsampling  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f ):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    trim = 0.1\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trim\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trim\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trim #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trim\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trim\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trim\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \n",
    "    return filters, bias, f_dc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "    \n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] * f[z, :, :, :]) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "\n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "    #print(arr.shape)\n",
    "    try:\n",
    "        idx = np.nanargmax(arr)\n",
    "        #print (idx)\n",
    "    except:\n",
    "        idx = 0\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h + a, _w + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def NLLLoss(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[1]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] == 1):\n",
    "                out[:,i,j] = logs[:,i,j] #in that case the propab. is correct with targen being the 1\n",
    "            else:\n",
    "                out[:,i,j] = 1 - logs[:,i,j] # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    return out.sum()/mylen\n",
    "\n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, verbose=True, callback=None):\n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    \n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    filters,bias, f_dc = init_filters(5,16) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "    \n",
    "    #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    \n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]\n",
    "    for i in filters:     \n",
    "        v1 = np.zeros(i[0].shape)\n",
    "        v2 = np.zeros(i[1].shape)\n",
    "        s1 = np.zeros(i[0].shape)\n",
    "        s2 = np.zeros(i[1].shape)\n",
    "        v_a = [v1, v2]\n",
    "        s_a = [s1, s2]\n",
    "        v_adam.append(v_a)\n",
    "        s_adam.append(s_a)\n",
    "            \n",
    "    for i in bias:\n",
    "        bv1 = np.zeros(i[0].shape)\n",
    "        bv2 = np.zeros(i[1].shape)\n",
    "        bs1 = np.zeros(i[0].shape)\n",
    "        bs2 = np.zeros(i[1].shape)    \n",
    "        bv_a = [bv1, bv2]\n",
    "        bs_a = [bs1, bs2]\n",
    "        bv_adam.append(bv_a)\n",
    "        bs_adam.append(bs_a)\n",
    "    \n",
    "    for i in f_dc:\n",
    "        fdc_v1 = np.zeros(i[0].shape)\n",
    "        bdc_v2 = np.zeros(i[1].shape)\n",
    "        fdc_s1 = np.zeros(i[0].shape)\n",
    "        bdc_s2 = np.zeros(i[1].shape)    \n",
    "        fdc_v_a = [fdc_v1, bdc_v2]\n",
    "        fdc_s_a = [fdc_s1, bdc_s2]\n",
    "        fdc_v_adam.append(fdc_v_a)\n",
    "        fdc_s_adam.append(fdc_s_a)\n",
    "    \n",
    "    #Final layer 1x1 filter setup\n",
    "    out_f = np.random.randn(1,16,1,1)*0.1\n",
    "    out_b = np.random.randn(out_f.shape[0],1)*0.1\n",
    "    \n",
    "    v_out_f = np.zeros(out_f.shape)\n",
    "    s_out_f = np.zeros(out_f.shape)\n",
    "    bv_out_b = np.zeros(out_b.shape)\n",
    "    bs_out_b = np.zeros(out_b.shape)\n",
    "    out_fb = [out_f, out_b]\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7,f8,f9] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "    [fb6_dc, fb7_dc, fb8_dc, fb9_dc] = f_dc\n",
    "    \n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        batch = 12\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            \n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.95\n",
    "            beta2= 0.99\n",
    "            lr = learning_rate\n",
    "            batch_size= batch\n",
    "            \n",
    "            df =  []\n",
    "            db =  []\n",
    "            dfb=  []\n",
    "            for i in filters:\n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                df2_t = np.zeros(i[1].shape)\n",
    "                f_temp = [df1_t, df2_t]\n",
    "                df.append(f_temp)\n",
    "                \n",
    "            for i in bias:\n",
    "                db1_t = np.zeros(i[0].shape)\n",
    "                db2_t = np.zeros(i[1].shape)\n",
    "                b_temp = [db1_t, db2_t]\n",
    "                db.append(b_temp)\n",
    "            \n",
    "            for i in f_dc:\n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                db1_t = np.zeros(i[1].shape)\n",
    "                fb_temp = [df1_t, db1_t]\n",
    "                dfb.append(fb_temp)\n",
    "                \n",
    "            dout_f = np.zeros(out_f.shape)\n",
    "            dout_b = np.zeros(out_b.shape)\n",
    "            ######################################\n",
    "            \n",
    "            \n",
    "            #timestamp1 = time.time()\n",
    "            \n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            cost = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            [df1,df2,df3,df4,df5,df6,df7,df8,df9] = df\n",
    "            [db1,db2,db3,db4,db5,db6,db7,db8,db9] = db \n",
    "            [dfb6_dc,dfb7_dc,dfb8_dc,dfb9_dc]     = dfb\n",
    "            \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print(b)\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                params = [f1[0], b1[0]]  \n",
    "                conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "                conv1_1[conv1_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f1[1], b1[1]]\n",
    "                conv1_2 = conv(conv1_1, params, 1)\n",
    "                conv1_2[conv1_2<=0] = 0 #Relu\n",
    "                ##################################### conv1_2: 100x100x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (100-2)/2+1  = 50 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f2[0], b2[0]]  \n",
    "                conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv2_1[conv2_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f2[1], b2[1]]\n",
    "                conv2_2 = conv(conv2_1, params, 1)\n",
    "                conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "                #####################################  50x50x32\n",
    "\n",
    "                pl2 = maxpool(conv2_2, 2, 2) #pool_f = 2 , pool_s = 2    , (50 -2)/2 +1 = 25\n",
    "                ## ADD DROPOUT HERE\n",
    "\n",
    "                ########### 3rd Big Layer ###########\n",
    "                params = [f3[0], b3[0]]  \n",
    "                conv3_1 = conv(pl2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f3[1], b3[1]]\n",
    "                conv3_2 = conv(conv3_1, params, 1)\n",
    "                conv3_2[conv3_2<=0] = 0 #Relu             \n",
    "                #####################################  25x25x64\n",
    "\n",
    "                pl3 = maxpool(conv3_2, 2, 2) #pool_f = 2 , pool_s = 2   ,  (25-2)/2 +1 = 12\n",
    "                ## ADD DROPOUT HERE\n",
    "                \n",
    "                ########### 4th Big Layer ###########\n",
    "                params = [f4[0], b4[0]]  \n",
    "                conv4_1 = conv(pl3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv4_1[conv4_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f4[1], b4[1]]\n",
    "                conv4_2 = conv(conv4_1, params, 1)\n",
    "                conv4_2[conv4_2<=0] = 0 #Relu             \n",
    "                #####################################     12x12x128\n",
    "\n",
    "                pl4 = maxpool(conv4_2, 2, 2) #pool_f = 2 , pool_s = 2  , (12-2)/2 +1 =6  : 6x6x128\n",
    "                ## ADD DROPOUT HERE\n",
    "                \n",
    "                ########### 5th Big Layer ###########   6x6x128-->6x6x256\n",
    "                params = [f5[0], b5[0]]  \n",
    "                conv5_1 = conv(pl4, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv5_1[conv5_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f5[1], b5[1]]\n",
    "                conv5_2 = conv(conv5_1, params, 1)\n",
    "                conv5_2[conv5_2<=0] = 0 #Relu             \n",
    "                #####################################  6x6x256\n",
    "                \n",
    "                #####################################\n",
    "                #Because of ambigious size after the upsampling the concat func must take care possible crop of the conv#_2 \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "                params = [fb6_dc[0], fb6_dc[1]] # deconv filter, deconv bias\n",
    "                dc6, new_in6 = convTransp(conv5_2, params, 1, 0)   #result:   =  12x12x128 , # conv5_2 requires NO crop\n",
    "                #Concat dc6 with conv4_2 so we get 256 channels (12x12x256)\n",
    "                c6 = concat(dc6, conv4_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          12x12x256     \n",
    "                params = [f6[0], b6[0]]  \n",
    "                conv6_1 = conv(c6, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv6_1[conv6_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f6[1], b6[1]]\n",
    "                conv6_2 = conv(conv6_1, params, 1)\n",
    "                conv6_2[conv6_2<=0] = 0 #Relu   \n",
    "                #####################################    12x12x128\n",
    "                #(12-1)*2 + 2 =24\n",
    "                params = [fb7_dc[0], fb7_dc[1]] # deconv filter, deconv bias\n",
    "                dc7, new_in7 = convTransp(conv6_2, params, 1, 0)   #result:   =  24x24x64\n",
    "                #Concat dc7 with conv3_2 so we get  channels (24x24x128)\n",
    "                c7 = concat(dc7, conv3_2)   #crop is required\n",
    "                \n",
    "                ########### 2nd Big dc Layer ###########          24x24x128     \n",
    "                params = [f7[0], b7[0]]  \n",
    "                conv7_1 = conv(c7, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv7_1[conv7_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f7[1], b7[1]]\n",
    "                conv7_2 = conv(conv7_1, params, 1)\n",
    "                conv7_2[conv7_2<=0] = 0 #Relu     \n",
    "                #####################################    24x24x64\n",
    "                #(24-1)*2 + 2 = 48\n",
    "                params = [fb8_dc[0], fb8_dc[1]] # deconv filter, deconv bias\n",
    "                dc8, new_in8 = convTransp(conv7_2, params, 1, 0)   #result:   =  48x48x32\n",
    "                #Concat dc8 with conv2_2 so we get  channels (48x48x64)\n",
    "                c8 = concat(dc8 ,conv2_2)   #crop is required\n",
    "                \n",
    "                ########### 3rd Big dc Layer ###########          48x48x64    \n",
    "                params = [f8[0], b8[0]]  \n",
    "                conv8_1 = conv(c8, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv8_1[conv8_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f8[1], b8[1]]\n",
    "                conv8_2 = conv(conv8_1, params, 1)\n",
    "                conv8_2[conv8_2<=0] = 0 #Relu    \n",
    "                #####################################    48x48x32                              \n",
    "                #(48-1)*2 + 2 = 96\n",
    "                params = [fb9_dc[0], fb9_dc[1]] # deconv filter, deconv bias\n",
    "                dc9, new_in9 = convTransp(conv8_2, params, 1, 0)   #result:   =  96x96x16\n",
    "                #Concat dc9 with conv1_2 so we get  channels (96x96x32)\n",
    "                c9 = concat(dc9, conv1_2)   #crop is required                \n",
    "               \n",
    "                ########### 4th Big dc Layer ###########          96x96x32   \n",
    "                params = [f9[0], b9[0]]  \n",
    "                conv9_1 = conv(c9, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv9_1[conv9_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f9[1], b9[1]]\n",
    "                conv9_2 = conv(conv9_1, params, 1)\n",
    "                conv9_2[conv9_2<=0] = 0 #Relu   \n",
    "                #####################################    96x96x16\n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 96x96x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv9_2, params, 1, 0) #output.shape: 96x96x1\n",
    "                \n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                \n",
    "                #label crop is needed\n",
    "                Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                cost += NLLLoss(Y_hat, Y_t_b)\n",
    "                print(cost)\n",
    "                \n",
    "                accuracy += get_accuracy_value(Y_hat, Y_t_b)\n",
    "                \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t_b\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv9_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv9_2, out_f, conv_s) #\n",
    "                #pack data\n",
    "                \n",
    "                \n",
    "                dconv9_2[conv9_2<=0] = 0             \n",
    "                dconv9_1, df9_2, db9_2 = convolutionBackward(dconv9_2, conv9_1, f9[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv9_1[conv9_1<=0] = 0\n",
    "                conc_dconv9, df9_1, db9_1 = convolutionBackward(dconv9_1, c9, f9[0], conv_s) #C9 is not needed for input,we know how to select the right gradients\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv9, dconv1_2 = crop2half(conc_dconv9)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                \n",
    "                dconv8_2, df9_dc, db9_dc = convTranspBackward(dconv9, new_in9, fb9_dc[0],conv_s)\n",
    "                #pack data\n",
    "\n",
    "                dconv8_2[conv8_2<=0] = 0\n",
    "                dconv8_1, df8_2, db8_2 = convolutionBackward(dconv8_2, conv8_1, f8[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv8_1[conv8_1<=0] = 0\n",
    "                conc_dconv8, df8_1, db8_1 = convolutionBackward(dconv8_1, c8, f8[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv8, dconv2_2 = crop2half(conc_dconv8)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                dconv2_2 = reshape(dconv2_2, conv2_2.shape[1])\n",
    "                \n",
    "                dconv7_2, df8_dc, db8_dc = convTranspBackward(dconv8, new_in8, fb8_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv7_2[conv7_2<=0] = 0\n",
    "                dconv7_1, df7_2, db7_2 = convolutionBackward(dconv7_2, conv7_1, f7[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv7_1[conv7_1<=0] = 0\n",
    "                conc_dconv7, df7_1, db7_1 = convolutionBackward(dconv7_1, c7, f7[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv7, dconv3_2 = crop2half(conc_dconv7)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #Make sure that dconv3_2 is the same dim with the dconv3_2 that will come from maxpool in decoding side\n",
    "                dconv3_2 = reshape(dconv3_2, conv3_2.shape[1])\n",
    "                \n",
    "                dconv6_2, df7_dc, db7_dc = convTranspBackward(dconv7, new_in7, fb7_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv6_2[conv6_2<=0] = 0\n",
    "                dconv6_1, df6_2, db6_2 = convolutionBackward(dconv6_2, conv6_1, f6[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv7_1[conv7_1<=0] = 0\n",
    "                conc_dconv6, df6_1, db6_1 = convolutionBackward(dconv6_1, c6, f6[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv6, dconv4_2 = crop2half(conc_dconv6)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                dconv4_2 = reshape(dconv4_2, conv4_2.shape[1])\n",
    "                \n",
    "                dconv5_2, df6_dc, db6_dc = convTranspBackward(dconv6, new_in6, fb6_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv5_2[conv5_2<=0] = 0\n",
    "                dconv5_1, df5_2, db5_2 = convolutionBackward(dconv5_2, conv5_1, f5[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv5_1[conv5_1<=0] = 0\n",
    "                dpl4, df5_1, db5_1 = convolutionBackward(dconv5_1, pl4, f5[0], conv_s) #\n",
    "                \n",
    "                dconv4_2 += maxpoolBackward(dpl4, conv4_2, f=2 , s=2) #Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv4_2[conv4_2<=0] = 0\n",
    "                dconv4_1, df4_2, db4_2 = convolutionBackward(dconv4_2, conv4_1, f4[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv4_1[conv4_1<=0] = 0\n",
    "                dpl3, df4_1, db4_1 = convolutionBackward(dconv4_1, pl3, f4[0], conv_s) #\n",
    "\n",
    "                dconv3_2 += maxpoolBackward(dpl3, conv3_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv3_2[conv3_2<=0] = 0\n",
    "                dconv3_1, df3_2, db3_2 = convolutionBackward(dconv3_2, conv3_1, f3[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv3_1[conv3_1<=0] = 0\n",
    "                dpl2, df3_1, db3_1 = convolutionBackward(dconv3_1, pl2, f3[0], conv_s) #\n",
    "                \n",
    "                dconv2_2 += maxpoolBackward(dpl2, conv2_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv2_2[conv2_2<=0] = 0\n",
    "                dconv2_1, df2_2, db2_2 = convolutionBackward(dconv2_2, conv2_1, f2[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv2_1[conv2_1<=0] = 0\n",
    "                dpl1, df2_1, db2_1 = convolutionBackward(dconv2_1, pl1, f2[0], conv_s) #\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv1_2[conv1_2<=0] = 0\n",
    "                dconv1_1, df1_2, db1_2 = convolutionBackward(dconv1_2, conv1_1, f1[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv1_1[conv1_1<=0] = 0\n",
    "                _, df1_1, db1_1 = convolutionBackward(dconv1_1, X_t[b], f1[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                [df1,df2,df3,df4,df5,df6,df7,df8,df9] = df\n",
    "                [db1,db2,db3,db4,db5,db6,db7,db8,db9] = db \n",
    "                [dfb6_dc,dfb7_dc,dfb8_dc,dfb9_dc]     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                df4[0] += df4_1\n",
    "                df4[1] += df4_2\n",
    "                df5[0] += df5_1\n",
    "                df5[1] += df5_2\n",
    "                df6[0] += df6_1\n",
    "                df6[1] += df6_2\n",
    "                df7[0] += df7_1\n",
    "                df7[1] += df7_2\n",
    "                df8[0] += df8_1\n",
    "                df8[1] += df8_2\n",
    "                df9[0] += df9_1\n",
    "                df9[1] += df9_2\n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                db4[0] += db4_1\n",
    "                db4[1] += db4_2\n",
    "                db5[0] += db5_1\n",
    "                db5[1] += db5_2\n",
    "                db6[0] += db6_1\n",
    "                db6[1] += db6_2\n",
    "                db7[0] += db7_1\n",
    "                db7[1] += db7_2\n",
    "                db8[0] += db8_1\n",
    "                db8[1] += db8_2\n",
    "                db9[0] += db9_1\n",
    "                db9[1] += db9_2\n",
    "\n",
    "                dfb6_dc[0] += df6_dc\n",
    "                dfb6_dc[1] += db6_dc\n",
    "                dfb7_dc[0] += df7_dc\n",
    "                dfb7_dc[1] += db7_dc\n",
    "                dfb8_dc[0] += df8_dc\n",
    "                dfb8_dc[1] += db8_dc\n",
    "                dfb9_dc[0] += df9_dc\n",
    "                dfb9_dc[1] += db9_dc\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in filter:\n",
    "                v_adam[i,0] = beta1*v_adam[i,0] + (1-beta1)*df[i,0]/batch_size #f1\n",
    "                s_adam[i,0] = beta2*s_adam[i,0] + (1-beta2)*df[i,0]/batch_size #f1\n",
    "                filters[i,0] -= lr*v_adam[i,0]/np.sqrt(s_adam[i,0] + 1e-7)\n",
    "                \n",
    "                v_adam[i,1] = beta1*v_adam[i,1] + (1-beta1)*df[i,1]/batch_size #f2\n",
    "                s_adam[i,1] = beta2*s_adam[i,1] + (1-beta2)*df[i,1]/batch_size #f2\n",
    "                filters[i,1] -= lr*v_adam[i,1]/np.sqrt(s_adam[i,1] + 1e-7)\n",
    "                \n",
    "            for i in bias:\n",
    "                bv_adam[i,0] = beta1*bv_adam[i,0] + (1-beta1)*db[i,0]/batch_size #b1\n",
    "                bs_adam[i,0] = beta2*bs_adam[i,0] + (1-beta2)*db[i,0]/batch_size #b1\n",
    "                bias[i,0] -= lr*bv_adam[i,0]/np.sqrt(bs_adam[i,0] + 1e-7)\n",
    "                \n",
    "                bv_adam[i,1] = beta1*bv_adam[i,1] + (1-beta1)*db[i,1]/batch_size #b2\n",
    "                bs_adam[i,1] = beta2*bs_adam[i,1] + (1-beta2)*db[i,1]/batch_size #b2\n",
    "                bias[i,1] -= lr*bv_adam[i,1]/np.sqrt(bs_adam[i,1] + 1e-7)\n",
    "            \n",
    "            for i in f_dc:\n",
    "                fdc_v_adam[i,0] = beta1*fdc_v_adam[i,0] + (1-beta1)*dfb[i,0]/batch_size #f1\n",
    "                fdc_s_adam[i,0] = beta2*fdc_s_adam[i,0] + (1-beta2)*dfb[i,0]/batch_size #f1\n",
    "                f_dc[i,0] -= lr*bv_adam[i,0]/np.sqrt(bs_adam[i,0] + 1e-7)\n",
    "                \n",
    "                fdc_v_adam[i,1] = beta1*fdc_v_adam[i,1] + (1-beta1)*dfb[i,1]/batch_size #b2\n",
    "                fdc_s_adam[i,1] = beta2*fdc_s_adam[i,1] + (1-beta2)*dfb[i,1]/batch_size #b2\n",
    "                f_dc[i,1] -= lr*fdc_v_adam[i,1]/np.sqrt(fdc_s_adam[i,1] + 1e-7)    \n",
    "            \n",
    "            v_out = beta1*v_out + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out = beta2*s_out + (1 - beta2)*dout_f/batch_size #f\n",
    "            out_f -= lr*v_out/np.sqrt(s_out + 1e-7)\n",
    "            \n",
    "            bv_out = beta1*bv_out + (1 - beta1)*dout_b/batch_size #f\n",
    "            bs_out = beta2*bs_out + (1 - beta2)*dout_b/batch_size #f\n",
    "            out_b -= lr*bv_out/np.sqrt(bs_out + 1e-7)\n",
    "            \n",
    "            \n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            print(\"Batch:{%d}\".format(c+12))\n",
    "            \n",
    "            '''\n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            \n",
    "            '''\n",
    "            print(\"Cost : {:.5f}\".format(cost/batch))\n",
    "            print(\"Accuracy : {:.5f}%\".format((accuracy*100)/batch))\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        if(verbose):\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "            \n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {1}\n",
      "0\n",
      "0.5805876701125283\n",
      "100\n",
      "96\n",
      "50\n",
      "48\n",
      "25\n",
      "24\n",
      "12\n",
      "12\n",
      "1\n",
      "1.161178522825517\n",
      "100\n",
      "96\n",
      "50\n",
      "48\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-67bfd28b9d31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mparams_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#0.05 stable LR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-5fcd352c63d6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, Y, epochs, learning_rate, dropout, verbose, callback)\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0;31m#pack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mdconv7_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv7_1\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 \u001b[0mconc_dconv7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf7_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb7_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolutionBackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdconv7_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_s\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;31m###### we get the concat gradients ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-30e31036bfeb>\u001b[0m in \u001b[0;36mconvolutionBackward\u001b[0;34m(dconv_prev, conv_in, filt, s, pad)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m#each entry of the dconv_prev will try to affect the idxs from which was made of.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mdfilt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdconv_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconv_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0mdconv_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdconv_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdconv_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#, axis =1) ## AXIS?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values = train(train_images, train_labels, 2, 0.01, True) #0.05 stable LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Prediction ######\n",
    "Yt = test_labels.T\n",
    "temp1 = []\n",
    "for i in range(Yt.shape[1]):\n",
    "        for j in range(Yt.shape[0]):\n",
    "            if(Yt[j][i]==1):\n",
    "                temp1.append(j)\n",
    "Yt=np.array(temp1)\n",
    "Y_test_hat, _ = full_forward_propagation(np.transpose(test_images), params_values, NN_ARCHITECTURE)#multiple?!\n",
    "\n",
    "Yht = np.array(Y_test_hat.T)\n",
    "#x_log=np.log( np.exp(Yh) / np.sum(np.exp(Yh), axis = 1) )  #(60000,10) , we need to add along columns so we get sum of 1 on every example-row\n",
    "num = np.exp(Yht)\n",
    "den = np.sum(np.exp(Yht), axis = 1)\n",
    "for i in range(Yht.shape[0]): #60000\n",
    "                #for j in range(Yh.shape[1]): #10\n",
    "                Yht[i][:] = np.log(num[i][:] / den[i])  \n",
    "\n",
    "#cost = get_cost_value(Yht, Yt)\n",
    "\n",
    "#cost_history.append(cost)\n",
    "accuracy = get_accuracy_value(Y_test_hat, test_labels.T)\n",
    "#accuracy_history.append(accuracy)\n",
    "print(\"Accuracy: {:.5f}%\".format( accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
