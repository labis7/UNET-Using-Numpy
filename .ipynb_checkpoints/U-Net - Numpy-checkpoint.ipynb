{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load from /home/USER/data/mnist or elsewhere; download if missing.\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\salt\n",
    "        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    #os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\"\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "    \"\"\"\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/images/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(128, 128)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,128,128).astype('float32')#/255\n",
    "        return pixels[:1,:,:,:]\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        \n",
    "        folder = path + \"/labels/\"\n",
    "        onlyfiles = [cv2.resize(image.imread(folder+f),(128, 128)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,128,128).astype('float32') #/255\n",
    "        return pixels[:1,:,:,:]\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(path)\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(path)\n",
    "    \"\"\"\"\n",
    "    print(\"Test Images  : Loading . . .\")\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    print(\"Test Labels  : Loading . . .\")\n",
    "    test_labels = _labels(os.path.join(path, files[3])) \n",
    "    \"\"\"\n",
    "    print(\"Done!\")\n",
    "    return train_images , train_labels #, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n",
      "(1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape) # ONE-HOT !!!\n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "#plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_labels[0].squeeze(), cmap='Greys_r');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Convolution Architecture - Downsampling/Upsampling  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f ):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    trim = 0.05\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trim\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trim\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trim #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trim\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trim\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trim\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \n",
    "    return filters, bias, f_dc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "\n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(np.multiply(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] , f[z, :, :, :])) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "\n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "    #print(arr.shape)\n",
    "    try:\n",
    "        idx = np.nanargmax(arr)\n",
    "        #print (idx)\n",
    "    except:\n",
    "        idx = 0\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h + a, _w + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "        print(\"Warning: Extra crop needed and handled!(%d --> %d)\" %(dim, img2.shape[1]))\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def NLLLoss(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[1]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] == 1):\n",
    "                out[:,i,j] = logs[:,i,j] #in that case the propab. is correct with targen being the 1\n",
    "            else:\n",
    "                out[:,i,j] = 1 - logs[:,i,j] # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    return -np.log(out.sum()/mylen)\n",
    "\n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "def normalize(output):\n",
    "    output[output<-10]=-4\n",
    "    output[output>10] = 4\n",
    "    return output\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, verbose=True, callback=None):\n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    \n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    filters,bias, f_dc = init_filters(5,16) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "    ##Final 1x1 filter\n",
    "    trim = 0.04\n",
    "    out_f = np.random.randn(1,16,1,1)*trim\n",
    "    out_b = np.random.randn(out_f.shape[0],1)*trim  \n",
    "    out_fb = [out_f, out_b]\n",
    "    #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "\n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]  \n",
    "\n",
    "            \n",
    "\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7,f8,f9] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "    [fb6_dc, fb7_dc, fb8_dc, fb9_dc] = f_dc\n",
    "    \n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        batch = 1\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            print('Batch: {}'.format(int(c/batch +1)))\n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.95\n",
    "            beta2= 0.99\n",
    "            lr = learning_rate\n",
    "            batch_size= batch\n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            cost = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            df =  []\n",
    "            db =  []\n",
    "            dfb=  []\n",
    "            for i in filters:\n",
    "                v1 = np.zeros(i[0].shape)\n",
    "                v2 = np.zeros(i[1].shape)\n",
    "                s1 = np.zeros(i[0].shape)\n",
    "                s2 = np.zeros(i[1].shape)\n",
    "                v_a = [v1, v2]\n",
    "                s_a = [s1, s2]\n",
    "                v_adam.append(v_a)\n",
    "                s_adam.append(s_a)\n",
    "                \n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                df2_t = np.zeros(i[1].shape)\n",
    "                f_temp = [df1_t, df2_t]\n",
    "                df.append(f_temp)\n",
    "                \n",
    "            for i in bias:\n",
    "                bv1 = np.zeros(i[0].shape)\n",
    "                bv2 = np.zeros(i[1].shape)\n",
    "                bs1 = np.zeros(i[0].shape)\n",
    "                bs2 = np.zeros(i[1].shape)    \n",
    "                bv_a = [bv1, bv2]\n",
    "                bs_a = [bs1, bs2]\n",
    "                bv_adam.append(bv_a)\n",
    "                bs_adam.append(bs_a)\n",
    "                \n",
    "                \n",
    "                db1_t = np.zeros(i[0].shape)\n",
    "                db2_t = np.zeros(i[1].shape)\n",
    "                b_temp = [db1_t, db2_t]\n",
    "                db.append(b_temp)\n",
    "            \n",
    "            for i in f_dc:\n",
    "                fdc_v1 = np.zeros(i[0].shape)\n",
    "                bdc_v2 = np.zeros(i[1].shape)\n",
    "                fdc_s1 = np.zeros(i[0].shape)\n",
    "                bdc_s2 = np.zeros(i[1].shape)    \n",
    "                fdc_v_a = [fdc_v1, bdc_v2]\n",
    "                fdc_s_a = [fdc_s1, bdc_s2]\n",
    "                fdc_v_adam.append(fdc_v_a)\n",
    "                fdc_s_adam.append(fdc_s_a)\n",
    "                \n",
    "                \n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                db1_t = np.zeros(i[1].shape)\n",
    "                fb_temp = [df1_t, db1_t]\n",
    "                dfb.append(fb_temp)\n",
    "            \n",
    "            \n",
    "            #Final layer 1x1 filter setup\n",
    "\n",
    "            v_out_f = np.zeros(out_f.shape)\n",
    "            s_out_f = np.zeros(out_f.shape)\n",
    "            bv_out_b = np.zeros(out_b.shape)\n",
    "            bs_out_b = np.zeros(out_b.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            dout_f = np.zeros(out_f.shape)\n",
    "            dout_b = np.zeros(out_b.shape)\n",
    "            \n",
    "            ######################################\n",
    "            \n",
    "            \n",
    "            #timestamp1 = time.time()\n",
    "            \n",
    "            \n",
    "            [df1,df2,df3,df4,df5,df6,df7,df8,df9] = df\n",
    "            [db1,db2,db3,db4,db5,db6,db7,db8,db9] = db \n",
    "            [dfb6_dc,dfb7_dc,dfb8_dc,dfb9_dc]     = dfb\n",
    "            \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print('Image: {}/{}'.format((b+1),batch))\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                params = [f1[0], b1[0]]  \n",
    "                conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "                conv1_1[conv1_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f1[1], b1[1]]\n",
    "                conv1_2 = conv(conv1_1, params, 1)\n",
    "                conv1_2[conv1_2<=0] = 0 #Relu\n",
    "                ##################################### conv1_2: 128x128x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (128-2)/2+1  = 64 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f2[0], b2[0]]  \n",
    "                conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv2_1[conv2_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f2[1], b2[1]]\n",
    "                conv2_2 = conv(conv2_1, params, 1)\n",
    "                conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "                #####################################  64x64x32\n",
    "\n",
    "                pl2 = maxpool(conv2_2, 2, 2) #pool_f = 2 , pool_s = 2    , (64 -2)/2 +1 = 32\n",
    "                ## ADD DROPOUT HERE\n",
    "\n",
    "                ########### 3rd Big Layer ###########\n",
    "                params = [f3[0], b3[0]]  \n",
    "                conv3_1 = conv(pl2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f3[1], b3[1]]\n",
    "                conv3_2 = conv(conv3_1, params, 1)\n",
    "                conv3_2[conv3_2<=0] = 0 #Relu             \n",
    "                #####################################  32x32x64\n",
    "\n",
    "                pl3 = maxpool(conv3_2, 2, 2) #pool_f = 2 , pool_s = 2   ,  (32-2)/2 +1 = 16\n",
    "                ## ADD DROPOUT HERE\n",
    "                \n",
    "                ########### 4th Big Layer ###########\n",
    "                params = [f4[0], b4[0]]  \n",
    "                conv4_1 = conv(pl3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv4_1[conv4_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f4[1], b4[1]]\n",
    "                conv4_2 = conv(conv4_1, params, 1)\n",
    "                conv4_2[conv4_2<=0] = 0 #Relu             \n",
    "                #####################################     16x16x128\n",
    "\n",
    "                pl4 = maxpool(conv4_2, 2, 2) #pool_f = 2 , pool_s = 2  , (16-2)/2 +1 =8  : 8x8x128\n",
    "                ## ADD DROPOUT HERE\n",
    "                \n",
    "                ########### 5th Big Layer ###########   8x8x128-->8x8x256\n",
    "                params = [f5[0], b5[0]]  \n",
    "                conv5_1 = conv(pl4, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv5_1[conv5_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f5[1], b5[1]]\n",
    "                conv5_2 = conv(conv5_1, params, 1)\n",
    "                conv5_2[conv5_2<=0] = 0 #Relu             \n",
    "                #####################################  8x8x256\n",
    "                \n",
    "                #####################################\n",
    "                #Because of ambigious size after the upsampling the concat func must take care possible crop of the conv#_2 \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "                params = [fb6_dc[0], fb6_dc[1]] # deconv filter, deconv bias\n",
    "                dc6, new_in6 = convTransp(conv5_2, params, 1, 0)   #result:   =  16x16x128 , # conv5_2 requires NO crop\n",
    "                #Concat dc6 with conv4_2 so we get 256 channels (16x16x256)\n",
    "                c6 = concat(dc6, conv4_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          16x16x256     \n",
    "                params = [f6[0], b6[0]]  \n",
    "                conv6_1 = conv(c6, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv6_1[conv6_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f6[1], b6[1]]\n",
    "                conv6_2 = conv(conv6_1, params, 1)\n",
    "                conv6_2[conv6_2<=0] = 0 #Relu   \n",
    "                #####################################    16x16x128\n",
    "                #(16-1)*2 + 2 =32\n",
    "                params = [fb7_dc[0], fb7_dc[1]] # deconv filter, deconv bias\n",
    "                dc7, new_in7 = convTransp(conv6_2, params, 1, 0)   #result:   =  32x32x64\n",
    "                #Concat dc7 with conv3_2 so we get  channels (32x32x128)\n",
    "                c7 = concat(dc7, conv3_2)   \n",
    "                \n",
    "                ########### 2nd Big dc Layer ###########          32x32x128     \n",
    "                params = [f7[0], b7[0]]  \n",
    "                conv7_1 = conv(c7, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv7_1[conv7_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f7[1], b7[1]]\n",
    "                conv7_2 = conv(conv7_1, params, 1)\n",
    "                conv7_2[conv7_2<=0] = 0 #Relu     \n",
    "                #####################################    32x32x64\n",
    "                #(24-1)*2 + 2 = 48\n",
    "                params = [fb8_dc[0], fb8_dc[1]] # deconv filter, deconv bias\n",
    "                dc8, new_in8 = convTransp(conv7_2, params, 1, 0)   #result:   =  64x64x32\n",
    "                #Concat dc8 with conv2_2 so we get  channels (64x64x64)\n",
    "                c8 = concat(dc8 ,conv2_2)   \n",
    "                \n",
    "                ########### 3rd Big dc Layer ###########          64x64x64    \n",
    "                params = [f8[0], b8[0]]  \n",
    "                conv8_1 = conv(c8, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv8_1[conv8_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f8[1], b8[1]]\n",
    "                conv8_2 = conv(conv8_1, params, 1)\n",
    "                conv8_2[conv8_2<=0] = 0 #Relu    \n",
    "                #####################################    64x64x32                              \n",
    "                #(64-1)*2 + 2 = 128\n",
    "                params = [fb9_dc[0], fb9_dc[1]] # deconv filter, deconv bias\n",
    "                dc9, new_in9 = convTransp(conv8_2, params, 1, 0)   #result:   =  128x128x16\n",
    "                #Concat dc9 with conv1_2 so we get  channels (128x128x32)\n",
    "                c9 = concat(dc9, conv1_2)                   \n",
    "               \n",
    "                ########### 4th Big dc Layer ###########          128x128x32   \n",
    "                params = [f9[0], b9[0]]  \n",
    "                conv9_1 = conv(c9, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv9_1[conv9_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f9[1], b9[1]]\n",
    "                conv9_2 = conv(conv9_1, params, 1)\n",
    "                conv9_2[conv9_2<=0] = 0 #Relu   \n",
    "                #####################################    128x128x16\n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 128x128x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv9_2, params, 1, 0) #output.shape: 128x128x1\n",
    "                \n",
    "                print(output[:,0:10,0:10])\n",
    "                output = normalize(output)\n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                \n",
    "                #label crop is needed\n",
    "                #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "                cost += NLLLoss(Y_hat, Y_t[b])\n",
    "                print(cost/(b+1))\n",
    "                \n",
    "                accuracy += get_accuracy_value(Y_hat, Y_t[b])\n",
    "                print(accuracy/(b+1))\n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t[b]\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv9_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv9_2, out_f, conv_s) #\n",
    "                #pack data\n",
    "                \n",
    "                \n",
    "                dconv9_2[conv9_2<=0] = 0             \n",
    "                dconv9_1, df9_2, db9_2 = convolutionBackward(dconv9_2, conv9_1, f9[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv9_1[conv9_1<=0] = 0\n",
    "                conc_dconv9, df9_1, db9_1 = convolutionBackward(dconv9_1, c9, f9[0], conv_s) #C9 is not needed for input,we know how to select the right gradients\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv9, dconv1_2 = crop2half(conc_dconv9)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                \n",
    "                dconv8_2, df9_dc, db9_dc = convTranspBackward(dconv9, new_in9, fb9_dc[0],conv_s)\n",
    "                #pack data\n",
    "\n",
    "                dconv8_2[conv8_2<=0] = 0\n",
    "                dconv8_1, df8_2, db8_2 = convolutionBackward(dconv8_2, conv8_1, f8[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv8_1[conv8_1<=0] = 0\n",
    "                conc_dconv8, df8_1, db8_1 = convolutionBackward(dconv8_1, c8, f8[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv8, dconv2_2 = crop2half(conc_dconv8)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #dconv2_2 = reshape(dconv2_2, conv2_2.shape[1])\n",
    "                \n",
    "                dconv7_2, df8_dc, db8_dc = convTranspBackward(dconv8, new_in8, fb8_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv7_2[conv7_2<=0] = 0\n",
    "                dconv7_1, df7_2, db7_2 = convolutionBackward(dconv7_2, conv7_1, f7[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv7_1[conv7_1<=0] = 0\n",
    "                conc_dconv7, df7_1, db7_1 = convolutionBackward(dconv7_1, c7, f7[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv7, dconv3_2 = crop2half(conc_dconv7)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #Make sure that dconv3_2 is the same dim with the dconv3_2 that will come from maxpool in decoding side\n",
    "                #dconv3_2 = reshape(dconv3_2, conv3_2.shape[1])\n",
    "                \n",
    "                dconv6_2, df7_dc, db7_dc = convTranspBackward(dconv7, new_in7, fb7_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv6_2[conv6_2<=0] = 0\n",
    "                dconv6_1, df6_2, db6_2 = convolutionBackward(dconv6_2, conv6_1, f6[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv7_1[conv7_1<=0] = 0\n",
    "                conc_dconv6, df6_1, db6_1 = convolutionBackward(dconv6_1, c6, f6[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv6, dconv4_2 = crop2half(conc_dconv6)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #dconv4_2 = reshape(dconv4_2, conv4_2.shape[1])\n",
    "                \n",
    "                dconv5_2, df6_dc, db6_dc = convTranspBackward(dconv6, new_in6, fb6_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv5_2[conv5_2<=0] = 0\n",
    "                dconv5_1, df5_2, db5_2 = convolutionBackward(dconv5_2, conv5_1, f5[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv5_1[conv5_1<=0] = 0\n",
    "                dpl4, df5_1, db5_1 = convolutionBackward(dconv5_1, pl4, f5[0], conv_s) #\n",
    "                \n",
    "                dconv4_2 += maxpoolBackward(dpl4, conv4_2, f=2 , s=2) #Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv4_2[conv4_2<=0] = 0\n",
    "                dconv4_1, df4_2, db4_2 = convolutionBackward(dconv4_2, conv4_1, f4[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv4_1[conv4_1<=0] = 0\n",
    "                dpl3, df4_1, db4_1 = convolutionBackward(dconv4_1, pl3, f4[0], conv_s) #\n",
    "\n",
    "                dconv3_2 += maxpoolBackward(dpl3, conv3_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv3_2[conv3_2<=0] = 0\n",
    "                dconv3_1, df3_2, db3_2 = convolutionBackward(dconv3_2, conv3_1, f3[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv3_1[conv3_1<=0] = 0\n",
    "                dpl2, df3_1, db3_1 = convolutionBackward(dconv3_1, pl2, f3[0], conv_s) #\n",
    "                \n",
    "                dconv2_2 += maxpoolBackward(dpl2, conv2_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv2_2[conv2_2<=0] = 0\n",
    "                dconv2_1, df2_2, db2_2 = convolutionBackward(dconv2_2, conv2_1, f2[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv2_1[conv2_1<=0] = 0\n",
    "                dpl1, df2_1, db2_1 = convolutionBackward(dconv2_1, pl1, f2[0], conv_s) #\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv1_2[conv1_2<=0] = 0\n",
    "                dconv1_1, df1_2, db1_2 = convolutionBackward(dconv1_2, conv1_1, f1[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv1_1[conv1_1<=0] = 0\n",
    "                _, df1_1, db1_1 = convolutionBackward(dconv1_1, X_t[b], f1[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                [df1,df2,df3,df4,df5,df6,df7,df8,df9] = df\n",
    "                [db1,db2,db3,db4,db5,db6,db7,db8,db9] = db \n",
    "                [dfb6_dc,dfb7_dc,dfb8_dc,dfb9_dc]     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                df4[0] += df4_1\n",
    "                df4[1] += df4_2\n",
    "                df5[0] += df5_1\n",
    "                df5[1] += df5_2\n",
    "                df6[0] += df6_1\n",
    "                df6[1] += df6_2\n",
    "                df7[0] += df7_1\n",
    "                df7[1] += df7_2\n",
    "                df8[0] += df8_1\n",
    "                df8[1] += df8_2\n",
    "                df9[0] += df9_1\n",
    "                df9[1] += df9_2\n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                db4[0] += db4_1\n",
    "                db4[1] += db4_2\n",
    "                db5[0] += db5_1\n",
    "                db5[1] += db5_2\n",
    "                db6[0] += db6_1\n",
    "                db6[1] += db6_2\n",
    "                db7[0] += db7_1\n",
    "                db7[1] += db7_2\n",
    "                db8[0] += db8_1\n",
    "                db8[1] += db8_2\n",
    "                db9[0] += db9_1\n",
    "                db9[1] += db9_2\n",
    "\n",
    "                dfb6_dc[0] += df6_dc\n",
    "                dfb6_dc[1] += db6_dc\n",
    "                dfb7_dc[0] += df7_dc\n",
    "                dfb7_dc[1] += db7_dc\n",
    "                dfb8_dc[0] += df8_dc\n",
    "                dfb8_dc[1] += db8_dc\n",
    "                dfb9_dc[0] += df9_dc\n",
    "                dfb9_dc[1] += db9_dc\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in range(len(filters)):\n",
    "                v_adam[i][0] = beta1*v_adam[i][0] + (1-beta1)*df[i][0]/batch_size #f1\n",
    "                s_adam[i][0] = beta2*s_adam[i][0] + (1-beta2)*(df[i][0]/batch_size)**2 #f1\n",
    "                filters[i][0] -= lr*v_adam[i][0]/np.sqrt(s_adam[i][0] + 1e-7)\n",
    "                \n",
    "                v_adam[i][1] = beta1*v_adam[i][1] + (1-beta1)*df[i][1]/batch_size #f2\n",
    "                s_adam[i][1] = beta2*s_adam[i][1] + (1-beta2)*(df[i][1]/batch_size)**2  #f2\n",
    "                filters[i][1] -= lr*v_adam[i][1]/np.sqrt(s_adam[i][1] + 1e-7)\n",
    "                \n",
    "            for i in range(len(bias)):\n",
    "                bv_adam[i][0] = beta1*bv_adam[i][0] + (1-beta1)*db[i][0]/batch_size #b1\n",
    "                bs_adam[i][0] = beta2*bs_adam[i][0] + (1-beta2)*(db[i][0]/batch_size)**2  #b1\n",
    "                bias[i][0] -= lr*bv_adam[i][0]/np.sqrt(bs_adam[i][0] + 1e-7)\n",
    "                \n",
    "                bv_adam[i][1] = beta1*bv_adam[i][1] + (1-beta1)*db[i][1]/batch_size #b2\n",
    "                bs_adam[i][1] = beta2*bs_adam[i][1] + (1-beta2)*(db[i][1]/batch_size)**2  #b2\n",
    "                bias[i][1] -= lr*bv_adam[i][1]/np.sqrt(bs_adam[i][1] + 1e-7)\n",
    "            \n",
    "            for i in range(len(f_dc)):\n",
    "                fdc_v_adam[i][0] = beta1*fdc_v_adam[i][0] + (1-beta1)*dfb[i][0]/batch_size #f1\n",
    "                fdc_s_adam[i][0] = beta2*fdc_s_adam[i][0] + (1-beta2)*(dfb[i][0]/batch_size)**2  #f1\n",
    "                f_dc[i][0] -= lr*fdc_v_adam[i][0]/np.sqrt(fdc_s_adam[i][0] + 1e-7)\n",
    "                \n",
    "                fdc_v_adam[i][1] = beta1*fdc_v_adam[i][1] + (1-beta1)*dfb[i][1]/batch_size #b2\n",
    "                fdc_s_adam[i][1] = beta2*fdc_s_adam[i][1] + (1-beta2)*(dfb[i][1]/batch_size)**2  #b2\n",
    "                f_dc[i][1] -= lr*fdc_v_adam[i][1]/np.sqrt(fdc_s_adam[i][1] + 1e-7)    \n",
    "            \n",
    "            v_out_f = beta1*v_out_f + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out_f = beta2*s_out_f + (1 - beta2)*(dout_f/batch_size)**2  #f\n",
    "            out_fb[0] -= lr*v_out_f/np.sqrt(s_out_f + 1e-7)\n",
    "            \n",
    "            bv_out_b = beta1*bv_out_b + (1 - beta1)*dout_b/batch_size #b\n",
    "            bs_out_b = beta2*bs_out_b + (1 - beta2)*(dout_b/batch_size)**2  #b\n",
    "            out_fb[1] -= lr*bv_out_b/np.sqrt(bs_out_b + 1e-7)\n",
    "            \n",
    "            \n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            #print(\"Batch:{}\".format(c+12))\n",
    "            \n",
    "            '''\n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            \n",
    "            '''\n",
    "            print(\"Cost : {:.5f}\".format(cost/batch))\n",
    "            print(\"Accuracy : {:.5f}%\".format((accuracy*100)/batch))\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        if(verbose):\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "    #pack filters\n",
    "    params_values = [filters, bias, f_dc, out_fb]\n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.01067427 0.01087591 0.01138014 0.01127339 0.01158224 0.01136116\n",
      "   0.01145947 0.01133274 0.01160238 0.0113497 ]\n",
      "  [0.01127687 0.01210756 0.01244628 0.01292397 0.0126599  0.01289461\n",
      "   0.01250211 0.01288226 0.01264701 0.01297614]\n",
      "  [0.01217266 0.01189223 0.01309227 0.01286102 0.01311547 0.01285568\n",
      "   0.01332316 0.01299581 0.01324    0.01279031]\n",
      "  [0.01231552 0.01220481 0.01325369 0.01321826 0.01343198 0.01333798\n",
      "   0.01350748 0.01322703 0.01338455 0.01343206]\n",
      "  [0.0124525  0.01222779 0.01339189 0.01312898 0.01346104 0.01348587\n",
      "   0.01347201 0.0131997  0.01354803 0.01352971]\n",
      "  [0.01219584 0.01232687 0.01312075 0.01343813 0.0133673  0.0133182\n",
      "   0.01320832 0.01345869 0.01332017 0.01345236]\n",
      "  [0.01236884 0.01217283 0.01341599 0.01328765 0.01337459 0.01309524\n",
      "   0.01367938 0.01339795 0.01338915 0.01305409]\n",
      "  [0.01225528 0.01237655 0.013172   0.01313532 0.01335991 0.0134592\n",
      "   0.0134628  0.01295291 0.01332837 0.01342714]\n",
      "  [0.01244208 0.01227558 0.01331986 0.01303798 0.01326839 0.01340075\n",
      "   0.01328844 0.01305505 0.01331427 0.01330334]\n",
      "  [0.01224786 0.01224918 0.01309926 0.01331423 0.01320476 0.01334081\n",
      "   0.01319214 0.013317   0.01329766 0.01341079]]]\n",
      "0.6939576139824524\n",
      "0.439697265625\n",
      "Cost : 0.69396\n",
      "Accuracy : 43.96973%\n",
      "Epoch:     1   -   cost: 0.69   -   Accuracy: 43.97%\n",
      "Epoch: {2}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[-1.10852422e+10 -2.17343372e+10 -2.99227956e+10 -3.79000543e+10\n",
      "   -4.37259413e+10 -5.56216782e+10 -5.79562957e+10 -7.11640687e+10\n",
      "   -7.10498901e+10 -8.65238069e+10]\n",
      "  [-3.16933387e+10 -5.78143472e+10 -8.25695845e+10 -9.91577183e+10\n",
      "   -1.20052165e+11 -1.44254490e+11 -1.58838837e+11 -1.81836594e+11\n",
      "   -1.92746215e+11 -2.22028508e+11]\n",
      "  [-3.95430305e+10 -7.58254789e+10 -1.05184256e+11 -1.30719983e+11\n",
      "   -1.52372895e+11 -1.89774972e+11 -2.02932191e+11 -2.39743648e+11\n",
      "   -2.45316633e+11 -2.91214445e+11]\n",
      "  [-6.70910430e+10 -1.21463250e+11 -1.74825406e+11 -2.06298492e+11\n",
      "   -2.52516173e+11 -2.97561546e+11 -3.35334312e+11 -3.73360845e+11\n",
      "   -4.03800307e+11 -4.54287671e+11]\n",
      "  [-6.49181255e+10 -1.23326989e+11 -1.71234233e+11 -2.10202912e+11\n",
      "   -2.46595927e+11 -3.03999604e+11 -3.28871119e+11 -3.82489701e+11\n",
      "   -3.95600611e+11 -4.64743454e+11]\n",
      "  [-9.72399124e+10 -1.75797456e+11 -2.53042624e+11 -2.97255932e+11\n",
      "   -3.63970251e+11 -4.26863433e+11 -4.83865774e+11 -5.35550367e+11\n",
      "   -5.81567138e+11 -6.50376650e+11]\n",
      "  [-8.85283057e+10 -1.67278943e+11 -2.31968944e+11 -2.83358440e+11\n",
      "   -3.32861783e+11 -4.08372447e+11 -4.42219504e+11 -5.11629814e+11\n",
      "   -5.31168199e+11 -6.21891320e+11]\n",
      "  [-1.27831605e+11 -2.30795980e+11 -3.31458973e+11 -3.88272537e+11\n",
      "   -4.74996335e+11 -5.55536694e+11 -6.29452610e+11 -6.93962117e+11\n",
      "   -7.54394124e+11 -8.42038846e+11]\n",
      "  [-1.12783503e+11 -2.12497744e+11 -2.94720393e+11 -3.58349985e+11\n",
      "   -4.21057965e+11 -5.14467078e+11 -5.58571691e+11 -6.42895150e+11\n",
      "   -6.68655988e+11 -7.80414649e+11]\n",
      "  [-1.56950382e+11 -2.83074580e+11 -4.06247994e+11 -4.74651138e+11\n",
      "   -5.80533870e+11 -6.77258063e+11 -7.69306570e+11 -8.46191602e+11\n",
      "   -9.21239466e+11 -1.02528406e+12]]]\n",
      "0.5831570995318439\n",
      "0.5382080078125\n",
      "Cost : 0.58316\n",
      "Accuracy : 53.82080%\n",
      "Epoch:     2   -   cost: 0.58   -   Accuracy: 53.82%\n",
      "Epoch: {3}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[1.10371388e+19 1.84636910e+19 2.64145717e+19 3.17415374e+19\n",
      "   3.80967299e+19 4.28686121e+19 4.80719604e+19 5.18666422e+19\n",
      "   5.62736744e+19 6.02808038e+19]\n",
      "  [1.61912346e+19 2.72925953e+19 3.89631868e+19 4.69888857e+19\n",
      "   5.63046905e+19 6.36110490e+19 7.12657410e+19 7.68913634e+19\n",
      "   8.33730996e+19 8.94899268e+19]\n",
      "  [2.01193841e+19 3.49566315e+19 5.00202791e+19 6.08105595e+19\n",
      "   7.28296544e+19 8.28204534e+19 9.25975478e+19 1.00219544e+20\n",
      "   1.08431760e+20 1.16879576e+20]\n",
      "  [2.45220918e+19 4.18458751e+19 5.98742689e+19 7.24116412e+19\n",
      "   8.69109773e+19 9.84410687e+19 1.10388921e+20 1.19060737e+20\n",
      "   1.29201601e+20 1.38781486e+20]\n",
      "  [2.77459299e+19 4.83709774e+19 6.92994453e+19 8.43442256e+19\n",
      "   1.01131837e+20 1.15161577e+20 1.28859234e+20 1.39454275e+20\n",
      "   1.50961810e+20 1.62776645e+20]\n",
      "  [3.08998268e+19 5.30567441e+19 7.60652944e+19 9.21486106e+19\n",
      "   1.10760175e+20 1.25655237e+20 1.41035512e+20 1.52118560e+20\n",
      "   1.65174231e+20 1.77498251e+20]\n",
      "  [3.29000427e+19 5.74777270e+19 8.24641882e+19 1.00487398e+20\n",
      "   1.20608041e+20 1.37534551e+20 1.53993318e+20 1.66664490e+20\n",
      "   1.80475111e+20 1.94706568e+20]\n",
      "  [3.61624908e+19 6.21812726e+19 8.92358164e+19 1.08195153e+20\n",
      "   1.30150089e+20 1.47796581e+20 1.65968531e+20 1.79028034e+20\n",
      "   1.94446035e+20 2.09024614e+20]\n",
      "  [3.87550483e+19 6.77032402e+19 9.71371578e+19 1.18367718e+20\n",
      "   1.42118836e+20 1.62090672e+20 1.81533079e+20 1.96486935e+20\n",
      "   2.12809387e+20 2.29584234e+20]\n",
      "  [4.12386881e+19 7.10599822e+19 1.02020269e+20 1.23743665e+20\n",
      "   1.48914111e+20 1.69172087e+20 1.90021614e+20 2.04978574e+20\n",
      "   2.22673121e+20 2.39390040e+20]]]\n",
      "0.8167474766695707\n",
      "0.439697265625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4834ff09834c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mparams_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.41\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#0.05 stable LR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-75ee4a77ef2d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, Y, epochs, learning_rate, dropout, verbose, callback)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m#pack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mdconv9_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv9_1\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mconc_dconv9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf9_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb9_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolutionBackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdconv9_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf9\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_s\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#C9 is not needed for input,we know how to select the right gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;31m###### we get the concat gradients ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-dba706f20d36>\u001b[0m in \u001b[0;36mconvolutionBackward\u001b[0;34m(dconv_prev, conv_in, filt, s, pad)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m#each entry of the dconv_prev will try to affect the idxs from which was made of.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mdfilt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdconv_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconv_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0mdconv_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdconv_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdconv_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#, axis =1) ## AXIS?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values = train(train_images, train_labels, 10, 0.01, True) #0.05 stable LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d1175c062e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m###### Prediction ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mYt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtemp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "###### Prediction ######\n",
    "Yt = test_labels.T\n",
    "temp1 = []\n",
    "for i in range(Yt.shape[1]):\n",
    "        for j in range(Yt.shape[0]):\n",
    "            if(Yt[j][i]==1):\n",
    "                temp1.append(j)\n",
    "Yt=np.array(temp1)\n",
    "Y_test_hat, _ = full_forward_propagation(np.transpose(test_images), params_values, NN_ARCHITECTURE)#multiple?!\n",
    "\n",
    "Yht = np.array(Y_test_hat.T)\n",
    "#x_log=np.log( np.exp(Yh) / np.sum(np.exp(Yh), axis = 1) )  #(60000,10) , we need to add along columns so we get sum of 1 on every example-row\n",
    "num = np.exp(Yht)\n",
    "den = np.sum(np.exp(Yht), axis = 1)\n",
    "for i in range(Yht.shape[0]): #60000\n",
    "                #for j in range(Yh.shape[1]): #10\n",
    "                Yht[i][:] = np.log(num[i][:] / den[i])  \n",
    "\n",
    "#cost = get_cost_value(Yht, Yt)\n",
    "\n",
    "#cost_history.append(cost)\n",
    "accuracy = get_accuracy_value(Y_test_hat, test_labels.T)\n",
    "#accuracy_history.append(accuracy)\n",
    "print(\"Accuracy: {:.5f}%\".format( accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
