{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load from /home/USER/data/mnist or elsewhere; download if missing.\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\salt\n",
    "        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    #os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\"\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "    \"\"\"\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/images/\"\n",
    "        onlyfiles = [cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,101,101).astype('float32')/255\n",
    "        return pixels\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        \n",
    "        folder = path + \"/labels/\"\n",
    "        onlyfiles = [image.imread(folder+f) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,101,101).astype('float32')/255\n",
    "        return pixels\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(path)\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(path)\n",
    "    \"\"\"\"\n",
    "    print(\"Test Images  : Loading . . .\")\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    print(\"Test Labels  : Loading . . .\")\n",
    "    test_labels = _labels(os.path.join(path, files[3])) \n",
    "    \"\"\"\n",
    "    print(\"Done!\")\n",
    "    return train_images , train_labels #, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 1, 101, 101)\n",
      "(4000, 1, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape) # ONE-HOT !!!\n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Convolution Architecture - Downsampling/Upsampling  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f ):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    trim = 0.1\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trim\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trim\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trim #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trim\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trim\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trim\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trim\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \n",
    "    return filters, bias, f_dc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "    \n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] * f[z, :, :, :]) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s, pad = 1 ):\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "\n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//s + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 3x3 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "    #print(arr.shape)\n",
    "    try:\n",
    "        idx = np.nanargmax(arr)\n",
    "        #print (idx)\n",
    "    except:\n",
    "        idx = 0\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h + a, _w + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def NLLLoss(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[1]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] == 1):\n",
    "                out[:,i,j] = logs[:,i,j] #in that case the propab. is correct with targen being the 1\n",
    "            else:\n",
    "                out[:,i,j] = 1 - logs[:,i,j] # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    return out.sum()/mylen\n",
    "\n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, verbose=True, callback=None):\n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    \n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    filters,bias, f_dc = init_filters(5,16) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "    \n",
    "    #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    \n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]\n",
    "    for i in filters:     \n",
    "        v1 = np.zeros(i[0].shape)\n",
    "        v2 = np.zeros(i[1].shape)\n",
    "        s1 = np.zeros(i[0].shape)\n",
    "        s2 = np.zeros(i[1].shape)\n",
    "        v_a = [v1, v2]\n",
    "        s_a = [s1, s2]\n",
    "        v_adam.append(v_a)\n",
    "        s_adam.append(s_a)\n",
    "            \n",
    "    for i in bias:\n",
    "        bv1 = np.zeros(i[0].shape)\n",
    "        bv2 = np.zeros(i[1].shape)\n",
    "        bs1 = np.zeros(i[0].shape)\n",
    "        bs2 = np.zeros(i[1].shape)    \n",
    "        bv_a = [bv1, bv2]\n",
    "        bs_a = [bs1, bs2]\n",
    "        bv_adam.append(bv_a)\n",
    "        bs_adam.append(bs_a)\n",
    "    \n",
    "    for i in f_dc:\n",
    "        fdc_v1 = np.zeros(i[0].shape)\n",
    "        bdc_v2 = np.zeros(i[1].shape)\n",
    "        fdc_s1 = np.zeros(i[0].shape)\n",
    "        bdc_s2 = np.zeros(i[1].shape)    \n",
    "        fdc_v_a = [fdc_v1, bdc_v2]\n",
    "        fdc_s_a = [fdc_s1, bdc_s2]\n",
    "        fdc_v_adam.append(fdc_v_a)\n",
    "        fdc_s_adam.append(fdc_s_a)\n",
    "    \n",
    "    #Final layer 1x1 filter setup\n",
    "    out_f = np.random.randn(1,16,1,1)*0.1\n",
    "    out_b = np.random.randn(out_f.shape[0],1)*0.1\n",
    "    \n",
    "    v_out_f = np.zeros(out_f.shape)\n",
    "    s_out_f = np.zeros(out_f.shape)\n",
    "    bv_out_b = np.zeros(out_b.shape)\n",
    "    bs_out_b = np.zeros(out_b.shape)\n",
    "    out_fb = [out_f, out_b]\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7,f8,f9] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "    [fb6_dc, fb7_dc, fb8_dc, fb9_dc] = f_dc\n",
    "    \n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        batch = 12\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            \n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.95\n",
    "            beta2= 0.99\n",
    "            lr = learning_rate\n",
    "            batch_size= batch\n",
    "            \n",
    "            df =  []\n",
    "            db =  []\n",
    "            dfb=  []\n",
    "            for i in filters:\n",
    "                df1 = np.zeros(i[0].shape)\n",
    "                df2 = np.zeros(i[1].shape)\n",
    "                f_temp = [df1, df2]\n",
    "                df.append(f_temp)\n",
    "                \n",
    "            for i in bias:\n",
    "                db1 = np.zeros(i[0].shape)\n",
    "                db2 = np.zeros(i[1].shape)\n",
    "                b_temp = [db1, db2]\n",
    "                db.append(b_temp)\n",
    "            \n",
    "            for i in f_dc:\n",
    "                df1 = np.zeros(i[0].shape)\n",
    "                db1 = np.zeros(i[1].shape)\n",
    "                fb_dc = [df1, db1]\n",
    "                dfb.append(fb_dc)\n",
    "                \n",
    "            dout_f = np.zeros(out_f.shape)\n",
    "            dout_b = np.zeros(out_b.shape)\n",
    "            ######################################\n",
    "            \n",
    "            \n",
    "            #timestamp1 = time.time()\n",
    "            \n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            cost = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            [df1,df2,df3,df4,df5,df6,df7,df8,df9] = df\n",
    "            [db1,db2,db3,db4,db5,db6,db7,db8,db9] = db \n",
    "            [dfb6_dc,dfb7_dc,dfb8_dc,dfb9_dc]     = dfb\n",
    "            \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print(b)\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                params = [f1[0], b1[0]]  \n",
    "                conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "                conv1_1[conv1_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f1[1], b1[1]]\n",
    "                conv1_2 = conv(conv1_1, params, 1)\n",
    "                conv1_2[conv1_2<=0] = 0 #Relu\n",
    "                ##################################### conv1_2: 101x101x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (101-2)/2+1  = 50 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f2[0], b2[0]]  \n",
    "                conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv2_1[conv2_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f2[1], b2[1]]\n",
    "                conv2_2 = conv(conv2_1, params, 1)\n",
    "                conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "                #####################################  50x50x32\n",
    "\n",
    "                pl2 = maxpool(conv2_2, 2, 2) #pool_f = 2 , pool_s = 2    , (50 -2)/2 +1 = 25\n",
    "                ## ADD DROPOUT HERE\n",
    "\n",
    "                ########### 3rd Big Layer ###########\n",
    "                params = [f3[0], b3[0]]  \n",
    "                conv3_1 = conv(pl2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f3[1], b3[1]]\n",
    "                conv3_2 = conv(conv3_1, params, 1)\n",
    "                conv3_2[conv3_2<=0] = 0 #Relu             \n",
    "                #####################################  25x25x64\n",
    "\n",
    "                pl3 = maxpool(conv3_2, 2, 2) #pool_f = 2 , pool_s = 2   ,  (25-2)/2 +1 = 12\n",
    "                ## ADD DROPOUT HERE\n",
    "                \n",
    "                ########### 4th Big Layer ###########\n",
    "                params = [f4[0], b4[0]]  \n",
    "                conv4_1 = conv(pl3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv4_1[conv4_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f4[1], b4[1]]\n",
    "                conv4_2 = conv(conv4_1, params, 1)\n",
    "                conv4_2[conv4_2<=0] = 0 #Relu             \n",
    "                #####################################     12x12x128\n",
    "\n",
    "                pl4 = maxpool(conv4_2, 2, 2) #pool_f = 2 , pool_s = 2  , (12-2)/2 +1 =6  : 6x6x128\n",
    "                ## ADD DROPOUT HERE\n",
    "                \n",
    "                ########### 5th Big Layer ###########   6x6x128-->6x6x256\n",
    "                params = [f5[0], b5[0]]  \n",
    "                conv5_1 = conv(pl4, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv5_1[conv5_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f5[1], b5[1]]\n",
    "                conv5_2 = conv(conv5_1, params, 1)\n",
    "                conv5_2[conv5_2<=0] = 0 #Relu             \n",
    "                #####################################  6x6x256\n",
    "                \n",
    "                #####################################\n",
    "                #Because of ambigious size after the upsampling the concat func must take care possible crop of the conv#_2 \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "                params = [fb6_dc[0], fb6_dc[1]] # deconv filter, deconv bias\n",
    "                dc6, new_in6 = convTransp(conv5_2, params, 1, 0)   #result:   =  12x12x128 , # conv5_2 requires NO crop\n",
    "                #Concat dc6 with conv4_2 so we get 256 channels (12x12x256)\n",
    "                c6 = concat(dc6, conv4_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          12x12x256     \n",
    "                params = [f6[0], b6[0]]  \n",
    "                conv6_1 = conv(c6, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv6_1[conv6_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f6[1], b6[1]]\n",
    "                conv6_2 = conv(conv6_1, params, 1)\n",
    "                conv6_2[conv6_2<=0] = 0 #Relu   \n",
    "                #####################################    12x12x128\n",
    "                #(12-1)*2 + 2 =24\n",
    "                params = [fb7_dc[0], fb7_dc[1]] # deconv filter, deconv bias\n",
    "                dc7, new_in7 = convTransp(conv6_2, params, 1, 0)   #result:   =  24x24x64\n",
    "                #Concat dc7 with conv3_2 so we get  channels (24x24x128)\n",
    "                c7 = concat(dc7, conv3_2)   #crop is required\n",
    "                \n",
    "                ########### 2nd Big dc Layer ###########          24x24x128     \n",
    "                params = [f7[0], b7[0]]  \n",
    "                conv7_1 = conv(c7, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv7_1[conv7_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f7[1], b7[1]]\n",
    "                conv7_2 = conv(conv7_1, params, 1)\n",
    "                conv7_2[conv7_2<=0] = 0 #Relu     \n",
    "                #####################################    24x24x64\n",
    "                #(24-1)*2 + 2 = 48\n",
    "                params = [fb8_dc[0], fb8_dc[1]] # deconv filter, deconv bias\n",
    "                dc8, new_in8 = convTransp(conv7_2, params, 1, 0)   #result:   =  48x48x32\n",
    "                #Concat dc8 with conv2_2 so we get  channels (48x48x64)\n",
    "                c8 = concat(dc8 ,conv2_2)   #crop is required\n",
    "                \n",
    "                ########### 3rd Big dc Layer ###########          48x48x64    \n",
    "                params = [f8[0], b8[0]]  \n",
    "                conv8_1 = conv(c8, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv8_1[conv8_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f8[1], b8[1]]\n",
    "                conv8_2 = conv(conv8_1, params, 1)\n",
    "                conv8_2[conv8_2<=0] = 0 #Relu    \n",
    "                #####################################    48x48x32                              \n",
    "                #(48-1)*2 + 2 = 96\n",
    "                params = [fb9_dc[0], fb9_dc[1]] # deconv filter, deconv bias\n",
    "                dc9, new_in9 = convTransp(conv8_2, params, 1, 0)   #result:   =  96x96x16\n",
    "                #Concat dc9 with conv1_2 so we get  channels (96x96x32)\n",
    "                c9 = concat(dc9, conv1_2)   #crop is required                \n",
    "               \n",
    "                ########### 4th Big dc Layer ###########          96x96x32   \n",
    "                params = [f9[0], b9[0]]  \n",
    "                conv9_1 = conv(c9, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv9_1[conv9_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f9[1], b9[1]]\n",
    "                conv9_2 = conv(conv9_1, params, 1)\n",
    "                conv9_2[conv9_2<=0] = 0 #Relu   \n",
    "                #####################################    96x96x16\n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 96x96x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv9_2, params, 1, 0) #output.shape: 96x96x1\n",
    "                \n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                \n",
    "                #label crop is needed\n",
    "                Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                cost += NLLLoss(Y_hat, Y_t_b)\n",
    "                print(cost)\n",
    "                \n",
    "                accuracy += get_accuracy_value(Y_hat, Y_t_b)\n",
    "                \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t_b\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv9_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv9_2, out_f, conv_s) #\n",
    "                #pack data\n",
    "                \n",
    "                \n",
    "                dconv9_2[conv9_2<=0] = 0             \n",
    "                dconv9_1, df9_2, db9_2 = convolutionBackward(dconv9_2, conv9_1, f9[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv9_1[conv9_1<=0] = 0\n",
    "                conc_dconv9, df9_1, db9_1 = convolutionBackward(dconv9_1, c9, f9[0], conv_s) #C9 is not needed for input,we know how to select the right gradients\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv9, dconv1_2 = crop2half(conc_dconv9)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                \n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                dconv8_2, df9_dc, db9_dc = convTranspBackward(dconv9, new_in9, f9_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv8_2[conv8_2<=0] = 0\n",
    "                dconv8_1, df8_2, db8_2 = convolutionBackward(dconv8_2, conv8_1, f8[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv8_1[conv8_1<=0] = 0\n",
    "                conc_dconv8, df8_1, db8_1 = convolutionBackward(dconv8_1, c8, f8[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv8, dconv2_2 = crop2half(conc_dconv8)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                \n",
    "                dconv7_2, df8_dc, db8_dc = convTranspBackward(dconv8, new_in8, f8_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv7_2[conv7_2<=0] = 0\n",
    "                dconv7_1, df7_2, db7_2 = convolutionBackward(dconv7_2, conv7_1, f7[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv7_1[conv7_1<=0] = 0\n",
    "                conc_dconv7, df7_1, db7_1 = convolutionBackward(dconv7_1, c7, f7[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv7, dconv3_2 = crop2half(conc_dconv7)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                \n",
    "                dconv6_2, df7_dc, db7_dc = convTranspBackward(dconv7, new_in7, f7_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv6_2[conv6_2<=0] = 0\n",
    "                dconv6_1, df6_2, db6_2 = convolutionBackward(dconv6_2, conv6_1, f6[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv7_1[conv7_1<=0] = 0\n",
    "                conc_dconv6, df6_1, db6_1 = convolutionBackward(dconv6_1, c6, f6[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv6, dconv4_2 = crop2half(conc_dconv6)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                \n",
    "                dconv5_2, df6_dc, db6_dc = convTranspBackward(dconv6, new_in6, f6_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv5_2[conv5_2<=0] = 0\n",
    "                dconv5_1, df5_2, db5_2 = convolutionBackward(dconv5_2, conv5_1, f5[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv5_1[conv5_1<=0] = 0\n",
    "                dpl4, df5_1, db5_1 = convolutionBackward(dconv5_1, pl4, f5[0], conv_s) #\n",
    "                \n",
    "                dconv4_2 += maxpoolBackward(dpl4, conv4_2, f=2 , s=2) #Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv4_2[conv4_2<=0] = 0\n",
    "                dconv4_1, df4_2, db4_2 = convolutionBackward(dconv4_2, conv4_1, f4[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv4_1[conv4_1<=0] = 0\n",
    "                dpl3, df4_1, db4_1 = convolutionBackward(dconv4_1, pl3, f4[0], conv_s) #\n",
    "                \n",
    "                dconv3_2 += maxpoolBackward(dpl3, conv3_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv3_2[conv3_2<=0] = 0\n",
    "                dconv3_1, df3_2, db3_2 = convolutionBackward(dconv3_2, conv3_1, f3[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv3_1[conv3_1<=0] = 0\n",
    "                dpl2, df3_1, db3_1 = convolutionBackward(dconv3_1, pl2, f3[0], conv_s) #\n",
    "                \n",
    "                dconv2_2 += maxpoolBackward(dpl2, conv2_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv2_2[conv2_2<=0] = 0\n",
    "                dconv2_1, df2_2, db2_2 = convolutionBackward(dconv2_2, conv2_1, f2[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv2_1[conv2_1<=0] = 0\n",
    "                dpl1, df2_1, db2_1 = convolutionBackward(dconv2_1, pl1, f2[0], conv_s) #\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                dconv1_2[conv1_2<=0] = 0\n",
    "                dconv1_1, df1_2, db1_2 = convolutionBackward(dconv1_2, conv1_1, f1[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv1_1[conv1_1<=0] = 0\n",
    "                _, df1_1, db1_1 = convolutionBackward(dconv1_1, X_t[b], f1[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                [df1,df2,df3,df4,df5,df6,df7,df8,df9] = df\n",
    "                [db1,db2,db3,db4,db5,db6,db7,db8,db9] = db \n",
    "                [dfb6_dc,dfb7_dc,dfb8_dc,dfb9_dc]     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                df4[0] += df4_1\n",
    "                df4[1] += df4_2\n",
    "                df5[0] += df5_1\n",
    "                df5[1] += df5_2\n",
    "                df6[0] += df6_1\n",
    "                df6[1] += df6_2\n",
    "                df7[0] += df7_1\n",
    "                df7[1] += df7_2\n",
    "                df8[0] += df8_1\n",
    "                df8[1] += df8_2\n",
    "                df9[0] += df9_1\n",
    "                df9[1] += df9_2\n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                db4[0] += db4_1\n",
    "                db4[1] += db4_2\n",
    "                db5[0] += db5_1\n",
    "                db5[1] += db5_2\n",
    "                db6[0] += db6_1\n",
    "                db6[1] += db6_2\n",
    "                db7[0] += db7_1\n",
    "                db7[1] += db7_2\n",
    "                db8[0] += db8_1\n",
    "                db8[1] += db8_2\n",
    "                db9[0] += db9_1\n",
    "                db9[1] += db9_2\n",
    "\n",
    "                dfb6_dc[0] += df6_dc\n",
    "                dfb6_dc[1] += db6_dc\n",
    "                dfb7_dc[0] += df7_dc\n",
    "                dfb7_dc[1] += db7_dc\n",
    "                dfb8_dc[0] += df8_dc\n",
    "                dfb8_dc[1] += db8_dc\n",
    "                dfb9_dc[0] += df9_dc\n",
    "                dfb9_dc[1] += db9_dc\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in filter:\n",
    "                v_adam[i,0] = beta1*v_adam[i,0] + (1-beta1)*df[i,0]/batch_size #f1\n",
    "                s_adam[i,0] = beta2*s_adam[i,0] + (1-beta2)*df[i,0]/batch_size #f1\n",
    "                filters[i,0] -= lr*v_adam[i,0]/np.sqrt(s_adam[i,0] + 1e-7)\n",
    "                \n",
    "                v_adam[i,1] = beta1*v_adam[i,1] + (1-beta1)*df[i,1]/batch_size #f2\n",
    "                s_adam[i,1] = beta2*s_adam[i,1] + (1-beta2)*df[i,1]/batch_size #f2\n",
    "                filters[i,1] -= lr*v_adam[i,1]/np.sqrt(s_adam[i,1] + 1e-7)\n",
    "                \n",
    "            for i in bias:\n",
    "                bv_adam[i,0] = beta1*bv_adam[i,0] + (1-beta1)*db[i,0]/batch_size #b1\n",
    "                bs_adam[i,0] = beta2*bs_adam[i,0] + (1-beta2)*db[i,0]/batch_size #b1\n",
    "                bias[i,0] -= lr*bv_adam[i,0]/np.sqrt(bs_adam[i,0] + 1e-7)\n",
    "                \n",
    "                bv_adam[i,1] = beta1*bv_adam[i,1] + (1-beta1)*db[i,1]/batch_size #b2\n",
    "                bs_adam[i,1] = beta2*bs_adam[i,1] + (1-beta2)*db[i,1]/batch_size #b2\n",
    "                bias[i,1] -= lr*bv_adam[i,1]/np.sqrt(bs_adam[i,1] + 1e-7)\n",
    "            \n",
    "            for i in f_dc:\n",
    "                fdc_v_adam[i,0] = beta1*fdc_v_adam[i,0] + (1-beta1)*dfb[i,0]/batch_size #f1\n",
    "                fdc_s_adam[i,0] = beta2*fdc_s_adam[i,0] + (1-beta2)*dfb[i,0]/batch_size #f1\n",
    "                f_dc[i,0] -= lr*bv_adam[i,0]/np.sqrt(bs_adam[i,0] + 1e-7)\n",
    "                \n",
    "                fdc_v_adam[i,1] = beta1*fdc_v_adam[i,1] + (1-beta1)*dfb[i,1]/batch_size #b2\n",
    "                fdc_s_adam[i,1] = beta2*fdc_s_adam[i,1] + (1-beta2)*dfb[i,1]/batch_size #b2\n",
    "                f_dc[i,1] -= lr*fdc_v_adam[i,1]/np.sqrt(fdc_s_adam[i,1] + 1e-7)    \n",
    "            \n",
    "            v_out = beta1*v_out + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out = beta2*s_out + (1 - beta2)*dout_f/batch_size #f\n",
    "            out_f -= lr*v_out/np.sqrt(s_out + 1e-7)\n",
    "            \n",
    "            bv_out = beta1*bv_out + (1 - beta1)*dout_b/batch_size #f\n",
    "            bs_out = beta2*bs_out + (1 - beta2)*dout_b/batch_size #f\n",
    "            out_b -= lr*bv_out/np.sqrt(bs_out + 1e-7)\n",
    "            \n",
    "            \n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            print(c)\n",
    "            \n",
    "            '''\n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            \n",
    "            '''\n",
    "            print(\"Cost : {:.5f}\".format(cost/batch))\n",
    "            print(\"Accuracy : {:.5f}%\".format((accuracy*100)/batch))\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        if(verbose):\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "            \n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {1}\n",
      "0\n",
      "0.8058720337202767\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f9_dc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-67bfd28b9d31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mparams_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#0.05 stable LR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-41590df60571>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, Y, epochs, learning_rate, dropout, verbose, callback)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m#conv8_2 is not needed for input,we know how to select the right gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0mdconv8_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf9_dc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb9_dc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvTranspBackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdconv9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_in9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf9_dc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m                 \u001b[0;31m#pack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f9_dc' is not defined"
     ]
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values = train(train_images, train_labels, 2, 0.01, True) #0.05 stable LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Prediction ######\n",
    "Yt = test_labels.T\n",
    "temp1 = []\n",
    "for i in range(Yt.shape[1]):\n",
    "        for j in range(Yt.shape[0]):\n",
    "            if(Yt[j][i]==1):\n",
    "                temp1.append(j)\n",
    "Yt=np.array(temp1)\n",
    "Y_test_hat, _ = full_forward_propagation(np.transpose(test_images), params_values, NN_ARCHITECTURE)#multiple?!\n",
    "\n",
    "Yht = np.array(Y_test_hat.T)\n",
    "#x_log=np.log( np.exp(Yh) / np.sum(np.exp(Yh), axis = 1) )  #(60000,10) , we need to add along columns so we get sum of 1 on every example-row\n",
    "num = np.exp(Yht)\n",
    "den = np.sum(np.exp(Yht), axis = 1)\n",
    "for i in range(Yht.shape[0]): #60000\n",
    "                #for j in range(Yh.shape[1]): #10\n",
    "                Yht[i][:] = np.log(num[i][:] / den[i])  \n",
    "\n",
    "#cost = get_cost_value(Yht, Yt)\n",
    "\n",
    "#cost_history.append(cost)\n",
    "accuracy = get_accuracy_value(Y_test_hat, test_labels.T)\n",
    "#accuracy_history.append(accuracy)\n",
    "print(\"Accuracy: {:.5f}%\".format( accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
