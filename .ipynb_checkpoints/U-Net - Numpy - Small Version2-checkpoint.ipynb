{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\salt\n",
    "        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    #os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\"\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "    \"\"\"\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/images/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(32, 32)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,32,32).astype('float32')#/255\n",
    "        return pixels[:1,:,:,:]\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        \n",
    "        folder = path + \"/labels/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(32, 32)) for f in os.listdir(folder)]\n",
    "        #onlyfiles = [cv2.resize(image.imread(folder+f),(32, 32)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,32,32).astype('float32') #/255\n",
    "        return pixels[:1,:,:,:]\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(path)\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(path)\n",
    "    \"\"\"\"\n",
    "    print(\"Test Images  : Loading . . .\")\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    print(\"Test Labels  : Loading . . .\")\n",
    "    test_labels = _labels(os.path.join(path, files[3])) \n",
    "    \"\"\"\n",
    "    print(\"Done!\")\n",
    "    return train_images, train_labels #, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 32, 32)\n",
      "(1, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "#train_images=cv2.resize(train_images[0,:,:], (32,32)).reshape(1,1,32,32)\n",
    "print(train_images.shape)\n",
    "#train_labels = train_images\n",
    "print(train_labels.shape) # ONE-HOT !!!\n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "#plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_labels[0].squeeze(), cmap=plt.get_cmap('gray'), vmin=0, vmax=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Convolution Architecture - Downsampling/Upsampling  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f ,trim):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    \n",
    "    trimf = trim\n",
    "    trimb = trim*5\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    \"\"\"\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trimf #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trimb\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \"\"\"\n",
    "    trimbr = trim\n",
    "    locbr = 0\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.normal(loc = locbr, scale = trimbr , size = f1) #np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.normal(loc = locbr, scale = trimbr , size = (f1.shape[0],1)) #np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.normal(loc = locbr, scale = trimbr , size = f2)\n",
    "        b2 = np.random.normal(loc = locbr, scale = trimbr , size = (f2.shape[0],1))\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc =  np.random.normal(loc = locbr, scale = trimbr , size = (n_f,ch_in,2,2))#upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.normal(loc = locbr, scale = trimbr , size = (fdc.shape[0],1))\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.normal(loc = locbr, scale = trimbr , size = (n_f, ch_in, 3, 3))\n",
    "        b1 = np.random.normal(loc = locbr, scale = trimbr , size = (f1.shape[0],1))\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.normal(loc = locbr, scale = trimbr , size = f2)\n",
    "        b2 = np.random.normal(loc = locbr, scale = trimbr , size = (f2.shape[0],1))\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "    return filters, bias, f_dc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "\n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(np.multiply(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] , f[z, :, :, :])) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    #filt =np.rot90(filt, 2)  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!! A T T E N T I O N !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "def convTransp1(image, params, s = 2, pad = 1):\n",
    "    [f, b] = params\n",
    "    n_f, n_c, f_s, _ = f.shape\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2\n",
    "    res = np.zeros((n_f, target_dim, target_dim))\n",
    "    temp =np.zeros((n_c, target_dim, target_dim))\n",
    "    for z in range(n_f):\n",
    "        for _h in range(input_s):      \n",
    "            for _w in range(input_s):\n",
    "                temp[:, _h*s:_h*s+f_s, _w*s:_w*s+f_s] += image[:, _h, _w].reshape(n_c,1,1)*f[z,:,:,:] #bias will be added at the end\n",
    "        res[z] = np.sum(temp , axis = 0) + b[z]\n",
    "    return res, image\n",
    "\n",
    "def convTranspBackward1(dconv_prev, new_in, filt, s = 2):\n",
    "    n_f, n_c, f_s, _ = filt.shape\n",
    "    _, input_s, _ = new_in.shape\n",
    "    #final_dim = (new_in.shape[1] - 2)//2 + 1 \n",
    "    dc_s=dconv_prev.shape[1]\n",
    "    temp = np.zeros((n_c,dc_s,dc_s))\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    dconv_in = np.zeros(new_in.shape)\n",
    "    db = np.zeros((n_f,1))\n",
    "    for z in range(n_f):\n",
    "        for _h in range(input_s):      \n",
    "            for _w in range(input_s): \n",
    "                dfilt[z] += dconv_prev[z, _h*s:_h*s+f_s, _w*s:_w*s+f_s]*new_in[:,_h,_w].reshape(n_c,1,1)\n",
    "                temp[:, _h*s:_h*s+f_s, _w*s:_w*s+f_s] += dconv_prev[z, _h*s:_h*s+f_s, _w*s:_w*s+f_s] * filt[z]\n",
    "                for ch in range(n_c):\n",
    "                    dconv_in[ch, _h, _w] += np.sum(temp[ch, _h*s:_h*s+f_s, _w*s:_w*s+f_s])\n",
    "        db[z] = np.sum(dconv_prev[z])        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "    \n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    [f, b]=params\n",
    "    f = np.rot90(f, 1, (2,3))\n",
    "    params = [f, b]\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    \n",
    "    ### OR just: np.pad(image[:,:,:],2,'constant') # Important, we must loop with respect to the 1st dim\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "    #print(arr.shape)\n",
    "    try:\n",
    "        idx = np.nanargmax(arr)\n",
    "        #print (idx)\n",
    "    except:\n",
    "        idx = 0\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h + a, _w + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "        print(\"Warning: Extra crop needed and handled!(%d --> %d)\" %(dim, img2.shape[1]))\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def Cross_Entropy(logs, targets):  # Pixel-Wise Cross entropy --> average accuracy\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[2]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] >= logs[:,i,j]):#Gray and above\n",
    "                out[:,i,j] = logs[:,i,j]/targets[:,i,j] \n",
    "            else:\n",
    "                out[:,i,j] = (1 - logs[:,i,j])/(1 - targets[:,i,j]) # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    res =out.sum()/mylen\n",
    "    return -np.log(res),res\n",
    "\n",
    "\n",
    "def Dice_Coef(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[2]\n",
    "    #Apply Dice coefficient\n",
    "    numerator = (logs*targets)\n",
    "    denominator = logs + targets\n",
    "    loss = 1 - (2*np.sum(numerator))/(np.sum(denominator))\n",
    "    return loss, np.exp(-loss)\n",
    "                \n",
    "    \n",
    "    \n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "def normalize(output):\n",
    "    output[output<-4]=-4\n",
    "    output[output>4] = 4\n",
    "    return output\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validate(X, Y, params):\n",
    "    ### Unpacking ###\n",
    "    [filters, bias, f_dc, out_fb] = params\n",
    "    [f1,f2,f3,f4,f5] = filters\n",
    "    [b1,b2,b3,b4,b5]= bias \n",
    "    f1_dc = f_dc[0][0]\n",
    "    b1_dc = f_dc[0][1]\n",
    "    f2_dc = f_dc[1][0]\n",
    "    b2_dc = f_dc[1][1]\n",
    "    [out_f, out_b] = out_fb\n",
    "    #################\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Calculating Forward step . . .')\n",
    "    \n",
    "    batch = 1\n",
    "    for c in range(0, X.shape[0], batch):\n",
    "        if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "            batch = X.shape[0] - c\n",
    "        X_t = X[c:(c + batch)]\n",
    "        Y_t = Y[c:(c + batch)]\n",
    "        for b in range(batch):\n",
    "            #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "\n",
    "\n",
    "            #########################################################################################\n",
    "            #########################################################################################\n",
    "            ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "\n",
    "            ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "            params = [f1[0], b1[0]]  \n",
    "            conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "            conv1_1[conv1_1<=0] = 0 #Relu\n",
    "\n",
    "            params = [f1[1], b1[1]]\n",
    "            conv1_2 = conv(conv1_1, params, 1)\n",
    "            conv1_2[conv1_2<=0] = 0 #Relu\n",
    "            ##################################### conv1_2: 32x32x16\n",
    "\n",
    "            pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (32-2)/2+1  = 16 \n",
    "\n",
    "            ########### 2nd Big Layer ###########\n",
    "            params = [f2[0], b2[0]]  \n",
    "            conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "            conv2_1[conv2_1<=0] = 0 #Relu\n",
    "\n",
    "            params = [f2[1], b2[1]]\n",
    "            conv2_2 = conv(conv2_1, params, 1)\n",
    "            conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "            #####################################  16x16x32\n",
    "\n",
    "            pl2 = maxpool(conv2_2, 2, 2) #   pl1 : (16-2)/2+1  = 8 \n",
    "\n",
    "            ########### 2nd Big Layer ###########\n",
    "            params = [f3[0], b3[0]]  \n",
    "            conv3_1 = conv(pl2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "            conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "            params = [f3[1], b3[1]]\n",
    "            conv3_2 = conv(conv3_1, params, 1)\n",
    "            conv3_2[conv3_2<=0] = 0 #Relu             \n",
    "            #####################################  8x8x64\n",
    "\n",
    "            ##################################### \n",
    "            ##################################### \n",
    "            #####################################\n",
    "            #Deconvolution/Upsampling\n",
    "            # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "\n",
    "            params = [f_dc[0][0], f_dc[0][1]] # deconv filter, deconv bias\n",
    "            dc1, new_in1 = convTransp(conv3_2, params, 1, 0)   #result:   =  16x6x32 , \n",
    "\n",
    "            #Concat dc1 with conv2_2 so we get 64 channels (16x16x64)\n",
    "            c1 = concat(dc1, conv2_2) # 1st one is the right one size  \n",
    "\n",
    "            ########### 1st Big dc Layer ###########          16x16x64     \n",
    "            params = [f4[0], b4[0]]  \n",
    "            conv4_1 = conv(c1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "            conv4_1[conv4_1<=0] = 0 #Relu\n",
    "\n",
    "            params = [f4[1], b4[1]]\n",
    "            conv4_2 = conv(conv4_1, params, 1)\n",
    "            conv4_2[conv4_2<=0] = 0 #Relu   \n",
    "            #####################################    16x16x32\n",
    "\n",
    "            #Deconvolution/Upsampling\n",
    "            # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "\n",
    "            params = [f_dc[1][0], f_dc[1][1]] # deconv filter, deconv bias\n",
    "            dc2, new_in2 = convTransp(conv4_2, params, 1, 0)   #result:   =  32x32x16 , \n",
    "\n",
    "            #Concat dc2 with conv1_2 so we get 64 channels (32x32x32)\n",
    "            c2 = concat(dc2, conv1_2) # 1st one is the right one size  \n",
    "\n",
    "            ########### 1st Big dc Layer ###########          32x32x32     \n",
    "            params = [f5[0], b5[0]]  \n",
    "            conv5_1 = conv(c2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "            conv5_1[conv5_1<=0] = 0 #Relu\n",
    "\n",
    "            params = [f5[1], b5[1]]\n",
    "            conv5_2 = conv(conv5_1, params, 1)\n",
    "            conv5_2[conv5_2<=0] = 0 #Relu   \n",
    "            #####################################    32x32x16\n",
    "\n",
    "\n",
    "            ############################# Last Layer conv(1x1) --> 32x32x1 ##########################\n",
    "            params = [out_f, out_b]\n",
    "            output = conv(conv5_2, params, 1, 0) #output.shape: 32x32x1\n",
    "\n",
    "\n",
    "            output = normalize(output)\n",
    "            ## Sigmoid ##\n",
    "            Y_hat = sigmoid(output)\n",
    "            #print(Y_hat[:,0:3,0:3])\n",
    "            #label crop is needed\n",
    "            #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "            plt.imshow(Y_hat.squeeze(), cmap=plt.get_cmap('gray'), vmin=0, vmax=1);\n",
    "            #plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "            cost_,accuracy_ = Dice_Coef(Y_hat, Y_t[b])#Cross_Entropy(Y_hat, Y_t[b])\n",
    "            cost = cost_\n",
    "            accuracy = accuracy_\n",
    "            print(\"Cost: {:.2f}   -   Accuracy: {:.2f}%\".format(cost/batch, (accuracy*100)/batch))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch`\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, verbose=True, callback=None):\n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    trim= 0.0001 # 0.005,0.00005 with Lr 0.01\n",
    "    filters,bias, f_dc = init_filters(3,16,trim) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "    ##Final 1x1 filter\n",
    "    trimf = trim\n",
    "    trimb = trim\n",
    "    out_f = np.random.randn(1,16,1,1)*trimf\n",
    "    out_b = np.random.randn(out_f.shape[0],1)*trimb  \n",
    "    out_fb = [out_f, out_b]\n",
    "    #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    accuracy_history=[]\n",
    "    \n",
    "    if(dropout>0):\n",
    "        print(\"Dropout Enabled! -  Value: {}\".format(dropout))\n",
    "    else:\n",
    "        print(\"Dropout Disabled!\")\n",
    "    \n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]  \n",
    "\n",
    "            \n",
    "\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "    [f1,f2,f3,f4,f5] = filters\n",
    "    [b1,b2,b3,b4,b5]= bias \n",
    "    \n",
    "    f1_dc = f_dc[0][0]\n",
    "    b1_dc = f_dc[0][1]\n",
    "    f2_dc = f_dc[1][0]\n",
    "    b2_dc = f_dc[1][1]\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        batch = 1\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            print('Batch: {}'.format(int(c/batch +1)))\n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.9  #0.9\n",
    "            beta2= 0.99 #0.99\n",
    "            lr = learning_rate\n",
    "            batch_size= batch\n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w) --> shape:(batch, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            cost = 0\n",
    "            accuracy = 0\n",
    "            if(e < 80):\n",
    "                \n",
    "                df =  []\n",
    "                db =  []\n",
    "                dfb=  []\n",
    "                for i in filters:\n",
    "                    v1 = np.zeros(i[0].shape)\n",
    "                    v2 = np.zeros(i[1].shape)\n",
    "                    s1 = np.zeros(i[0].shape)\n",
    "                    s2 = np.zeros(i[1].shape)\n",
    "                    v_a = [v1, v2]\n",
    "                    s_a = [s1, s2]\n",
    "                    v_adam.append(v_a)\n",
    "                    s_adam.append(s_a)\n",
    "\n",
    "                    df1_t = np.zeros(i[0].shape)\n",
    "                    df2_t = np.zeros(i[1].shape)\n",
    "                    f_temp = [df1_t, df2_t]\n",
    "                    df.append(f_temp)\n",
    "\n",
    "                for i in bias:\n",
    "                    bv1 = np.zeros(i[0].shape)\n",
    "                    bv2 = np.zeros(i[1].shape)\n",
    "                    bs1 = np.zeros(i[0].shape)\n",
    "                    bs2 = np.zeros(i[1].shape)    \n",
    "                    bv_a = [bv1, bv2]\n",
    "                    bs_a = [bs1, bs2]\n",
    "                    bv_adam.append(bv_a)\n",
    "                    bs_adam.append(bs_a)\n",
    "\n",
    "\n",
    "                    db1_t = np.zeros(i[0].shape)\n",
    "                    db2_t = np.zeros(i[1].shape)\n",
    "                    b_temp = [db1_t, db2_t]\n",
    "                    db.append(b_temp)\n",
    "\n",
    "                for i in f_dc:\n",
    "                    fdc_v1 = np.zeros(i[0].shape)\n",
    "                    bdc_v2 = np.zeros(i[1].shape)\n",
    "                    fdc_s1 = np.zeros(i[0].shape)\n",
    "                    bdc_s2 = np.zeros(i[1].shape)    \n",
    "                    fdc_v_a = [fdc_v1, bdc_v2]\n",
    "                    fdc_s_a = [fdc_s1, bdc_s2]\n",
    "                    fdc_v_adam.append(fdc_v_a)\n",
    "                    fdc_s_adam.append(fdc_s_a)\n",
    "\n",
    "\n",
    "                    df1_t = np.zeros(i[0].shape)\n",
    "                    db1_t = np.zeros(i[1].shape)\n",
    "                    fb_temp = [df1_t, db1_t]\n",
    "                    dfb.append(fb_temp)\n",
    "\n",
    "\n",
    "                #Final layer 1x1 filter setup\n",
    "\n",
    "                v_out_f = np.zeros(out_f.shape)\n",
    "                s_out_f = np.zeros(out_f.shape)\n",
    "                bv_out_b = np.zeros(out_b.shape)\n",
    "                bs_out_b = np.zeros(out_b.shape)\n",
    "\n",
    "\n",
    "\n",
    "                dout_f = np.zeros(out_f.shape)\n",
    "                dout_b = np.zeros(out_b.shape)\n",
    "\n",
    "            ######################################\n",
    "\n",
    "\n",
    "            #timestamp1 = time.time()\n",
    "\n",
    "\n",
    "            [df1,df2,df3,df4,df5] = df\n",
    "            [db1,db2,db3,db4,db5] = db \n",
    "            [dfb1_dc, dfb2_dc]    = dfb\n",
    "            \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print('Image: {}/{}'.format((b+1),batch))\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                params = [f1[0], b1[0]]  \n",
    "                conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "                conv1_1[conv1_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f1[1], b1[1]]\n",
    "                conv1_2 = conv(conv1_1, params, 1)\n",
    "                conv1_2[conv1_2<=0] = 0 #Relu\n",
    "                ##################################### conv1_2: 32x32x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (32-2)/2+1  = 16 \n",
    "                if(dropout>0):\n",
    "                    ## Dropout ##\n",
    "                    d = (np.random.rand(pl1.shape[0],pl1.shape[1],pl1.shape[2])<dropout)\n",
    "                    d = d*1 #Bool --> int(0s and 1s)\n",
    "                    pl1 = d*pl1\n",
    "                    #############\n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f2[0], b2[0]]  \n",
    "                conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv2_1[conv2_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f2[1], b2[1]]\n",
    "                conv2_2 = conv(conv2_1, params, 1)\n",
    "                conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "                #####################################  16x16x32\n",
    "                \n",
    "                pl2 = maxpool(conv2_2, 2, 2) #   pl1 : (16-2)/2+1  = 8 \n",
    "                if(dropout>0):\n",
    "                    ## Dropout ##\n",
    "                    d = (np.random.rand(pl2.shape[0],pl2.shape[1],pl2.shape[2])<dropout)\n",
    "                    d = d*1 #Bool --> int(0s and 1s)\n",
    "                    pl2 = d*pl2\n",
    "                    #############\n",
    "                ## ADD DROPOUT HERE\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f3[0], b3[0]]  \n",
    "                conv3_1 = conv(pl2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f3[1], b3[1]]\n",
    "                conv3_2 = conv(conv3_1, params, 1)\n",
    "                conv3_2[conv3_2<=0] = 0 #Relu             \n",
    "                #####################################  8x8x64\n",
    "          \n",
    "                ##################################### \n",
    "                ##################################### \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[0][0], f_dc[0][1]] # deconv filter, deconv bias\n",
    "                dc1, new_in1 = convTransp(conv3_2, params, 1, 0)   #result:   =  16x6x32 , \n",
    "                #Concat dc1 with conv2_2 so we get 64 channels (16x16x64)\n",
    "                c1 = concat(dc1, conv2_2) # 1st one is the right one size  \n",
    "                if(dropout>0):\n",
    "                    ## Dropout ##\n",
    "                    d = (np.random.rand(c1.shape[0],c1.shape[1],c1.shape[2])<dropout)\n",
    "                    d = d*1 #Bool --> int(0s and 1s)\n",
    "                    c1 = d*c1\n",
    "                    #############\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          16x16x64     \n",
    "                params = [f4[0], b4[0]]  \n",
    "                conv4_1 = conv(c1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv4_1[conv4_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f4[1], b4[1]]\n",
    "                conv4_2 = conv(conv4_1, params, 1)\n",
    "                conv4_2[conv4_2<=0] = 0 #Relu   \n",
    "                #####################################    16x16x32\n",
    "                \n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[1][0], f_dc[1][1]] # deconv filter, deconv bias\n",
    "                dc2, new_in2 = convTransp(conv4_2, params, 1, 0)   #result:   =  32x32x16 , \n",
    "                #Concat dc2 with conv1_2 so we get 64 channels (32x32x32)\n",
    "                c2 = concat(dc2, conv1_2) # 1st one is the right one size  \n",
    "                if(dropout>0): \n",
    "                    ## Dropout ##\n",
    "                    d = (np.random.rand(c2.shape[0],c2.shape[1],c2.shape[2])<dropout)\n",
    "                    d = d*1 #Bool --> int(0s and 1s)\n",
    "                    c2 = d*c2\n",
    "                    #############\n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          32x32x32     \n",
    "                params = [f5[0], b5[0]]  \n",
    "                conv5_1 = conv(c2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv5_1[conv5_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f5[1], b5[1]]\n",
    "                conv5_2 = conv(conv5_1, params, 1)\n",
    "                conv5_2[conv5_2<=0] = 0 #Relu   \n",
    "                #####################################    32x32x16\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 32x32x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv5_2, params, 1, 0) #output.shape: 32x32x1\n",
    "                \n",
    "                \n",
    "                output = normalize(output)\n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                #print(Y_hat[:,0:3,0:3])\n",
    "                #label crop is needed\n",
    "                #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "                cost_,accuracy_ = Dice_Coef(Y_hat, Y_t[b])#Cross_Entropy(Y_hat, Y_t[b])\n",
    "                cost += cost_\n",
    "                accuracy += accuracy_\n",
    "                accuracy_history.append(accuracy)\n",
    "                if (accuracy>0.655):\n",
    "                    params_values = [filters, bias, f_dc, out_fb]\n",
    "                    return params_values, accuracy_history\n",
    "                #print(accuracy/(b+1))\n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t[b] #- (np.divide(Y_t[b], Y_hat) - np.divide(1 - Y_t[b], 1 - Y_hat))#\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv5_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv5_2, out_f, conv_s) #\n",
    "                #pack data\n",
    "                \n",
    "                \n",
    "                dconv5_2[conv5_2<=0] = 0             \n",
    "                dconv5_1, df5_2, db5_2 = convolutionBackward(dconv5_2, conv5_1, f5[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv5_1[conv5_1<=0] = 0\n",
    "                conc_dconv4, df5_1, db5_1 = convolutionBackward(dconv5_1, c2, f5[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv4, dconv1_2 = crop2half(conc_dconv4)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv4_2, df2_dc, db2_dc = convTranspBackward(dconv4, new_in2, f_dc[1][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv4_2[conv4_2<=0] = 0\n",
    "                dconv4_1, df4_2, db4_2 = convolutionBackward(dconv4_2, conv4_1, f4[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv4_1[conv4_1<=0] = 0\n",
    "                conc_dconv3, df4_1, db4_1 = convolutionBackward(dconv4_1, c1, f4[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv3, dconv2_2 = crop2half(conc_dconv3)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv3_2, df1_dc, db1_dc = convTranspBackward(dconv3, new_in1, f_dc[0][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv3_2[conv3_2<=0] = 0\n",
    "                dconv3_1, df3_2, db3_2 = convolutionBackward(dconv3_2, conv3_1, f3[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv3_1[conv3_1<=0] = 0\n",
    "                dpl2, df3_1, db3_1 = convolutionBackward(dconv3_1, pl2, f3[0], conv_s) #\n",
    "                \n",
    "                dconv2_2 += maxpoolBackward(dpl2, conv2_2, f=2 , s=2)\n",
    "                \n",
    "                dconv2_2[conv2_2<=0] = 0\n",
    "                dconv2_1, df2_2, db2_2 = convolutionBackward(dconv2_2, conv2_1, f2[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv2_1[conv2_1<=0] = 0\n",
    "                dpl1, df2_1, db2_1 = convolutionBackward(dconv2_1, pl1, f2[0], conv_s) #\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)\n",
    "                \n",
    "                dconv1_2[conv1_2<=0] = 0\n",
    "                dconv1_1, df1_2, db1_2 = convolutionBackward(dconv1_2, conv1_1, f1[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv1_1[conv1_1<=0] = 0\n",
    "                _, df1_1, db1_1 = convolutionBackward(dconv1_1, X_t[b], f1[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                #[df1,df2,df3,df4,df5] = df\n",
    "                #[db1,db2,db3,db4,db5] = db \n",
    "                #dfb1_dc,df     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                df4[0] += df4_1\n",
    "                df4[1] += df4_2\n",
    "                df5[0] += df5_1\n",
    "                df5[1] += df5_2\n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                db4[0] += db4_1\n",
    "                db4[1] += db4_2\n",
    "                db5[0] += db5_1\n",
    "                db5[1] += db5_2\n",
    "\n",
    "                dfb1_dc[0] += df1_dc\n",
    "                dfb1_dc[1] += db1_dc\n",
    "                dfb2_dc[0] += df2_dc\n",
    "                dfb2_dc[1] += db2_dc\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "\n",
    "\n",
    "      \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in range(len(filters)):\n",
    "                v_adam[i][0] = beta1*v_adam[i][0] + (1-beta1)*df[i][0]/batch_size #f1\n",
    "                s_adam[i][0] = beta2*s_adam[i][0] + (1-beta2)*(df[i][0]/batch_size)**2 #f1  \n",
    "                filters[i][0] -= lr*v_adam[i][0]/np.sqrt(s_adam[i][0] + 1e-8)\n",
    "                \n",
    "                v_adam[i][1] = beta1*v_adam[i][1] + (1-beta1)*df[i][1]/batch_size #f2\n",
    "                s_adam[i][1] = beta2*s_adam[i][1] + (1-beta2)*(df[i][1]/batch_size)**2  #f2\n",
    "                filters[i][1] -= lr*v_adam[i][1]/np.sqrt(s_adam[i][1] + 1e-8)\n",
    "                \n",
    "            for i in range(len(bias)):\n",
    "                bv_adam[i][0] = beta1*bv_adam[i][0] + (1-beta1)*db[i][0]/batch_size #b1\n",
    "                bs_adam[i][0] = beta2*bs_adam[i][0] + (1-beta2)*(db[i][0]/batch_size)**2  #b1\n",
    "                bias[i][0] -= lr*bv_adam[i][0]/np.sqrt(bs_adam[i][0] + 1e-8)\n",
    "                \n",
    "                bv_adam[i][1] = beta1*bv_adam[i][1] + (1-beta1)*db[i][1]/batch_size #b2\n",
    "                bs_adam[i][1] = beta2*bs_adam[i][1] + (1-beta2)*(db[i][1]/batch_size)**2  #b2\n",
    "                bias[i][1] -= lr*bv_adam[i][1]/np.sqrt(bs_adam[i][1] + 1e-8)\n",
    "            \n",
    "            for i in range(len(f_dc)):\n",
    "                fdc_v_adam[i][0] = beta1*fdc_v_adam[i][0] + (1-beta1)*dfb[i][0]/batch_size #f1\n",
    "                fdc_s_adam[i][0] = beta2*fdc_s_adam[i][0] + (1-beta2)*(dfb[i][0]/batch_size)**2  #f1\n",
    "                f_dc[i][0] -= lr*fdc_v_adam[i][0]/np.sqrt(fdc_s_adam[i][0] + 1e-8)\n",
    "                \n",
    "                fdc_v_adam[i][1] = beta1*fdc_v_adam[i][1] + (1-beta1)*dfb[i][1]/batch_size #b2\n",
    "                fdc_s_adam[i][1] = beta2*fdc_s_adam[i][1] + (1-beta2)*(dfb[i][1]/batch_size)**2  #b2\n",
    "                f_dc[i][1] -= lr*fdc_v_adam[i][1]/np.sqrt(fdc_s_adam[i][1] + 1e-8)    \n",
    "            \n",
    "            v_out_f = beta1*v_out_f + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out_f = beta2*s_out_f + (1 - beta2)*(dout_f/batch_size)**2  #f\n",
    "            out_fb[0] -= lr*v_out_f/np.sqrt(s_out_f + 1e-8)\n",
    "            \n",
    "            bv_out_b = beta1*bv_out_b + (1 - beta1)*dout_b/batch_size #b\n",
    "            bs_out_b = beta2*bs_out_b + (1 - beta2)*(dout_b/batch_size)**2  #b\n",
    "            out_fb[1] -= lr*bv_out_b/np.sqrt(bs_out_b + 1e-8)\n",
    "            \n",
    "            '''\n",
    "                        for i in range(len(filters)):\n",
    "                filters[i][0] -= lr*df[i][0]\n",
    "                bias[i][0] -= lr*db[i][0]\n",
    "            \n",
    "            \n",
    "            f_dc[0][0] -= lr*df1_dc\n",
    "            f_dc[0][1] -= lr*db1_dc\n",
    "            \n",
    "            out_fb[0] -= lr*dout_f\n",
    "            out_fb[1] -= lr*dout_b\n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            #print(\"Batch:{}\".format(c+12))\n",
    "            \n",
    "           \n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            '''\n",
    "            #print(\"Cost : {:.5f}\".format(cost/batch))\n",
    "            #print(\"Accuracy : {:.5f}%\".format((accuracy*100)/batch))\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        if(verbose):\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "    #pack filters\n",
    "    params_values = [filters, bias, f_dc, out_fb]\n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout Enabled! -  Value: 0.5\n",
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     1   -   cost: 0.75   -   Accuracy: 47.06%\n",
      "Epoch: {2}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     2   -   cost: 0.75   -   Accuracy: 47.04%\n",
      "Epoch: {3}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     3   -   cost: 0.75   -   Accuracy: 47.03%\n",
      "Epoch: {4}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     4   -   cost: 0.75   -   Accuracy: 47.02%\n",
      "Epoch: {5}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     5   -   cost: 0.75   -   Accuracy: 47.00%\n",
      "Epoch: {6}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     6   -   cost: 0.76   -   Accuracy: 46.98%\n",
      "Epoch: {7}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     7   -   cost: 0.76   -   Accuracy: 46.95%\n",
      "Epoch: {8}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     8   -   cost: 0.76   -   Accuracy: 46.89%\n",
      "Epoch: {9}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:     9   -   cost: 0.76   -   Accuracy: 46.71%\n",
      "Epoch: {10}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    10   -   cost: 0.77   -   Accuracy: 46.13%\n",
      "Epoch: {11}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    11   -   cost: 0.82   -   Accuracy: 44.19%\n",
      "Epoch: {12}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    12   -   cost: 0.91   -   Accuracy: 40.33%\n",
      "Epoch: {13}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    13   -   cost: 0.97   -   Accuracy: 38.01%\n",
      "Epoch: {14}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    14   -   cost: 0.96   -   Accuracy: 38.38%\n",
      "Epoch: {15}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    15   -   cost: 0.94   -   Accuracy: 39.10%\n",
      "Epoch: {16}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    16   -   cost: 0.88   -   Accuracy: 41.45%\n",
      "Epoch: {17}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    17   -   cost: 0.83   -   Accuracy: 43.79%\n",
      "Epoch: {18}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    18   -   cost: 0.86   -   Accuracy: 42.49%\n",
      "Epoch: {19}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    19   -   cost: 0.83   -   Accuracy: 43.81%\n",
      "Epoch: {20}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    20   -   cost: 0.84   -   Accuracy: 43.20%\n",
      "Epoch: {21}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    21   -   cost: 0.82   -   Accuracy: 43.91%\n",
      "Epoch: {22}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    22   -   cost: 0.84   -   Accuracy: 43.20%\n",
      "Epoch: {23}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    23   -   cost: 0.81   -   Accuracy: 44.42%\n",
      "Epoch: {24}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    24   -   cost: 0.82   -   Accuracy: 44.26%\n",
      "Epoch: {25}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    25   -   cost: 0.78   -   Accuracy: 46.00%\n",
      "Epoch: {26}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    26   -   cost: 0.77   -   Accuracy: 46.27%\n",
      "Epoch: {27}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    27   -   cost: 0.72   -   Accuracy: 48.48%\n",
      "Epoch: {28}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    28   -   cost: 0.71   -   Accuracy: 48.98%\n",
      "Epoch: {29}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    29   -   cost: 0.69   -   Accuracy: 50.33%\n",
      "Epoch: {30}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    30   -   cost: 0.65   -   Accuracy: 52.26%\n",
      "Epoch: {31}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    31   -   cost: 0.60   -   Accuracy: 54.93%\n",
      "Epoch: {32}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    32   -   cost: 0.64   -   Accuracy: 52.62%\n",
      "Epoch: {33}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    33   -   cost: 0.64   -   Accuracy: 52.74%\n",
      "Epoch: {34}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    34   -   cost: 0.62   -   Accuracy: 53.71%\n",
      "Epoch: {35}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    35   -   cost: 0.61   -   Accuracy: 54.34%\n",
      "Epoch: {36}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    36   -   cost: 0.58   -   Accuracy: 55.73%\n",
      "Epoch: {37}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    37   -   cost: 0.61   -   Accuracy: 54.43%\n",
      "Epoch: {38}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    38   -   cost: 0.58   -   Accuracy: 56.09%\n",
      "Epoch: {39}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    39   -   cost: 0.58   -   Accuracy: 56.07%\n",
      "Epoch: {40}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    40   -   cost: 0.56   -   Accuracy: 57.27%\n",
      "Epoch: {41}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    41   -   cost: 0.56   -   Accuracy: 57.27%\n",
      "Epoch: {42}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    42   -   cost: 0.53   -   Accuracy: 58.88%\n",
      "Epoch: {43}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    43   -   cost: 0.54   -   Accuracy: 58.36%\n",
      "Epoch: {44}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    44   -   cost: 0.50   -   Accuracy: 60.50%\n",
      "Epoch: {45}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    45   -   cost: 0.55   -   Accuracy: 57.79%\n",
      "Epoch: {46}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    46   -   cost: 0.50   -   Accuracy: 60.85%\n",
      "Epoch: {47}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    47   -   cost: 0.44   -   Accuracy: 64.52%\n",
      "Epoch: {48}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "Epoch:    48   -   cost: 0.47   -   Accuracy: 62.22%\n",
      "Epoch: {49}\n",
      "Batch: 1\n",
      "Image: 1/1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "#By tuning LR helps with eliminating big jumps of the accuracy.\n",
    "#Its important to make SMALL adjustment to LR so you can find the right spot\n",
    "params_values, accuracy_history = train(train_images, train_labels, 60, 0.008, 0) #0.05 stable LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(accuracy_history, label=\"Accuracy\")\n",
    "#plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "#plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Forward step . . .\n",
      "Cost: 0.37   -   Accuracy: 69.21%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYt = test_labels.T\\ntemp1 = []\\nfor i in range(Yt.shape[1]):\\n        for j in range(Yt.shape[0]):\\n            if(Yt[j][i]==1):\\n                temp1.append(j)\\nYt=np.array(temp1)\\nY_test_hat, _ = full_forward_propagation(np.transpose(test_images), params_values, NN_ARCHITECTURE)#multiple?!\\n\\nYht = np.array(Y_test_hat.T)\\n#x_log=np.log( np.exp(Yh) / np.sum(np.exp(Yh), axis = 1) )  #(60000,10) , we need to add along columns so we get sum of 1 on every example-row\\nnum = np.exp(Yht)\\nden = np.sum(np.exp(Yht), axis = 1)\\nfor i in range(Yht.shape[0]): #60000\\n                #for j in range(Yh.shape[1]): #10\\n                Yht[i][:] = np.log(num[i][:] / den[i])  \\n\\n#cost = get_cost_value(Yht, Yt)\\n\\n#cost_history.append(cost)\\naccuracy = get_accuracy_value(Y_test_hat, test_labels.T)\\n#accuracy_history.append(accuracy)\\nprint(\"Accuracy: {:.5f}%\".format( accuracy*100))\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Prediction ######\n",
    "Validate(train_images, train_labels, params_values);\n",
    "pass\n",
    "\"\"\"\n",
    "Yt = test_labels.T\n",
    "temp1 = []\n",
    "for i in range(Yt.shape[1]):\n",
    "        for j in range(Yt.shape[0]):\n",
    "            if(Yt[j][i]==1):\n",
    "                temp1.append(j)\n",
    "Yt=np.array(temp1)\n",
    "Y_test_hat, _ = full_forward_propagation(np.transpose(test_images), params_values, NN_ARCHITECTURE)#multiple?!\n",
    "\n",
    "Yht = np.array(Y_test_hat.T)\n",
    "#x_log=np.log( np.exp(Yh) / np.sum(np.exp(Yh), axis = 1) )  #(60000,10) , we need to add along columns so we get sum of 1 on every example-row\n",
    "num = np.exp(Yht)\n",
    "den = np.sum(np.exp(Yht), axis = 1)\n",
    "for i in range(Yht.shape[0]): #60000\n",
    "                #for j in range(Yh.shape[1]): #10\n",
    "                Yht[i][:] = np.log(num[i][:] / den[i])  \n",
    "\n",
    "#cost = get_cost_value(Yht, Yt)\n",
    "\n",
    "#cost_history.append(cost)\n",
    "accuracy = get_accuracy_value(Y_test_hat, test_labels.T)\n",
    "#accuracy_history.append(accuracy)\n",
    "print(\"Accuracy: {:.5f}%\".format( accuracy*100))\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
