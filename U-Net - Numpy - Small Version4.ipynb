{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load from /home/USER/data/mnist or elsewhere; download if missing.\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "    \"\"\"\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist\n",
    "        path = os.path.join(os.path.expanduser('~'), 'data', 'salt')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        with gzip.open(path) as f:\n",
    "            # First 16 bytes are magic_number, n_imgs, n_rows, n_cols\n",
    "            pixels = np.frombuffer(f.read(), 'B', offset=16)\n",
    "        return pixels.reshape(-1, 1, 28, 28).astype('float32') / 255\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        with gzip.open(path) as f:\n",
    "            # First 8 bytes are magic_number, n_labels\n",
    "            integer_labels = np.frombuffer(f.read(), 'B', offset=8)\n",
    "        def _onehot(integer_labels):\n",
    "            \"\"\"Return matrix whose rows are onehot encodings of integers.\"\"\"\n",
    "            n_rows = len(integer_labels)\n",
    "            n_cols = integer_labels.max() + 1\n",
    "            onehot = np.zeros((n_rows, n_cols), dtype='uint8')\n",
    "            onehot[np.arange(n_rows), integer_labels] = 1\n",
    "            return onehot\n",
    "\n",
    "        return _onehot(integer_labels)\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(os.path.join(path, files[0]))\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(os.path.join(path, files[1]))\n",
    "    print(\"Test Images  : Loading . . .\")\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    print(\"Test Labels  : Loading . . .\")\n",
    "    test_labels = _labels(os.path.join(path, files[3]))\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return train_images, train_labels #, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n",
      "(1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\"\"\"\n",
    "temp = np.zeros((train_images.shape[0],1,128,128))\n",
    "for i in range(train_images.shape[0]):\n",
    "    #print(cv2.resize(train_images[i,0,:,:], (128,128)).shape)\n",
    "    temp[i,0,:,:]=cv2.resize(train_images[i,0,:,:], (128,128)).reshape(1,1,128,128)\n",
    "#print(train_images.shape)\n",
    "train_images= train_labels = temp\n",
    "print(train_labels.shape) \n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\"\"\"\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "#plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tone up\n",
    "#train_labels[train_labels>0.8] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_labels[0].squeeze(), cmap='Greys_r');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Convolution Architecture - Downsampling/Upsampling  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f,trim ):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    trimf = trim\n",
    "    trimb = trim*5\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trimf #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trimb\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \n",
    "    return filters, bias, f_dc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "\n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(np.multiply(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] , f[z, :, :, :])) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "\n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "    #print(arr.shape)\n",
    "    try:\n",
    "        idx = np.nanargmax(arr)\n",
    "        #print (idx)\n",
    "    except:\n",
    "        idx = 0\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h + a, _w + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "        print(\"Warning: Extra crop needed and handled!(%d --> %d)\" %(dim, img2.shape[1]))\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def NLLLoss(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[1]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] >= logs[:,i,j]):#Gray and above\n",
    "                out[:,i,j] = logs[:,i,j]/targets[:,i,j] \n",
    "            else:\n",
    "                out[:,i,j] = (1 - logs[:,i,j])/(1 - targets[:,i,j]) # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    res = out.sum()/mylen\n",
    "    return -np.log(res), res\n",
    "\n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "def normalize(output):\n",
    "    output[output<-10]=-4\n",
    "    output[output>10] = 4\n",
    "    return output\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch`\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, mode, params_values): \n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    trim= 0.001\n",
    "    if(mode == 'train'):\n",
    "        filters,bias, f_dc = init_filters(4,16,trim) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "        ##Final 1x1 filter\n",
    "        trimf = trim\n",
    "        trimb = trim*5\n",
    "        out_f = np.random.randn(1,16,1,1)*trimf\n",
    "        out_b = np.random.randn(out_f.shape[0],1)*trimb  \n",
    "        out_fb = [out_f, out_b]\n",
    "        #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "        #image shape: (channels, height, width)\n",
    "    else:\n",
    "        [filters, bias, f_dc, out_fb] = params_values \n",
    "        [out_f, out_b] = out_fb\n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7]= bias \n",
    "    \n",
    "\n",
    "    f1_dc = f_dc[0][0]\n",
    "    b1_dc = f_dc[0][1]\n",
    "    f2_dc = f_dc[1][0]\n",
    "    b2_dc = f_dc[1][1]\n",
    "    f3_dc = f_dc[2][0]\n",
    "    b3_dc = f_dc[2][1]\n",
    "    \n",
    "    \n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]  \n",
    "\n",
    "            \n",
    "\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    prev_cost = 1000\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        \n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        batch = 1\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            print('Batch: {}'.format(int(c/batch +1)))\n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.9  #0.9\n",
    "            beta2= 0.99 #0.99\n",
    "            #lr = learning_rate\n",
    "            batch_size= batch\n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            cost = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            #Special setup for LR\n",
    "            if(e<4):\n",
    "                lr=0.03\n",
    "            ####TODO:Possible solution for unstable future results(from ~1x10-5 --> 0.98 possibility and back again),\n",
    "            #is to reduce dynamically the learning rate(this problem can also be reduced by making trims even smaller)\n",
    "            \n",
    "            if((e < 20)and(mode == 'train')):\n",
    "                \n",
    "                df =  []\n",
    "                db =  []\n",
    "                dfb=  []\n",
    "                for i in filters:\n",
    "                    v1 = np.zeros(i[0].shape)\n",
    "                    v2 = np.zeros(i[1].shape)\n",
    "                    s1 = np.zeros(i[0].shape)\n",
    "                    s2 = np.zeros(i[1].shape)\n",
    "                    v_a = [v1, v2]\n",
    "                    s_a = [s1, s2]\n",
    "                    v_adam.append(v_a)\n",
    "                    s_adam.append(s_a)\n",
    "\n",
    "                    df1_t = np.zeros(i[0].shape)\n",
    "                    df2_t = np.zeros(i[1].shape)\n",
    "                    f_temp = [df1_t, df2_t]\n",
    "                    df.append(f_temp)\n",
    "\n",
    "                for i in bias:\n",
    "                    bv1 = np.zeros(i[0].shape)\n",
    "                    bv2 = np.zeros(i[1].shape)\n",
    "                    bs1 = np.zeros(i[0].shape)\n",
    "                    bs2 = np.zeros(i[1].shape)    \n",
    "                    bv_a = [bv1, bv2]\n",
    "                    bs_a = [bs1, bs2]\n",
    "                    bv_adam.append(bv_a)\n",
    "                    bs_adam.append(bs_a)\n",
    "\n",
    "\n",
    "                    db1_t = np.zeros(i[0].shape)\n",
    "                    db2_t = np.zeros(i[1].shape)\n",
    "                    b_temp = [db1_t, db2_t]\n",
    "                    db.append(b_temp)\n",
    "\n",
    "                for i in f_dc:\n",
    "                    fdc_v1 = np.zeros(i[0].shape)\n",
    "                    bdc_v2 = np.zeros(i[1].shape)\n",
    "                    fdc_s1 = np.zeros(i[0].shape)\n",
    "                    bdc_s2 = np.zeros(i[1].shape)    \n",
    "                    fdc_v_a = [fdc_v1, bdc_v2]\n",
    "                    fdc_s_a = [fdc_s1, bdc_s2]\n",
    "                    fdc_v_adam.append(fdc_v_a)\n",
    "                    fdc_s_adam.append(fdc_s_a)\n",
    "\n",
    "\n",
    "                    df1_t = np.zeros(i[0].shape)\n",
    "                    db1_t = np.zeros(i[1].shape)\n",
    "                    fb_temp = [df1_t, db1_t]\n",
    "                    dfb.append(fb_temp)\n",
    "                    \n",
    "                    \n",
    "                [df1,df2,df3,df4,df5,df6,df7] = df\n",
    "                [db1,db2,db3,db4,db5,db6,db7] = db \n",
    "                [dfb1_dc, dfb2_dc, dfb3_dc]    = dfb\n",
    "\n",
    "\n",
    "                #Final layer 1x1 filter setup\n",
    "\n",
    "                v_out_f = np.zeros(out_f.shape)\n",
    "                s_out_f = np.zeros(out_f.shape)\n",
    "                bv_out_b = np.zeros(out_b.shape)\n",
    "                bs_out_b = np.zeros(out_b.shape)\n",
    "\n",
    "\n",
    "\n",
    "                dout_f = np.zeros(out_f.shape)\n",
    "                dout_b = np.zeros(out_b.shape)\n",
    "\n",
    "            ######################################\n",
    "\n",
    "\n",
    "            #timestamp1 = time.time()\n",
    "\n",
    "          \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print('Image: {}/{}'.format((b+1),batch))\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                params = [f1[0], b1[0]]  \n",
    "                conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "                conv1_1[conv1_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f1[1], b1[1]]\n",
    "                conv1_2 = conv(conv1_1, params, 1)\n",
    "                conv1_2[conv1_2<=0] = 0 #Relu\n",
    "                ##################################### conv1_2: 32x32x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (32-2)/2+1  = 16 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f2[0], b2[0]]  \n",
    "                conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv2_1[conv2_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f2[1], b2[1]]\n",
    "                conv2_2 = conv(conv2_1, params, 1)\n",
    "                conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "                #####################################  16x16x32\n",
    "                \n",
    "                pl2 = maxpool(conv2_2, 2, 2) #   pl1 : (16-2)/2+1  = 8 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 3rd Big Layer ###########\n",
    "                params = [f3[0], b3[0]]  \n",
    "                conv3_1 = conv(pl2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f3[1], b3[1]]\n",
    "                conv3_2 = conv(conv3_1, params, 1)\n",
    "                conv3_2[conv3_2<=0] = 0 #Relu             \n",
    "                #####################################  8x8x64\n",
    "                         \n",
    "                pl3 = maxpool(conv3_2, 2, 2) #   pl1 : (8-2)/2+1  = 4   4x4x64\n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "            \n",
    "                ########### 4th Big Layer ###########\n",
    "                params = [f4[0], b4[0]]  \n",
    "                conv4_1 = conv(pl3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv4_1[conv4_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f4[1], b4[1]]\n",
    "                conv4_2 = conv(conv4_1, params, 1)\n",
    "                conv4_2[conv4_2<=0] = 0 #Relu              \n",
    "                #####################################  4x4x128\n",
    "                \n",
    "                ##################################### \n",
    "                ##################################### \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[0][0], f_dc[0][1]] # deconv filter, deconv bias\n",
    "                dc1, new_in1 = convTransp(conv4_2, params, 1, 0)   #result:   =  8x8x64 , \n",
    "                #Concat dc1 with conv3_2 \n",
    "                c1 = concat(dc1, conv3_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          8x8x128     \n",
    "                params = [f5[0], b5[0]]  \n",
    "                conv5_1 = conv(c1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv5_1[conv5_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f5[1], b5[1]]\n",
    "                conv5_2 = conv(conv5_1, params, 1)\n",
    "                conv5_2[conv5_2<=0] = 0 #Relu   \n",
    "                #####################################    8x8x64\n",
    "                \n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[1][0], f_dc[1][1]] # deconv filter, deconv bias\n",
    "                dc2, new_in2 = convTransp(conv5_2, params, 1, 0)   #result:   =  16x16x32 , \n",
    "                #Concat dc2 with conv1_2 \n",
    "                c2 = concat(dc2, conv2_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          16x16x64     \n",
    "                params = [f6[0], b6[0]]  \n",
    "                conv6_1 = conv(c2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv6_1[conv6_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f6[1], b6[1]]\n",
    "                conv6_2 = conv(conv6_1, params, 1)\n",
    "                conv6_2[conv6_2<=0] = 0 #Relu   \n",
    "                #####################################    16x16x32\n",
    "                \n",
    "                                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[2][0], f_dc[2][1]] # deconv filter, deconv bias\n",
    "                dc3, new_in3 = convTransp(conv6_2, params, 1, 0)   #result:   =  32x32x16 , \n",
    "                #Concat dc2 with conv1_2 \n",
    "                c3 = concat(dc3, conv1_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 3rd Big dc Layer ###########          32x32x32  \n",
    "                params = [f7[0], b7[0]]  \n",
    "                conv7_1 = conv(c3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv7_1[conv7_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f7[1], b7[1]]\n",
    "                conv7_2 = conv(conv7_1, params, 1)\n",
    "                conv7_2[conv7_2<=0] = 0 #Relu   \n",
    "                #####################################    32x32x16\n",
    "                \n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 32x32x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv7_2, params, 1, 0) #output.shape: 32x32x1\n",
    "                \n",
    "                \n",
    "                output = normalize(output)\n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                print(Y_hat[:,0:3,0:3])\n",
    "                #label crop is needed\n",
    "                #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "                cost_,accuracy_ = NLLLoss(Y_hat, Y_t[b])\n",
    "                cost += cost_\n",
    "                accuracy += accuracy_\n",
    "                if(mode == 'predict'):\n",
    "                    print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "                    return\n",
    "                #print(cost/(b+1), prev_cost)\n",
    "                #if(((cost-prev_cost)>0.2)and((e+1) == epochs)):\n",
    "                #    e=e-1\n",
    "                #    print(\"\\n\\n-------------Epoch skipped!--------------\\n\\n\")\n",
    "                #    continue\n",
    "                #prev_cost = cost\n",
    "                \n",
    "                #accuracy += get_accuracy_value(Y_hat, Y_t[b])\n",
    "                #print(accuracy/(b+1))\n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t[b]\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv7_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv7_2, out_f, conv_s) #\n",
    "                #pack data\n",
    "                \n",
    "                \n",
    "                dconv7_2[conv7_2<=0] = 0             \n",
    "                dconv7_1, df7_2, db7_2 = convolutionBackward(dconv7_2, conv7_1, f7[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv7_1[conv7_1<=0] = 0\n",
    "                conc_dconv6, df7_1, db7_1 = convolutionBackward(dconv7_1, c3, f7[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv6, dconv1_2 = crop2half(conc_dconv6)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv6_2, df3_dc, db3_dc = convTranspBackward(dconv6, new_in3, f_dc[2][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv6_2[conv6_2<=0] = 0\n",
    "                dconv6_1, df6_2, db6_2 = convolutionBackward(dconv6_2, conv6_1, f6[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv6_1[conv6_1<=0] = 0\n",
    "                conc_dconv5, df6_1, db6_1 = convolutionBackward(dconv6_1, c2, f6[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv5, dconv2_2 = crop2half(conc_dconv5)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv5_2, df2_dc, db2_dc = convTranspBackward(dconv5, new_in2, f_dc[1][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv5_2[conv5_2<=0] = 0\n",
    "                dconv5_1, df5_2, db5_2 = convolutionBackward(dconv5_2, conv5_1, f5[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv5_1[conv5_1<=0] = 0\n",
    "                conc_dconv4, df5_1, db5_1 = convolutionBackward(dconv5_1, c1, f5[0], conv_s) #\n",
    "                \n",
    "                dconv4, dconv3_2 = crop2half(conc_dconv4)\n",
    "                dconv4_2, df1_dc, db1_dc = convTranspBackward(dconv4, new_in1, f_dc[0][0], conv_s)\n",
    "                \n",
    "                dconv4_2[conv4_2<=0] = 0\n",
    "                dconv4_1, df4_2, db4_2 = convolutionBackward(dconv4_2, conv4_1, f4[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv4_1[conv4_1<=0] = 0\n",
    "                dpl3, df4_1, db4_1 = convolutionBackward(dconv4_1, pl3, f4[0], conv_s) #\n",
    "                \n",
    "                dconv3_2 += maxpoolBackward(dpl3, conv3_2, f=2 , s=2)\n",
    "                \n",
    "                \n",
    "                dconv3_2[conv3_2<=0] = 0\n",
    "                dconv3_1, df3_2, db3_2 = convolutionBackward(dconv3_2, conv3_1, f3[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv3_1[conv3_1<=0] = 0\n",
    "                dpl2, df3_1, db3_1 = convolutionBackward(dconv3_1, pl2, f3[0], conv_s) #\n",
    "                \n",
    "                dconv2_2 += maxpoolBackward(dpl2, conv2_2, f=2 , s=2)\n",
    "                \n",
    "                dconv2_2[conv2_2<=0] = 0\n",
    "                dconv2_1, df2_2, db2_2 = convolutionBackward(dconv2_2, conv2_1, f2[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv2_1[conv2_1<=0] = 0\n",
    "                dpl1, df2_1, db2_1 = convolutionBackward(dconv2_1, pl1, f2[0], conv_s) #\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)\n",
    "                \n",
    "                dconv1_2[conv1_2<=0] = 0\n",
    "                dconv1_1, df1_2, db1_2 = convolutionBackward(dconv1_2, conv1_1, f1[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv1_1[conv1_1<=0] = 0\n",
    "                _, df1_1, db1_1 = convolutionBackward(dconv1_1, X_t[b], f1[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                #[df1,df2,df3,df4,df5,df6,df7] = df\n",
    "                #[db1,db2,db3,db4,db5,df6,df7] = db \n",
    "                #dfb1_dc,dfb2_dc, dfb3_dc     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                df4[0] += df4_1\n",
    "                df4[1] += df4_2\n",
    "                df5[0] += df5_1\n",
    "                df5[1] += df5_2\n",
    "                df6[0] += df6_1\n",
    "                df6[1] += df6_2\n",
    "                df7[0] += df7_1\n",
    "                df7[1] += df7_2\n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                db4[0] += db4_1\n",
    "                db4[1] += db4_2\n",
    "                db5[0] += db5_1\n",
    "                db5[1] += db5_2\n",
    "                db6[0] += db6_1\n",
    "                db6[1] += db6_2\n",
    "                db7[0] += db7_1\n",
    "                db7[1] += db7_2\n",
    "\n",
    "                dfb1_dc[0] += df1_dc\n",
    "                dfb1_dc[1] += db1_dc\n",
    "                dfb2_dc[0] += df2_dc\n",
    "                dfb2_dc[1] += db2_dc\n",
    "                dfb3_dc[0] += df3_dc\n",
    "                dfb3_dc[1] += db3_dc\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "\n",
    "\n",
    "      \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in range(len(filters)):\n",
    "                v_adam[i][0] = beta1*v_adam[i][0] + (1-beta1)*df[i][0]/batch_size #f1\n",
    "                s_adam[i][0] = beta2*s_adam[i][0] + (1-beta2)*(df[i][0]/batch_size)**2 #f1  \n",
    "                filters[i][0] -= lr*v_adam[i][0]/np.sqrt(s_adam[i][0] + 1e-8)\n",
    "                \n",
    "                v_adam[i][1] = beta1*v_adam[i][1] + (1-beta1)*df[i][1]/batch_size #f2\n",
    "                s_adam[i][1] = beta2*s_adam[i][1] + (1-beta2)*(df[i][1]/batch_size)**2  #f2\n",
    "                filters[i][1] -= lr*v_adam[i][1]/np.sqrt(s_adam[i][1] + 1e-8)\n",
    "                \n",
    "            for i in range(len(bias)):\n",
    "                bv_adam[i][0] = beta1*bv_adam[i][0] + (1-beta1)*db[i][0]/batch_size #b1\n",
    "                bs_adam[i][0] = beta2*bs_adam[i][0] + (1-beta2)*(db[i][0]/batch_size)**2  #b1\n",
    "                bias[i][0] -= lr*bv_adam[i][0]/np.sqrt(bs_adam[i][0] + 1e-8)\n",
    "                \n",
    "                bv_adam[i][1] = beta1*bv_adam[i][1] + (1-beta1)*db[i][1]/batch_size #b2\n",
    "                bs_adam[i][1] = beta2*bs_adam[i][1] + (1-beta2)*(db[i][1]/batch_size)**2  #b2\n",
    "                bias[i][1] -= lr*bv_adam[i][1]/np.sqrt(bs_adam[i][1] + 1e-8)\n",
    "            \n",
    "            for i in range(len(f_dc)):\n",
    "                fdc_v_adam[i][0] = beta1*fdc_v_adam[i][0] + (1-beta1)*dfb[i][0]/batch_size #f1\n",
    "                fdc_s_adam[i][0] = beta2*fdc_s_adam[i][0] + (1-beta2)*(dfb[i][0]/batch_size)**2  #f1\n",
    "                f_dc[i][0] -= lr*fdc_v_adam[i][0]/np.sqrt(fdc_s_adam[i][0] + 1e-8)\n",
    "                \n",
    "                fdc_v_adam[i][1] = beta1*fdc_v_adam[i][1] + (1-beta1)*dfb[i][1]/batch_size #b2\n",
    "                fdc_s_adam[i][1] = beta2*fdc_s_adam[i][1] + (1-beta2)*(dfb[i][1]/batch_size)**2  #b2\n",
    "                f_dc[i][1] -= lr*fdc_v_adam[i][1]/np.sqrt(fdc_s_adam[i][1] + 1e-8)    \n",
    "            \n",
    "            v_out_f = beta1*v_out_f + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out_f = beta2*s_out_f + (1 - beta2)*(dout_f/batch_size)**2  #f\n",
    "            out_fb[0] -= lr*v_out_f/np.sqrt(s_out_f + 1e-8)\n",
    "            \n",
    "            bv_out_b = beta1*bv_out_b + (1 - beta1)*dout_b/batch_size #b\n",
    "            bs_out_b = beta2*bs_out_b + (1 - beta2)*(dout_b/batch_size)**2  #b\n",
    "            out_fb[1] -= lr*bv_out_b/np.sqrt(bs_out_b + 1e-8)\n",
    "            \n",
    "            '''\n",
    "                        for i in range(len(filters)):\n",
    "                filters[i][0] -= lr*df[i][0]\n",
    "                bias[i][0] -= lr*db[i][0]\n",
    "            \n",
    "            \n",
    "            f_dc[0][0] -= lr*df1_dc\n",
    "            f_dc[0][1] -= lr*db1_dc\n",
    "            \n",
    "            out_fb[0] -= lr*dout_f\n",
    "            out_fb[1] -= lr*dout_b\n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            #print(\"Batch:{}\".format(c+12))\n",
    "            \n",
    "           \n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            '''\n",
    "            #print(\"Cost : {:.5f}\".format(cost/batch))\n",
    "            #print(\"Accuracy : {:.5f}%\".format((accuracy*100)/batch))\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        \n",
    "        print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "    #pack filters\n",
    "    params_values = [filters, bias, f_dc, out_fb]\n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.49924726 0.49924728 0.49924728]\n",
      "  [0.49924721 0.49924725 0.49924725]\n",
      "  [0.49924721 0.49924725 0.49924725]]]\n",
      "Epoch:     1   -   cost: 0.69   -   Accuracy: 50.39%\n",
      "Epoch: {2}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.50741502 0.50748867 0.50748919]\n",
      "  [0.50748918 0.50759884 0.50759968]\n",
      "  [0.50748979 0.5075998  0.50760075]]]\n",
      "Epoch:     2   -   cost: 0.68   -   Accuracy: 50.54%\n",
      "Epoch: {3}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.52003454 0.52223046 0.5227624 ]\n",
      "  [0.52222884 0.52567938 0.52653039]\n",
      "  [0.52276277 0.52653343 0.52749251]]]\n",
      "Epoch:     3   -   cost: 0.68   -   Accuracy: 50.88%\n",
      "Epoch: {4}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.56838026 0.59424411 0.60355728]\n",
      "  [0.59421632 0.63531348 0.65009476]\n",
      "  [0.60355806 0.65014118 0.66710434]]]\n",
      "Epoch:     4   -   cost: 0.62   -   Accuracy: 53.54%\n",
      "Epoch: {5}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.52132512 0.52356189 0.52397024]\n",
      "  [0.52356002 0.52700353 0.52763308]\n",
      "  [0.52396884 0.52763405 0.52831786]]]\n",
      "Epoch:     5   -   cost: 0.68   -   Accuracy: 50.88%\n",
      "Epoch: {6}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.52906404 0.53050467 0.53084019]\n",
      "  [0.53052619 0.53280452 0.53337425]\n",
      "  [0.53087557 0.53339383 0.53410411]]]\n",
      "Epoch:     6   -   cost: 0.67   -   Accuracy: 51.01%\n",
      "Epoch: {7}\n",
      "Batch: 1\n",
      "Image: 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-66943ed6ae5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mparams_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#0.05 stable LR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-147518990343>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(X, Y, epochs, learning_rate, dropout, mode, params_values)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[1;31m########### 4th Big Layer ###########\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                 \u001b[0mconv4_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpl3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#conv1 shape = (num_channels, h, w)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m                 \u001b[0mconv4_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconv4_1\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m#Relu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-dba706f20d36>\u001b[0m in \u001b[0;36mconv\u001b[1;34m(image, params, s, pad)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_h\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_w\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0mnp_o\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0m_h\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf_size\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp_o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values = train(train_images, train_labels, 10, 0.01, True, 'train',0) #0.05 stable LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.01798621 0.01798621 0.01798621]\n",
      "  [0.01798621 0.01798621 0.01798621]\n",
      "  [0.01798621 0.01798621 0.01798621]]]\n",
      "Epoch:     1   -   cost: 0.15   -   Accuracy: 85.80%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3iU5Zn48e89hxwnB5KQSBASkAhGzkaD4IWK2xaKFdmrHn9b3dVd7GUPuv21VVu73e7l/la7PenW0rW6ba2ttastuvZAEYoF1opigALhEAiHkAOBnDOZzOF9fn9kZhowCGSOmbk/15UrM+/MvO+dzLz3PM/zPgcxxqCUSl+2RAeglEosTQJKpTlNAkqlOU0CSqU5TQJKpTlNAkqluZglARFZKiL7RKRBRB6O1XGUUpGRWPQTEBE7sB/4ENAEvAPcYYzZE/WDKaUi4ojRfq8CGowxhwBE5OfACmDEJCAixmbTmolSsWRZ1kljzPgzt8cqCUwEjg273wTUDn+CiKwCVgVvk5WVFaNQlFIAbrf7yEjbY5UEZIRtp9U7jDHPAM8A2O127busVILEqgzeBEwadv9ioDlGx1JKRSBWSeAdoEpEpohIBnA78FqMjqWUikBMqgPGGL+IfBpYC9iB/zLG7I7FsZRSkYlVmwDGmN8Av4nV/pVS0aHX5ZRKc5oElEpzmgSUSnOaBJRKc5oElEpzmgSUSnOaBJRKc5oElEpzmgSUSnOaBJRKc5oElEpzmgSUSnOaBJRKc5oElEpzmgSUSnOaBJRKc5oElEpzmgSUSnOaBJRKc5oElEpzmgSUSnOaBJRKc5oElEpzmgSUSnOaBJRKc6NOAiIySUT+ICL1IrJbRB4Ibi8SkXUiciD4e1z0wlVKRVskJQE/8H+NMZcBC4BPiUg18DCw3hhTBawP3ldKJalRJwFjTIsx5r3g7V6gHpgIrAB+HHzaj4GbIw1SKRU7UVmQVEQqgXnA20CZMaYFhhKFiJSe5TWrgFXB29EIQyk1ChE3DIqIC3gFeNAY03O+rzPGPGOMqTHG1GgSUCpxIkoCIuJkKAH81Bjzy+DmNhGZEHx8AnAishCVUrE06uqADH19PwfUG2O+Neyh14C7gceDv1+NKEKVlkKlQxFBRLDZbNjt9vc9z7IsAoEAgUDggo8R2udI+42EZVn4/X4sy4rqfmNFjDGje6HINcAm4M9A6K/9EkPtAr8AJgNHgVuMMR0ftC+73W6ysrJGFYca2yzLwuv1YrfbcTgc5OTkkJGRQWFhISUlJZSWlnLZZZdRXl7OtddeS1ZWFg7H0HeX3++nrq6Ouro6nn76aTweD16vl4yMDGy2sxdyjTH4/X5uvvlm5s2bx80330xubm7U/qY333yTNWvWsHnzZk6dOkVmZmbU9h0Jt9u9zRhTc+b2UZcEjDGbgbNV5m8Y7X5V6rPb7WRkZHD55ZfjcDgYHBzE6XTicDhwuVxkZmaSl5dHQUEBxcXFzJkzh4suuoipU6fidDrD39yWZWGMITMzkx07duB2u/F4PAwMDDA4OMjJkycJBAIYY3C5XOTk5FBeXo7NZsPv93PFFVdQW1vLlClTiOaXUE1NDUePHkVEOHLkCA0NDfh8Pkb7hRtroy4JRJOWBNJLcXEx06ZN45VXXsHlco34nOGNxaEqQehnuFAiCBW9jTHs3buXAwcO8Pzzz9PT08PAwACLFy+murqaW2+9FafTGd6vzWYbcb+RsCwrHFdHRwdLliyhtbUVj8cTtWOMRtRLAkqdL2MMgUCACRMmMGvWLObPn8+MGTPIyckJn5CjFSr2h0oHxhgmTpwYLt57vV58Ph+XXHIJxcXFZGZmRr0NYKSYQnHl5+fz4IMP8tZbb/HSSy/F9LijpSUBFVMigjEGj8fD4sWLufXWW1m5ciUXXXRRokOLG2MMGzdu5MYbb0xoHFoSUBfM6/WGi9lnFs/PRkSw2+3k5uaSl5fHLbfcwrRp05g/fz4FBQWMGzeOvLy8mMeeLCzLwuPx0NNz3l1o4k6TQBo5W6kvdOJmZmZSUFAQbqRzu93ve83wS3cjCV12KyoqYvz48SxatIjp06dz6aWXfmCLfaqyLIuuri5OnEje7jKaBNKI1+sNX08PncQ2mw2n00llZSW1tbV8/vOfp6ioiPz8/Ihas0ONbQ6H47Q6crpxu9188YtfZPfu3YkO5aw0CYxhoVbo0KW1KVOmMHXqVEpLRxyuMWIHltAJWlZWxrRp0ygvLycrKyuql8zSmWVZHDhwgNbW1kSHclaaBMYwn88XTgLl5eX89V//NStXrqSqqirRoakgy7I4dOgQXV1dZGRkJDqcEWkSGCN8Ph8ALpeL2tpali9fTllZGS6XC6fTSW5uLhMmTKCkpCTBkSoYan9pbGxkz549GGPCvRyTUfJGlsZC9emMjIxwD7nBwUFEhKKiImbPns2KFSsoKSkhOzs70eGqM4TGM+zevZs//elPGGOSuk1Ek0ASCdXZS0pKmDx5Mh/96EdZvHgxs2bNCjfS2e12nE4n2dnZSf3BSmcHDx7kt7/9LWvWrGH//v0MDg4mOqQPpEkgwUSE8ePHU1tbSyAQwLIsCgsLw5fXpk2bpkX8McLr9dLc3My7777Le++9x6FDh+js7Ex0WOekSSDBbDYby5Yt47vf/e77HtPJVsaWtrY2brjhhvB4hWTojXs+NAkkSFVVFRUVFXzkIx/hiiuu0KL9GOXxePB4PLzxxhvU1dXR09PD4ODgmEkAoEkg7kIj16qrq5k9ezb33HOPXpMfg4wxGGNwu920tbXx1a9+lX379iXN3AEXQpNAnM2ZM4frr7+ej3/841RWVibttWP1wY4fP863v/1tjh07xpEjR2hubh6z76UmgTgyxlBeXs6CBQuorKyksLAw0SGpswjNUTAwMIDf7z9tUhAR4cCBA2zYsIFjx47R0dFBVlbWmG3D0SQQJ8YYBgcHmTZtGsuWLdM2gCRnWRa9vb08+eST7N27ly1btjAwMEAgECAzMxPLssIDrMZyAgBNAnFljInJxJbpzuPx0NbWxsmTJ+no6Ah3p76QxrnQYKcQn89He3s727dvp7Gxkc7OzvDQao/Hc95Dq8cCTQJqzOvv7+eXv/wlmzdvZsOGDfT19YXnFjxfNpvtnA20ydz1NxKp+VclIRHB6XQiIgQCgfDcdmp0mpubOXbsGC+//DItLS00NDTQ2tqK3+8PD1++EOlcPdMkEEcOhwOPx0N/fz/Z2dkRz6+Xzpqbm/nf//1fnn/++fdN653O8xeMhv6n4uzll1/mtttu49ChQ4kOZUxbs2YN//Iv/0JfX9+YvTSXLLQkEGfd3d38+c9/ZmBgINGhjEl9fX0cOXKEgwcP0tvbS0ZGhlarIqRJIM76+vro7OxM+pFlyWrPnj3ccccddHd3j8neeckoGqsS20WkTkReD94vEpF1InIg+Htc5GGmjtDqOx0dHfT29o6Z9eqShdfrpb29PeELeaSSaLQJPADUD7v/MLDeGFMFrA/eV0E2mw2Hw0FbWxsdHR1jaqBJMggEAvT29oZnWlKRi3Rp8ouB5cCzwzavAH4cvP1j4OZIjpGq/u3f/o3Pfe5z+o12gULX87XDVfRE2ibwHeCLwPDVJMqMMS0AxpgWERlx6lsRWQWsCt6OMIyxp6mp6bQ19May3t5e+vr6wj3qzlzbLzTiDoZO4qKiovDqwqN57/XyX3SNOgmIyI3ACWPMNhG57kJfb4x5BngGhpYhG20cKvH+53/+hxdeeIG3334bj8fzvga70DJkdrudrKwsnnrqKa677jrKysr0Gz0JRFISWATcJCIfBbKAfBF5AWgTkQnBUsAEIHmXXkmwvr4+XnrpJWpqapg7d26iw7lgJ0+e5PXXX2fDhg00NDTg8XhGrKsbY05b82Dt2rUcOXKECRMmcNlll1FbWxvv0NUwUVmQNFgS+Lwx5kYR+XfglDHmcRF5GCgyxnzxg16frguShorGt912G0888cSYqhYZY9i6dSuLFi3CbrePql+9iHDbbbfxzDPPhIv4H/Q/MMawadMmli1bNuq401k8FyR9HPiFiNwLHAVuicExUoJlWXR3d3P48GF2797N5MmTyc/PT3RY5zQwMMA//dM/sWvXrvB4iNEwxvDGG29w++23c9VVV3HFFVdw9dVXjziNutvt5pvf/CY7d+6MNHx1hqgkAWPMRmBj8PYp4IZo7Dcd+Hw+Wltb2bFjB3a7HWMMLpcrqevKgUCA9evX09jYGHEj3YkTJ3jllVfCc/VNmTKF4uJicnJywmMA/H4//f39bNy4Ubtbx0BUqgORStfqQIjdbic7O5uioiIuvvhifv7zn1NcXJzosM6qr6+PK6+8kqNHj0Zlf8YYMjIycDgcZGRkcNVVV/H0009TWFhIbm4uhw8fZt++fdx77710dXVp34pRimd1QF2gQCBAX18ffr8fj8fDr3/9ayZNmoRlWeGlvnNycrDb7Xi9Xvx+P36/P3wprrCwkHHjxnHxxRfHPNZTp07R1NQU1f4NIoLP58Pn8+F2u9m3bx+//vWvKSkpoaioiF27dnH06FE8Ho8mgBjQkkCSCs1gk5WVRU5ODpdeeik5OTk0NzfT399PV1cXNpuNzMxMFi9ezOLFi/n0pz8d88bFdevWsXHjRp599ln6+vpieiwVXVoSGGNCaxGGviWPHDmCw+EIz3MXmj5rcHCQbdu20dLSwoEDB5g1axbV1dXMnz8/JusUvv322/z2t7/VUZApRJNAkho+510gEKC7u/t9zwn1OGxra6OlpYUtW7awbNkyWltbmTlzZkySwPHjx6mvr9deeylE38kUYbPZyM7OZtOmTaxevTpmRXWfz4fX69W6eQrRkkAKEREGBwexLItDhw6RmZlJcXFxVNsJho8DUKlBSwIpxul0YrPZePrpp/nRj36UEgOUVGxpSSAFGWPYsWMH+fn5Uf3W1hJAatIkkIKMMRw6dIhJkyZF/cQ9c5iwGvu0OpCiAoFA1GffEZFwvwVNBKlDk0CKitWEJSUlJVRWVib12AZ1YTQJpKhY1d8/9rGPcf/99+NyuWKyfxV/2iaQohwOR0zWzgu1M+iCH6lDk0CKcjqdMTlRS0tLycnJ0Tn/U4hWB1LY4cOHef7559m7d2/U9+3z+fD7/VHfr4o/TQIprKenh82bN7N///7wwKNoKS0tHROzIKlz06HEKSw0EnHBggUsXLiQVatWUVo64gzwF8Tr9bJ582b+8Ic/8K1vfSsKkap40KHEaSg01LixsRGXy8W2bduYPn06FRUVEV3is9vtXHLJJRw/fhyXy8Xg4KCuCDSGaRJIA0ePHuXo0aO0trYye/ZsvvGNb0ScBCoqKpg/fz5lZWW0t7drEhjDtE0gjRw6dIjdu3dz+PBhOjs7I97f5MmT+cEPfsDy5cvJzs7WXoRjlCaBNNLZ2UljYyN79uzh5MmTEe8vLy+P2tpa5s2bR1lZGU6nMwpRqnjTJJBmTp06xYMPPsgLL7wQtX3+3d/9HevXr2fu3Lnaf2AM0iSQZgKBAC0tLRw/fpzu7m68Xm/E+8zJyaGkpITrr7+eJUuW4HK5tEfhGKJJIM2ELhseOXKEV199lVOnTkVlvw6Hg6985St8+9vfpqqqioKCgqjsV8VeRFcHRKQQeBaYCRjgHmAf8BJQCRwGbjXGRN4KpaLq4MGDvPbaa8yZM4cJEyZEZZ8iQlFREV/5ylfo6emhu7ubn/zkJ+zdu5eurq7wqEaHw6ETlSaRSC8RPgn8zhjzcRHJAHKALwHrhy1I+jDwUITHUVF2/PhxGhsbueeee5g5cyY2my0qrfu5ubl85CMfwbIsAoEAu3btor29Pby4CgyNawgNbrIsSy8vJtioewyKSD6wA5hqhu1ERPYB1w1bmnyjMWb6B+1LewzGX2jC0OnTp3P55ZezevXqqHcDNsbQ0dGB2+0OJwBjTLgUYIyhrq6OT3/60wwMDESlfUKdXSx6DE4F2oEfisgcYBvwAFBmjGkBCCaCEfupisgqYFXwdgRhqNEITRNWX1/P8ePHOXz4MBUVFVGty4sIxcXFZ11XMZSIFi1aRGNjI62trfT09ER1jIM6t0hKAjXAn4BFxpi3ReRJoAf4jDGmcNjzOo0x4z5oX1oSSCwRIT8/nxtvvJHvf//7ca2vh6oNmzZtYs2aNaxZsyZqjZXqdGcrCUTybjcBTcaYt4P3XwbmA23BagDB3yciOIaKA2MMvb29HDx4kK1bt9Le3h63Y9tsNpxOJ1VVVdx0002Ul5ejXwjxNeokYIxpBY6JSKi+fwOwB3gNuDu47W7g1YgiVHFhWRb19fU89thj7Nq1K+7HnzRpEtdddx2XXHIJLpdLq4hxFGm57zPAT0VkJzAX+H/A48CHROQA8KHgfTUGuN1udu7cSUNDA319fXGvm9vtdh577DG++93vUlRUpL0P4ySiS4TGmO3A++oYDJUK1Bjj8/k4deoUTU1NnDhxgokTJ8Z1VmERYcqUKeTk5FBdXU1zczMdHR309PTg9/u1dBAjOqmIep/s7GwKCgrYuHEjkyZNivvxLctiYGCAI0eO8NZbb/Hkk0+yZ8+e8FLtanR0UhF13vr7+/F4PDQ2NpKdnR31RU3PxWazkZubS3l5OTU1Ndxyyy00NDSwY8cOOjo6aGtrw263a0KIEk0C6n1CvQf/+7//myuvvJI777wzJtOXn0thYSGFhYXMmTOH/v5+Hn/8cbZt28axY8fIyMhISEypSP+LakTGGDZu3EhPTw9Lly4lLy+P7OzshMWTkZHBXXfdxcKFC5kxYwbr1q1j7969OJ1OLRFESJOAGpExhj179uD1emlubqa8vByn05mwYnioL8H48ePJycmhqamJxsZGXSk5CrRhUJ2VMQaHw0FpaSkLFixg8eLFrFy5kvHjxycsptBCqy0tLRw7doy77rqL5uZmndXoPGjDoLpgIoLf76exsZHMzExycnK49NJLueSSSygvL0/IoqR2ux273U5ZWRlZWVl8+MMfZs+ePezcuRPLsrRkMApaElDnJTTgyG63U1lZyZYtW8jNzU1oTKEBSHv37mXJkiV4PB4dlvwBYjF2QKWR0FLnPp+PtrY2vve977F27VpaW1vxeDwJiUlEsNlslJeX8/Wvf52bbrqJgoICXTb9AmkSUBesu7ubhx56iK9//evs37+fvr6+hBbDCwsLueuuu1i2bBmlpaXaPnCBtDqgRsWyLFwuF5MmTeJDH/oQNTU1LF++nJycnITF1NPTQ3t7O5/5zGd45513cLvdCYslGWnDoIoqm81GT08P27dvp6CggMHBQWpqahg/fjwulyshMeXn55Obm8ucOXMYGBigrq4Ov9+vjYXnoCUBFZHQZUSn08nMmTNZvHgxX/va1xI6kajP56O5uZnrr7+erq4uBgcHExZLMtGGQRUTIkIgEGBwcJAjR46wfft21q5dS0NDA263OyFThTmdToqKirj//vtZunQp2dnZOrvxB9CSgIoqy7Lwer184Qtf4P7776esrCyh8wK88cYb3HfffXR2dqZ9ieBsJQFNAiqqQtfuZ8yYwaxZs3C5XFx00UWsWrWKvLy8uPct6Orq4tChQ3z5y19mw4YNaT3oSBsGVVyEOhXt37+f/fv34/f7qaioYOnSpUyYMAGbzUZGRkbcruUXFhYyb948ZsyYwc6dO+nu7taGwjNoSUDFnN1uZ/z48UycOJEpU6bw6KOPUlVVFdcYurq6aGpq4sYbb4zrRKrJREsCKmECgQCtra243W56enrYsmULlmVxySWXxK14npubS2lpKSKCZVnaUDiMlgRU3GVmZjJ58mQ2bdpEXl5e3I7b09PDZZddRltbW1pOYqqXCFXSCI0/eOKJJ1i7dm3cjmuz2bjyyiuprKyM2zHHAq0OqLizLIuenh6++c1vcuzYMZYsWYLdbo95Ed1utzN9+nS8Xi8tLS0xPdZYoiUBlTA2m43Nmzdz//33s2PHjpgfLzMzky996Uvcd999eDye8CKp6U6TgEqorq4uNm/eHJf1B202GwUFBVRWVjJt2jQKCwvP/aI0oElAJdTAwAANDQ10dXXF7ZgVFRU89dRTXHvttXE7ZjKLKAmIyD+KyG4R2SUiL4pIlogUicg6ETkQ/P2BKxKr9BaarCSeV6mysrKorq6mvLycnJyctJ+teNRJQEQmAp8FaowxMwE7cDvwMLDeGFMFrA/eVyppZGVlMWnSJCZNmkReXl7a9xmI9K93ANki4gBygGZgBfDj4OM/Bm6O8BgqhTkcDsaNG5eQ5cgty9LGQSJbmvw48A3gKNACdBtjfg+UGWNags9pAUpHer2IrBKRd0Xk3WTosKTizxhDbm4u06dPp6CgIG7HDc2VODg4qJOOEFl1YBxD3/pTgHIgV0T+5nxfb4x5xhhTY4ypSfc6Wbry+/3U1NTw3HPPMXfu3Lgdd2BggAMHDtDY2EhPTw+WZcXt2Mkoks5CfwU0GmPaAUTkl8BCoE1EJhhjWkRkAnAiCnGqMcwYQyAQCK8ZMGXKFMrLy5k+fTqzZ8/moosuims33u7ubl5//XUOHTqU9qUAiCwJHAUWiEgOMADcALwL9AN3A48Hf78aaZBq7PP5fBhjyMjI4Nprr2XBggV8/OMfT0gf/qNHj/LII4/gcDjSen6BkFH/B4wxb4vIy8B7gB+oA54BXMAvRORehhLFLdEIVCU/r9eLw+EgPz+fm2++mY997GO4XC5sNlt45J7NZqOsrIz8/Py4n4DGGAYGBujt7cXhcOj6BEERvQvGmK8CXz1j8yBDpQKVRkSE/Px8srKyKC0tZeHChdxwww1xnUDkXCzLoqurixMnTmgJYBj9T6iI2Ww28vLy+M1vfsPFF1+M0+kkMzOTzMzMpOqI4/F4eOCBB9i1a1eiQ0kqmgTUqFiWRWZmJuPGjeOyyy6jsrKSiooKCgoKkrbzjWVZ7N27V0cQnkGTgLpgxhgGBwcpLS1lyZIlfPazn2X27NlJ9a0/EmMMHR0d9PX1peWkImejSUCdl1DvuszMTIqLi3nggQeYPHlyuASQ7AlAnZ0mAXVOdrs9fJJnZ2czceJE7r33XlwulzawpQB9B9VZ+f1+iouLufPOO7nyyitZsGABIoLD4cDlciVNq/+FyMrKIiMjI9FhJBVNAuo0IsLEiROpqKjA7/czfvx4FixYwJw5c6ioqEh0eBELrYug/kKTgAoLfct/4Qtf4K677gqfLDabTU+cFKZJIM35/X5sNhtVVVVMnTqVRYsWsWjRIpxOZ0qd+IODg7jdbh0rMAJNAmkuNIJu3rx5XHPNNfz93/99Sp38IR6Ph87OzoSskpzsNAmkqdDIvvvvv58lS5Ywa9YsCgoKUi4B+P1+vF4vq1ev5s0336S7uzvRISUdTQJpxBgTnnE31LV34cKFLFy4kKKiojHZ2j8Sy7KwLIuBgQE8Hg9ut5u33nqL3//+90nXlTkZaBJII36/n3HjxvHwww9zxRVXMGfOHJxOJw6HI2m7+l6o0EjBpqYmVq5cycDAADA0tbkmgJFpEkhxNpuN6upq5s6dG76+f/XVV1NeXk5ubm6iw4uqrq4u2traOH78OHv27KGpqQm/3x8+8TUBjEyTQAoTEZxOJzfddBMPPvggWVlZKVPkH8k777zDs88+y6ZNm8J1fz3xz02TQIoJXfK78847mTJlCgsWLGDq1KlkZGSkTJH/TF1dXbzyyits2bKFurq6cBVAnR9NAikmMzOTnJwcFi1axBVXXMGsWbNS9uQ3xuDz+WhtbeWFF17g8OHDnDihU1peKE0CKUJEsNlsPPbYY9xxxx3k5uamVIPfmULDmT/5yU+yfft2jh07hs/nS3RYY5ImgTEsdMlvypQpFBUVMXHiRGpraykpKUm5urDf76e1tRWfzxdeMKS/v5+tW7dy9OhR7QkYAU0CY5jP5yM7O5tVq1Zx1VVXUVNTk7L9/N1uN6tWraK+vp6mpiYyMzNxOBy6eEgUaBIYQ4wx4ZF91dXV1NbWMm3aNBYuXMi4ceNSpuV/YGCA9957j7a2NlpaWrDb7fT09LB//356e3sBCAQCevJHiSaBMWL4ENiysjJqamr4h3/4h5QY3jucZVn09vbywx/+kPfee4+6ujoyMjJOm7xE5wOILk0CSc7v9xMIBFiwYAHV1dU8+OCD5OXlkZubm3Kdffx+P48++ijbt2+nvr6evr4+srKyUrJ6k0w0CSQhYwx2u528vDxcLhcFBQXU1NRQXV1NVVUVTqcz0SFGlTGG/v5+urq62LhxIzt27Ahf1UjVqxvJRJNAEhocHKSkpIQVK1Zw6623snDhwnCDX6rN6ReawPTpp5/miSeewOv16okfZ+f8RInIfwE3AieMMTOD24qAl4BK4DBwqzGmM/jYI8C9QAD4rDFmbUwiTyGhYb0VFRVUVFQwe/ZsysrKmDdvHtOmTUvJ6bH9fj/btm2jt7eXnp4etm3bRl9fHw6HQ4v/cSbnamEVkcVAH/D8sCTwdaDDGPO4iDwMjDPGPCQi1cCLwFUMLVf+BnCpMeYDZ3Kw2+0mKysr8r9mjDLG4PV6WblyJVdffTWrVq3C5XIlOqyYcrvdrFixgt27d+sY/zhxu93bjDE1Z24/Z0nAGPNHEak8Y/MK4Lrg7R8DG4GHgtt/bowZBBpFpIGhhPDWaANPFaETPdSz75prrmH69OncfvvtZGdnY1kWRUVF5OXlkWoJsb+/n9WrV9Pe3k5nZydOpxOfz0d9fT1utzvR4aW90VYwy4wxLQDGmBYRKQ1unwj8adjzmoLb3kdEVgGrgrdHGcbYUFxcjMPhwOv1YrfbsdvtzJo1i7lz51JbW5uSxX2v1xvuxnvy5El+9atf0djYSGtra3gOA5Ucov1OjHQ2j1jfMMY8w9BS5tjt9pTs9eH3+7Hb7Tz33HNcfvnluFyucMIL9etP1Wvev/vd73j00UcJBAL4fD5OnDiB3+/XS35JaLRJoE1EJgRLAROA0NCtJmDSsOddDDRHEuBYJSLMnz+f2bNnU1VVRVFRUUrPbGOMoa+vD7fbzfHjx/njH//I4cOHsSzrtJ59qfr3j2WjTQKvAQdPdzkAAAkkSURBVHcDjwd/vzps+89E5FsMNQxWAVsjDXKsCV3Ku++++/jbv/3bRIcTF5ZlsWvXLrZs2cIjjzwSntBEJb/zuUT4IkONgCUi0gR8laGT/xcici9wFLgFwBizW0R+AewB/MCnznVlINVkZ2cza9YsPve5zzF37txEhxMXdXV1bN68mbq6Oo4dO4bNZtNr/WPI+VwduOMsD91wluf/K/CvkQQ1FoX6t48bN46ZM2eyfPnylDwRjDHhfg2hYv6GDRtYvXo1J0+exOfzaaPfGKPv1iiFJrUINe7dc889fPjDH6a6upr8/PyUTAAAHR0dtLa28s///M+cOnUKEeHw4cOcOnUqPM5fjS2aBM4htEKPzWYjPz+fkpISJk6cSHZ2Nh6PB7vdTmZmJldffTUzZsxgwoQJKfVN6Pf7w9/wPp+PpqYmDh06xJYtW+jq6tKGvhSQOp/WGPF6vcBQXb+2tpbly5ezYsUKiouLT3teaKhvqp0UPT093HfffdTX13PkyBEyMjKw2+34fL6U+1vTlSaBs1i6dCnz588PT9OdkZHB1KlTmTp1Knl5eSkzgcfZGGN488032bp1K/v376ezszM82CdUOlKpQZPAGUKX95YsWcInPvEJcnNzU/6EP1NoBqMnnniCdevWhXs0pmrHpnSnSSDIZrNRXl7OwoULeeihhygrKyMnJydlG/g+yPr16/nP//xP6urq9Fp/GtAkwF8m8ZgzZw7z589n+vTpaVffDXXvdbvdbN68mV/96lcpvWCJ+gtNAgzN2pubm8t3vvMdxo8fn3YJwLIs2tvb+fOf/8wnPvEJPB4PGRkZafd/SFeaBCA8Z39ubm7KF39DQ5q7u7vZu3cvgUAAv9/P0aNH2bt3Lx0dHSk5g5E6O32ngcrKSqqrq9Oi6Buaz2/z5s2sWrWK3t5evF4v2dnZ2t8/TWkSAO644w6WL1+ecpN5hNTX1/Piiy/S19eHz+djcHCQpqam8PwG2uqf3jQJAPPnz6eqqirRYURV6Hq+3++nrq6OH/zgB3R0dODz+U4b069Ff6XvfgqyLItt27ZRV1fHf/zHf9DZ2RmexNNut2uDnzqNJgHg+PHjdHR0UFBQMOY7BvX399Pd3c3WrVvZuXMnDQ0NGGPCdX1NAOpMmgSAdevW0d3dzd133012dnaiw4nI7t27ee211/jZz37GiRMntKivzkk/IQxNitHZ2UlnZydz5szhuuuuw+l0Jl1LeSAQoKenh97eXk6dOsWJEyfo6Oigvb0dr9dLIBDgwIEDHDx4kN7eXl2wU52Xc647EA/Jsu6A3W5n6dKlPPXUU7hcrqS7WuD3+zl48CBNTU2899577Nq1i8OHD7Nnzx7cbjderzcpk5dKDmdbd0CTwDAiQl5eHpdeeikZGRlJdzJZlkVXVxcej4fe3l4GBgbwer14PJ7whJ6pOJxZRYcmAaXS3NmSQOp3kVNKfSBNAkqlOU0CSqU5TQJKpTlNAkqlOU0CSqW5cyYBEfkvETkhIruGbft3EdkrIjtF5FciUjjssUdEpEFE9onIR2IVuFIqOs6nJPAjYOkZ29YBM40xs4H9wCMAIlIN3A5cHnzN90RkbI/IUSrFnTMJGGP+CHScse33xpjQmlN/YmgJcoAVwM+NMYPGmEagAbgqivEqpaIsGm0C9wC/Dd6eCBwb9lhTcNv7iMgqEXlXRN5Nhl6LSqWriEYRisiXGVqC/KehTSM8bcQz3BjzDPAMDHUbjiQOpdTojToJiMjdwI3ADeYvX+VNwKRhT7sYaB59eEqpWBtVdUBElgIPATcZY9zDHnoNuF1EMkVkClAFbI08TKVUrJyzJCAiLwLXASUi0gR8laGrAZnAuuCw1T8ZYz5pjNktIr8A9jBUTfiUMSYQq+CVUpHTocRKpQkdSqyUGpEmAaXSnCYBpdKcJgGl0pwmAaXSnCYBpdKcJgGl0lxS9BMQkXagHziZ6FiAEjSO4TSO043lOCqMMePP3JgUSQAgOJrwfR0ZNA6NQ+OIbRxaHVAqzWkSUCrNJVMSeCbRAQRpHKfTOE6XcnEkTZuAUioxkqkkoJRKAE0CSqW5pEgCIrI0uE5Bg4g8HMfjThKRP4hIvYjsFpEHgtuLRGSdiBwI/h4Xh1jsIlInIq8nMIZCEXk5uKZEvYhcnaA4/jH4fuwSkRdFJCtecZxlnY2zHjtW62zEc72PhCeB4LoETwPLgGrgjuD6BfHgB/6vMeYyYAHwqeCxHwbWG2OqgPXB+7H2AFA/7H4iYngS+J0xZgYwJxhPXOMQkYnAZ4EaY8xMwM7QWhbxiuNHvH+djRGPHeN1NkaKIzbrfRhjEvoDXA2sHXb/EeCRBMXyKvAhYB8wIbhtArAvxse9mKEP1xLg9eC2eMeQDzQSbCwetj3ecYSmrS9iaPq714EPxzMOoBLYda7/wZmfVWAtcHWs4jjjsZXAT6MRR8JLAlzAWgWxJCKVwDzgbaDMGNMCEPxdGuPDfwf4ImAN2xbvGKYC7cAPg9WSZ0UkN95xGGOOA98AjgItQLcx5vfxjuMMZzt2Ij+7o1rvYyTJkATOe62CmAUg4gJeAR40xvTE+dg3AieMMdviedwROID5wGpjzDyGxnLErX0mJFjfXgFMAcqBXBH5m3jHcZ4S8tmNZL2PkSRDEkjoWgUi4mQoAfzUGPPL4OY2EZkQfHwCcCKGISwCbhKRw8DPgSUi8kKcY4Ch96HJGPN28P7LDCWFeMfxV0CjMabdGOMDfgksTEAcw53t2HH/7A5b7+P/mGDZP9I4kiEJvANUicgUEclgqIHjtXgcWIbmS38OqDfGfGvYQ68Bdwdv381QW0FMGGMeMcZcbIypZOhv32CM+Zt4xhCMoxU4JiLTg5tuYGjq+LjGwVA1YIGI5ATfnxsYaqCMdxzDne3YcV1nI2brfcSykecCGkA+ylBr50Hgy3E87jUMFZt2AtuDPx8FihlqqDsQ/F0Up3iu4y8Ng3GPAZgLvBv8f6wBxiUojq8Be4FdwE8YWuMiLnEALzLUFuFj6Bv23g86NvDl4Od2H7AsxnE0MFT3D31Wvx+NOLTbsFJpLhmqA0qpBNIkoFSa0ySgVJrTJKBUmtMkoFSa0ySgVJrTJKBUmvv/6a0dOIaGOKwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(train_images[0].reshape(1,1,128,128), train_labels[0].reshape(1,1,128,128), 10, 0.0001, True, 'predict', params_values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
