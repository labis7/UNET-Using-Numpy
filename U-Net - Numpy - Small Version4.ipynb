{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load from /home/USER/data/mnist or elsewhere; download if missing.\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "    \"\"\"\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist\n",
    "        path = os.path.join(os.path.expanduser('~'), 'data', 'mnist')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        with gzip.open(path) as f:\n",
    "            # First 16 bytes are magic_number, n_imgs, n_rows, n_cols\n",
    "            pixels = np.frombuffer(f.read(), 'B', offset=16)\n",
    "        return pixels.reshape(-1, 1, 28, 28).astype('float32') / 255\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        with gzip.open(path) as f:\n",
    "            # First 8 bytes are magic_number, n_labels\n",
    "            integer_labels = np.frombuffer(f.read(), 'B', offset=8)\n",
    "        def _onehot(integer_labels):\n",
    "            \"\"\"Return matrix whose rows are onehot encodings of integers.\"\"\"\n",
    "            n_rows = len(integer_labels)\n",
    "            n_cols = integer_labels.max() + 1\n",
    "            onehot = np.zeros((n_rows, n_cols), dtype='uint8')\n",
    "            onehot[np.arange(n_rows), integer_labels] = 1\n",
    "            return onehot\n",
    "\n",
    "        return _onehot(integer_labels)\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(os.path.join(path, files[0]))\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(os.path.join(path, files[1]))\n",
    "    print(\"Test Images  : Loading . . .\")\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    print(\"Test Labels  : Loading . . .\")\n",
    "    test_labels = _labels(os.path.join(path, files[3]))\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return train_images[0:2,:,:,:], train_labels[0:2,:] #, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are ready to gzip!\n",
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Test Images  : Loading . . .\n",
      "Test Labels  : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_label= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "#print(train_images.shape)\n",
    "temp = np.zeros((train_images.shape[0],1,128,128))\n",
    "for i in range(train_images.shape[0]):\n",
    "    #print(cv2.resize(train_images[i,0,:,:], (128,128)).shape)\n",
    "    temp[i,0,:,:]=cv2.resize(train_images[i,0,:,:], (128,128)).reshape(1,1,128,128)\n",
    "#print(train_images.shape)\n",
    "train_images= train_labels = temp\n",
    "print(train_labels.shape) \n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "#plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tone up\n",
    "train_labels[train_labels>0.8] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Convolution Architecture - Downsampling/Upsampling  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f,trim ):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    trimf = trim\n",
    "    trimb = trim*5\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trimf #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trimb\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \n",
    "    return filters, bias, f_dc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "\n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(np.multiply(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] , f[z, :, :, :])) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "\n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "    #print(arr.shape)\n",
    "    try:\n",
    "        idx = np.nanargmax(arr)\n",
    "        #print (idx)\n",
    "    except:\n",
    "        idx = 0\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h + a, _w + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "        print(\"Warning: Extra crop needed and handled!(%d --> %d)\" %(dim, img2.shape[1]))\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def NLLLoss(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[1]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] >= logs[:,i,j]):#Gray and above\n",
    "                out[:,i,j] = logs[:,i,j]/targets[:,i,j] \n",
    "            else:\n",
    "                out[:,i,j] = (1 - logs[:,i,j])/(1 - targets[:,i,j]) # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    res = out.sum()/mylen\n",
    "    return -np.log(res), res\n",
    "\n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "def normalize(output):\n",
    "    output[output<-10]=-4\n",
    "    output[output>10] = 4\n",
    "    return output\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch`\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, mode, params_values): \n",
    "    print(X.shape)\n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    trim= 0.00001\n",
    "    if(mode == 'train'):\n",
    "        filters,bias, f_dc = init_filters(4,16,trim) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "        ##Final 1x1 filter\n",
    "        trimf = trim\n",
    "        trimb = trim*5\n",
    "        out_f = np.random.randn(1,16,1,1)*trimf\n",
    "        out_b = np.random.randn(out_f.shape[0],1)*trimb  \n",
    "        out_fb = [out_f, out_b]\n",
    "        #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "        #image shape: (channels, height, width)\n",
    "    else:\n",
    "        [filters, bias, f_dc, out_fb] = params_values \n",
    "        [out_f, out_b] = out_fb\n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7]= bias \n",
    "    \n",
    "\n",
    "    f1_dc = f_dc[0][0]\n",
    "    b1_dc = f_dc[0][1]\n",
    "    f2_dc = f_dc[1][0]\n",
    "    b2_dc = f_dc[1][1]\n",
    "    f3_dc = f_dc[2][0]\n",
    "    b3_dc = f_dc[2][1]\n",
    "    \n",
    "    \n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]  \n",
    "\n",
    "            \n",
    "\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    prev_cost = 1000\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        \n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        batch = 1\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            print('Batch: {}'.format(int(c/batch +1)))\n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.9  #0.9\n",
    "            beta2= 0.99 #0.99\n",
    "            #lr = learning_rate\n",
    "            batch_size= batch\n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            cost = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            #Special setup for LR\n",
    "            if(e<4):\n",
    "                lr=0.03\n",
    "            ####TODO:Possible solution for unstable future results(from ~1x10-5 --> 0.98 possibility and back again),\n",
    "            #is to reduce dynamically the learning rate(this problem can also be reduced by making trims even smaller)\n",
    "            \n",
    "            if((e < 20)and(mode == 'train')):\n",
    "                \n",
    "                df =  []\n",
    "                db =  []\n",
    "                dfb=  []\n",
    "                for i in filters:\n",
    "                    v1 = np.zeros(i[0].shape)\n",
    "                    v2 = np.zeros(i[1].shape)\n",
    "                    s1 = np.zeros(i[0].shape)\n",
    "                    s2 = np.zeros(i[1].shape)\n",
    "                    v_a = [v1, v2]\n",
    "                    s_a = [s1, s2]\n",
    "                    v_adam.append(v_a)\n",
    "                    s_adam.append(s_a)\n",
    "\n",
    "                    df1_t = np.zeros(i[0].shape)\n",
    "                    df2_t = np.zeros(i[1].shape)\n",
    "                    f_temp = [df1_t, df2_t]\n",
    "                    df.append(f_temp)\n",
    "\n",
    "                for i in bias:\n",
    "                    bv1 = np.zeros(i[0].shape)\n",
    "                    bv2 = np.zeros(i[1].shape)\n",
    "                    bs1 = np.zeros(i[0].shape)\n",
    "                    bs2 = np.zeros(i[1].shape)    \n",
    "                    bv_a = [bv1, bv2]\n",
    "                    bs_a = [bs1, bs2]\n",
    "                    bv_adam.append(bv_a)\n",
    "                    bs_adam.append(bs_a)\n",
    "\n",
    "\n",
    "                    db1_t = np.zeros(i[0].shape)\n",
    "                    db2_t = np.zeros(i[1].shape)\n",
    "                    b_temp = [db1_t, db2_t]\n",
    "                    db.append(b_temp)\n",
    "\n",
    "                for i in f_dc:\n",
    "                    fdc_v1 = np.zeros(i[0].shape)\n",
    "                    bdc_v2 = np.zeros(i[1].shape)\n",
    "                    fdc_s1 = np.zeros(i[0].shape)\n",
    "                    bdc_s2 = np.zeros(i[1].shape)    \n",
    "                    fdc_v_a = [fdc_v1, bdc_v2]\n",
    "                    fdc_s_a = [fdc_s1, bdc_s2]\n",
    "                    fdc_v_adam.append(fdc_v_a)\n",
    "                    fdc_s_adam.append(fdc_s_a)\n",
    "\n",
    "\n",
    "                    df1_t = np.zeros(i[0].shape)\n",
    "                    db1_t = np.zeros(i[1].shape)\n",
    "                    fb_temp = [df1_t, db1_t]\n",
    "                    dfb.append(fb_temp)\n",
    "                    \n",
    "                    \n",
    "                [df1,df2,df3,df4,df5,df6,df7] = df\n",
    "                [db1,db2,db3,db4,db5,db6,db7] = db \n",
    "                [dfb1_dc, dfb2_dc, dfb3_dc]    = dfb\n",
    "\n",
    "\n",
    "                #Final layer 1x1 filter setup\n",
    "\n",
    "                v_out_f = np.zeros(out_f.shape)\n",
    "                s_out_f = np.zeros(out_f.shape)\n",
    "                bv_out_b = np.zeros(out_b.shape)\n",
    "                bs_out_b = np.zeros(out_b.shape)\n",
    "\n",
    "\n",
    "\n",
    "                dout_f = np.zeros(out_f.shape)\n",
    "                dout_b = np.zeros(out_b.shape)\n",
    "\n",
    "            ######################################\n",
    "\n",
    "\n",
    "            #timestamp1 = time.time()\n",
    "\n",
    "          \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print('Image: {}/{}'.format((b+1),batch))\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                params = [f1[0], b1[0]]  \n",
    "                conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "                conv1_1[conv1_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f1[1], b1[1]]\n",
    "                conv1_2 = conv(conv1_1, params, 1)\n",
    "                conv1_2[conv1_2<=0] = 0 #Relu\n",
    "                ##################################### conv1_2: 32x32x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (32-2)/2+1  = 16 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f2[0], b2[0]]  \n",
    "                conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv2_1[conv2_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f2[1], b2[1]]\n",
    "                conv2_2 = conv(conv2_1, params, 1)\n",
    "                conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "                #####################################  16x16x32\n",
    "                \n",
    "                pl2 = maxpool(conv2_2, 2, 2) #   pl1 : (16-2)/2+1  = 8 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 3rd Big Layer ###########\n",
    "                params = [f3[0], b3[0]]  \n",
    "                conv3_1 = conv(pl2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f3[1], b3[1]]\n",
    "                conv3_2 = conv(conv3_1, params, 1)\n",
    "                conv3_2[conv3_2<=0] = 0 #Relu             \n",
    "                #####################################  8x8x64\n",
    "                         \n",
    "                pl3 = maxpool(conv3_2, 2, 2) #   pl1 : (8-2)/2+1  = 4   4x4x64\n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "            \n",
    "                ########### 4th Big Layer ###########\n",
    "                params = [f4[0], b4[0]]  \n",
    "                conv4_1 = conv(pl3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv4_1[conv4_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f4[1], b4[1]]\n",
    "                conv4_2 = conv(conv4_1, params, 1)\n",
    "                conv4_2[conv4_2<=0] = 0 #Relu              \n",
    "                #####################################  4x4x128\n",
    "                \n",
    "                ##################################### \n",
    "                ##################################### \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[0][0], f_dc[0][1]] # deconv filter, deconv bias\n",
    "                dc1, new_in1 = convTransp(conv4_2, params, 1, 0)   #result:   =  8x8x64 , \n",
    "                #Concat dc1 with conv3_2 \n",
    "                c1 = concat(dc1, conv3_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          8x8x128     \n",
    "                params = [f5[0], b5[0]]  \n",
    "                conv5_1 = conv(c1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv5_1[conv5_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f5[1], b5[1]]\n",
    "                conv5_2 = conv(conv5_1, params, 1)\n",
    "                conv5_2[conv5_2<=0] = 0 #Relu   \n",
    "                #####################################    8x8x64\n",
    "                \n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[1][0], f_dc[1][1]] # deconv filter, deconv bias\n",
    "                dc2, new_in2 = convTransp(conv5_2, params, 1, 0)   #result:   =  16x16x32 , \n",
    "                #Concat dc2 with conv1_2 \n",
    "                c2 = concat(dc2, conv2_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          16x16x64     \n",
    "                params = [f6[0], b6[0]]  \n",
    "                conv6_1 = conv(c2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv6_1[conv6_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f6[1], b6[1]]\n",
    "                conv6_2 = conv(conv6_1, params, 1)\n",
    "                conv6_2[conv6_2<=0] = 0 #Relu   \n",
    "                #####################################    16x16x32\n",
    "                \n",
    "                                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[2][0], f_dc[2][1]] # deconv filter, deconv bias\n",
    "                dc3, new_in3 = convTransp(conv6_2, params, 1, 0)   #result:   =  32x32x16 , \n",
    "                #Concat dc2 with conv1_2 \n",
    "                c3 = concat(dc3, conv1_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 3rd Big dc Layer ###########          32x32x32  \n",
    "                params = [f7[0], b7[0]]  \n",
    "                conv7_1 = conv(c3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv7_1[conv7_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f7[1], b7[1]]\n",
    "                conv7_2 = conv(conv7_1, params, 1)\n",
    "                conv7_2[conv7_2<=0] = 0 #Relu   \n",
    "                #####################################    32x32x16\n",
    "                \n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 32x32x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv7_2, params, 1, 0) #output.shape: 32x32x1\n",
    "                \n",
    "                \n",
    "                output = normalize(output)\n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                print(Y_hat[:,0:3,0:3])\n",
    "                #label crop is needed\n",
    "                #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "                cost_,accuracy_ = NLLLoss(Y_hat, Y_t[b])\n",
    "                cost += cost_\n",
    "                accuracy += accuracy_\n",
    "                if(mode == 'predict'):\n",
    "                    print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "                    return\n",
    "                #print(cost/(b+1), prev_cost)\n",
    "                #if(((cost-prev_cost)>0.2)and((e+1) == epochs)):\n",
    "                #    e=e-1\n",
    "                #    print(\"\\n\\n-------------Epoch skipped!--------------\\n\\n\")\n",
    "                #    continue\n",
    "                #prev_cost = cost\n",
    "                \n",
    "                #accuracy += get_accuracy_value(Y_hat, Y_t[b])\n",
    "                #print(accuracy/(b+1))\n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t[b]\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv7_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv7_2, out_f, conv_s) #\n",
    "                #pack data\n",
    "                \n",
    "                \n",
    "                dconv7_2[conv7_2<=0] = 0             \n",
    "                dconv7_1, df7_2, db7_2 = convolutionBackward(dconv7_2, conv7_1, f7[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv7_1[conv7_1<=0] = 0\n",
    "                conc_dconv6, df7_1, db7_1 = convolutionBackward(dconv7_1, c3, f7[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv6, dconv1_2 = crop2half(conc_dconv6)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv6_2, df3_dc, db3_dc = convTranspBackward(dconv6, new_in3, f_dc[2][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv6_2[conv6_2<=0] = 0\n",
    "                dconv6_1, df6_2, db6_2 = convolutionBackward(dconv6_2, conv6_1, f6[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv6_1[conv6_1<=0] = 0\n",
    "                conc_dconv5, df6_1, db6_1 = convolutionBackward(dconv6_1, c2, f6[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv5, dconv2_2 = crop2half(conc_dconv5)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv5_2, df2_dc, db2_dc = convTranspBackward(dconv5, new_in2, f_dc[1][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv5_2[conv5_2<=0] = 0\n",
    "                dconv5_1, df5_2, db5_2 = convolutionBackward(dconv5_2, conv5_1, f5[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv5_1[conv5_1<=0] = 0\n",
    "                conc_dconv4, df5_1, db5_1 = convolutionBackward(dconv5_1, c1, f5[0], conv_s) #\n",
    "                \n",
    "                dconv4, dconv3_2 = crop2half(conc_dconv4)\n",
    "                dconv4_2, df1_dc, db1_dc = convTranspBackward(dconv4, new_in1, f_dc[0][0], conv_s)\n",
    "                \n",
    "                dconv4_2[conv4_2<=0] = 0\n",
    "                dconv4_1, df4_2, db4_2 = convolutionBackward(dconv4_2, conv4_1, f4[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv4_1[conv4_1<=0] = 0\n",
    "                dpl3, df4_1, db4_1 = convolutionBackward(dconv4_1, pl3, f4[0], conv_s) #\n",
    "                \n",
    "                dconv3_2 += maxpoolBackward(dpl3, conv3_2, f=2 , s=2)\n",
    "                \n",
    "                \n",
    "                dconv3_2[conv3_2<=0] = 0\n",
    "                dconv3_1, df3_2, db3_2 = convolutionBackward(dconv3_2, conv3_1, f3[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv3_1[conv3_1<=0] = 0\n",
    "                dpl2, df3_1, db3_1 = convolutionBackward(dconv3_1, pl2, f3[0], conv_s) #\n",
    "                \n",
    "                dconv2_2 += maxpoolBackward(dpl2, conv2_2, f=2 , s=2)\n",
    "                \n",
    "                dconv2_2[conv2_2<=0] = 0\n",
    "                dconv2_1, df2_2, db2_2 = convolutionBackward(dconv2_2, conv2_1, f2[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv2_1[conv2_1<=0] = 0\n",
    "                dpl1, df2_1, db2_1 = convolutionBackward(dconv2_1, pl1, f2[0], conv_s) #\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)\n",
    "                \n",
    "                dconv1_2[conv1_2<=0] = 0\n",
    "                dconv1_1, df1_2, db1_2 = convolutionBackward(dconv1_2, conv1_1, f1[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv1_1[conv1_1<=0] = 0\n",
    "                _, df1_1, db1_1 = convolutionBackward(dconv1_1, X_t[b], f1[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                #[df1,df2,df3,df4,df5,df6,df7] = df\n",
    "                #[db1,db2,db3,db4,db5,df6,df7] = db \n",
    "                #dfb1_dc,dfb2_dc, dfb3_dc     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                df4[0] += df4_1\n",
    "                df4[1] += df4_2\n",
    "                df5[0] += df5_1\n",
    "                df5[1] += df5_2\n",
    "                df6[0] += df6_1\n",
    "                df6[1] += df6_2\n",
    "                df7[0] += df7_1\n",
    "                df7[1] += df7_2\n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                db4[0] += db4_1\n",
    "                db4[1] += db4_2\n",
    "                db5[0] += db5_1\n",
    "                db5[1] += db5_2\n",
    "                db6[0] += db6_1\n",
    "                db6[1] += db6_2\n",
    "                db7[0] += db7_1\n",
    "                db7[1] += db7_2\n",
    "\n",
    "                dfb1_dc[0] += df1_dc\n",
    "                dfb1_dc[1] += db1_dc\n",
    "                dfb2_dc[0] += df2_dc\n",
    "                dfb2_dc[1] += db2_dc\n",
    "                dfb3_dc[0] += df3_dc\n",
    "                dfb3_dc[1] += db3_dc\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "\n",
    "\n",
    "      \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in range(len(filters)):\n",
    "                v_adam[i][0] = beta1*v_adam[i][0] + (1-beta1)*df[i][0]/batch_size #f1\n",
    "                s_adam[i][0] = beta2*s_adam[i][0] + (1-beta2)*(df[i][0]/batch_size)**2 #f1  \n",
    "                filters[i][0] -= lr*v_adam[i][0]/np.sqrt(s_adam[i][0] + 1e-8)\n",
    "                \n",
    "                v_adam[i][1] = beta1*v_adam[i][1] + (1-beta1)*df[i][1]/batch_size #f2\n",
    "                s_adam[i][1] = beta2*s_adam[i][1] + (1-beta2)*(df[i][1]/batch_size)**2  #f2\n",
    "                filters[i][1] -= lr*v_adam[i][1]/np.sqrt(s_adam[i][1] + 1e-8)\n",
    "                \n",
    "            for i in range(len(bias)):\n",
    "                bv_adam[i][0] = beta1*bv_adam[i][0] + (1-beta1)*db[i][0]/batch_size #b1\n",
    "                bs_adam[i][0] = beta2*bs_adam[i][0] + (1-beta2)*(db[i][0]/batch_size)**2  #b1\n",
    "                bias[i][0] -= lr*bv_adam[i][0]/np.sqrt(bs_adam[i][0] + 1e-8)\n",
    "                \n",
    "                bv_adam[i][1] = beta1*bv_adam[i][1] + (1-beta1)*db[i][1]/batch_size #b2\n",
    "                bs_adam[i][1] = beta2*bs_adam[i][1] + (1-beta2)*(db[i][1]/batch_size)**2  #b2\n",
    "                bias[i][1] -= lr*bv_adam[i][1]/np.sqrt(bs_adam[i][1] + 1e-8)\n",
    "            \n",
    "            for i in range(len(f_dc)):\n",
    "                fdc_v_adam[i][0] = beta1*fdc_v_adam[i][0] + (1-beta1)*dfb[i][0]/batch_size #f1\n",
    "                fdc_s_adam[i][0] = beta2*fdc_s_adam[i][0] + (1-beta2)*(dfb[i][0]/batch_size)**2  #f1\n",
    "                f_dc[i][0] -= lr*fdc_v_adam[i][0]/np.sqrt(fdc_s_adam[i][0] + 1e-8)\n",
    "                \n",
    "                fdc_v_adam[i][1] = beta1*fdc_v_adam[i][1] + (1-beta1)*dfb[i][1]/batch_size #b2\n",
    "                fdc_s_adam[i][1] = beta2*fdc_s_adam[i][1] + (1-beta2)*(dfb[i][1]/batch_size)**2  #b2\n",
    "                f_dc[i][1] -= lr*fdc_v_adam[i][1]/np.sqrt(fdc_s_adam[i][1] + 1e-8)    \n",
    "            \n",
    "            v_out_f = beta1*v_out_f + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out_f = beta2*s_out_f + (1 - beta2)*(dout_f/batch_size)**2  #f\n",
    "            out_fb[0] -= lr*v_out_f/np.sqrt(s_out_f + 1e-8)\n",
    "            \n",
    "            bv_out_b = beta1*bv_out_b + (1 - beta1)*dout_b/batch_size #b\n",
    "            bs_out_b = beta2*bs_out_b + (1 - beta2)*(dout_b/batch_size)**2  #b\n",
    "            out_fb[1] -= lr*bv_out_b/np.sqrt(bs_out_b + 1e-8)\n",
    "            \n",
    "            '''\n",
    "                        for i in range(len(filters)):\n",
    "                filters[i][0] -= lr*df[i][0]\n",
    "                bias[i][0] -= lr*db[i][0]\n",
    "            \n",
    "            \n",
    "            f_dc[0][0] -= lr*df1_dc\n",
    "            f_dc[0][1] -= lr*db1_dc\n",
    "            \n",
    "            out_fb[0] -= lr*dout_f\n",
    "            out_fb[1] -= lr*dout_b\n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            #print(\"Batch:{}\".format(c+12))\n",
    "            \n",
    "           \n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            '''\n",
    "            #print(\"Cost : {:.5f}\".format(cost/batch))\n",
    "            #print(\"Accuracy : {:.5f}%\".format((accuracy*100)/batch))\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        \n",
    "        print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "    #pack filters\n",
    "    params_values = [filters, bias, f_dc, out_fb]\n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n",
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.50000035 0.50000035 0.50000035]\n",
      "  [0.50000035 0.50000035 0.50000035]\n",
      "  [0.50000035 0.50000035 0.50000035]]]\n",
      "Epoch:     1   -   cost: 0.63   -   Accuracy: 53.25%\n",
      "Epoch: {2}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.49165715 0.49165715 0.49165715]\n",
      "  [0.49165715 0.49165715 0.49165715]\n",
      "  [0.49165715 0.49165715 0.49165715]]]\n",
      "Epoch:     2   -   cost: 0.62   -   Accuracy: 53.86%\n",
      "Epoch: {3}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.48025398 0.47962301 0.47962301]\n",
      "  [0.47962303 0.47867778 0.47867778]\n",
      "  [0.47962303 0.47867778 0.47867778]]]\n",
      "Epoch:     3   -   cost: 0.60   -   Accuracy: 54.80%\n",
      "Epoch: {4}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.44969124 0.43919665 0.43718032]\n",
      "  [0.43919682 0.422966   0.41977213]\n",
      "  [0.43718054 0.41977221 0.41618781]]]\n",
      "Epoch:     4   -   cost: 0.53   -   Accuracy: 59.10%\n",
      "Epoch: {5}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.2999183  0.22531839 0.20639704]\n",
      "  [0.22531853 0.13570363 0.11589531]\n",
      "  [0.20639685 0.11589501 0.09652263]]]\n",
      "Epoch:     5   -   cost: 0.27   -   Accuracy: 76.58%\n",
      "Epoch: {6}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.22473938 0.12978301 0.10665545]\n",
      "  [0.12981941 0.0483822  0.03408303]\n",
      "  [0.10671175 0.03409525 0.02265102]]]\n",
      "Epoch:     6   -   cost: 0.23   -   Accuracy: 79.26%\n",
      "Epoch: {7}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.29259212 0.20141857 0.17351603]\n",
      "  [0.20157312 0.10063611 0.07614387]\n",
      "  [0.17378833 0.07623648 0.05459616]]]\n",
      "Epoch:     7   -   cost: 0.16   -   Accuracy: 84.97%\n",
      "Epoch: {8}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.45132906 0.4275912  0.41762754]\n",
      "  [0.42781222 0.38897169 0.37278441]\n",
      "  [0.41802686 0.37301581 0.35424623]]]\n",
      "Epoch:     8   -   cost: 0.43   -   Accuracy: 64.98%\n",
      "Epoch: {9}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.06118905 0.01079108 0.00499241]\n",
      "  [0.01084947 0.00053992 0.00014543]\n",
      "  [0.00504888 0.00014664 0.01798621]]]\n",
      "Epoch:     9   -   cost: 0.19   -   Accuracy: 82.98%\n",
      "Epoch: {10}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[5.59411477e-02 8.78916080e-03 3.83781959e-03]\n",
      "  [8.85031623e-03 3.63574328e-04 8.90730332e-05]\n",
      "  [3.89157109e-03 8.99372637e-05 1.79862100e-02]]]\n",
      "Epoch:    10   -   cost: 0.17   -   Accuracy: 83.98%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values = train(train_images[0].reshape(1,1,128,128), train_labels[0].reshape(1,1,128,128), 10, 0.0001, True, 'train',0) #0.05 stable LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n",
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/1\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'f1' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-4b015d180758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-98-90badda1eab8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(X, Y, epochs, learning_rate, dropout, mode, params_values)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;31m########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                 \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m                 \u001b[0mconv1_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[0mconv1_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconv1_1\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m#Relu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'f1' referenced before assignment"
     ]
    }
   ],
   "source": [
    "train(train_images[0].reshape(1,1,128,128), train_labels[0].reshape(1,1,128,128), 10, 0.0001, True, 'predict', params_values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
