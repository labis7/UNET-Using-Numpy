{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\salt\n",
    "        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt2')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    #os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\"\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "    \"\"\"\n",
    "    dim=64\n",
    "    dataset=4\n",
    "    def _images(path,dim):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/images/\"\n",
    "        #cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY)\n",
    "        onlyfiles = [cv2.imread(folder+f, cv2.IMREAD_GRAYSCALE) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,dim,dim).astype('float32')/255\n",
    "        return pixels[:dataset,:,:,:]\n",
    "\n",
    "    def _labels(path,dim):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        \n",
    "        folder = path + \"/labels/\"\n",
    "        #onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(dim, dim)) for f in os.listdir(folder)]\n",
    "        #onlyfiles = [cv2.resize(cv2.imread(folder+f, cv2.IMREAD_GRAYSCALE),(dim, dim)) for f in os.listdir(folder)]\n",
    "        onlyfiles = [cv2.imread(folder+f, cv2.IMREAD_GRAYSCALE) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,dim,dim).astype('float32')/255\n",
    "        return pixels[:dataset,:,:,:]\n",
    "    \n",
    "    def _t_images(path,dim):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/t_images/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(dim, dim)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,dim,dim).astype('float32')#/255\n",
    "        return pixels[0:2,:,:,:]\n",
    "    def _t_labels(path,dim):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        \n",
    "        folder = path + \"/t_labels/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(dim, dim)) for f in os.listdir(folder)]\n",
    "        #onlyfiles = [cv2.resize(image.imread(folder+f),(32, 32)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,dim,dim).astype('float32') #/255\n",
    "        return pixels[0:2,:,:,:]\n",
    "\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(path,dim)\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(path,dim)\n",
    "    #print(\"Test Images  : Loading . . .\")\n",
    "    #test_images = _t_images(path,dim)\n",
    "    #print(\"Test Labels  : Loading . . .\")\n",
    "    #test_labels = _t_labels(path,dim)\n",
    "    print(\"Done!\")\n",
    "    return train_images, train_labels# , test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 128, 128)\n",
      "(1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape) # ONE-HOT !!!\n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "#plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(train_labels[0].squeeze(), cmap='Greys_r');\n",
    "plt.imshow(train_labels[0].squeeze(),cmap='gray', vmin=0, vmax=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8035b4f3c2e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(train_labels[0].squeeze(), cmap='Greys_r');\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(train_labels[1].squeeze(), cmap='Greys_r');\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(train_labels[2].squeeze(), cmap='Greys_r');\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(train_labels[3].squeeze(), cmap='Greys_r');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(test_images[0].squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Filter/Parameter Initializattions  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f ,trim):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    \n",
    "    trimf = trim\n",
    "    trimb = trim*5\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    \"\"\"\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trimf #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trimb\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \"\"\"\n",
    "    trimbr = trim\n",
    "    locbr = 0\n",
    "    scb=1\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.normal(loc = locbr, scale = trimbr , size = f1) #np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.normal(loc = locbr, scale = trimbr*scb , size = (f1.shape[0],1)) #np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.normal(loc = locbr, scale = trimbr , size = f2)\n",
    "        b2 = np.random.normal(loc = locbr, scale = trimbr*scb, size = (f2.shape[0],1))\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc =  np.random.normal(loc = locbr, scale = trimbr , size = (n_f,ch_in,2,2))#upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.normal(loc = locbr, scale = trimbr*scb , size = (fdc.shape[0],1))\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.normal(loc = locbr, scale = trimbr , size = (n_f, ch_in, 3, 3))\n",
    "        b1 = np.random.normal(loc = locbr, scale = trimbr*scb , size = (f1.shape[0],1))\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.normal(loc = locbr, scale = trimbr , size = f2)\n",
    "        b2 = np.random.normal(loc = locbr, scale = trimbr*scb , size = (f2.shape[0],1))\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "    return filters, bias, f_dc   \n",
    "\n",
    "\n",
    "def init_groupnorm_params(bias, out_b, norm_batch, locbr, trimbr):\n",
    "    [b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "    \n",
    "    \n",
    "    t_1,_ = b1\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma1_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) #MAKE IT FLOAT\n",
    "    beta1_1  = np.random.normal( scale = trimbr , size = gb_size)\n",
    "    gamma1_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta1_2  = np.random.normal( scale = trimbr , size = gb_size)\n",
    "    tempg_1 = [gamma1_1,gamma1_2]\n",
    "    tempb_1 = [beta1_1,beta1_2]\n",
    "    \n",
    "    t_1,_ = b2\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma2_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta2_1  = np.random.normal( scale = trimbr , size = gb_size)\n",
    "    gamma2_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta2_2  = np.random.normal(scale = trimbr , size = gb_size)  \n",
    "    tempg_2 = [gamma2_1,gamma2_2]\n",
    "    tempb_2 = [beta2_1,beta2_2]\n",
    "    \n",
    "    t_1,_ = b3\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma3_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta3_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma3_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta3_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_3 = [gamma3_1,gamma3_2]\n",
    "    tempb_3 = [beta3_1,beta3_2]\n",
    "    \n",
    "    t_1,_ = b4\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma4_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta4_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma4_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta4_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_4 = [gamma4_1,gamma4_2]\n",
    "    tempb_4 = [beta4_1,beta4_2]\n",
    "    \n",
    "    t_1,_ = b5\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma5_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta5_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma5_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta5_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_5 = [gamma5_1,gamma5_2]\n",
    "    tempb_5 = [beta5_1,beta5_2]\n",
    "    \n",
    "    t_1,_ = b6\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma6_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta6_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma6_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta6_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_6 = [gamma6_1,gamma6_2]\n",
    "    tempb_6 = [beta6_1,beta6_2]\n",
    "    \n",
    "    t_1,_ = b7\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma7_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta7_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma7_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta7_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_7 = [gamma7_1,gamma7_2]\n",
    "    tempb_7 = [beta7_1,beta7_2]\n",
    "    \n",
    "    t_1,_ = b8\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma8_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta8_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma8_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta8_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_8 = [gamma8_1,gamma8_2]\n",
    "    tempb_8 = [beta8_1,beta8_2]\n",
    "    \n",
    "    t_1,_ = b9\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma9_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta9_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma9_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta9_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_9 = [gamma9_1,gamma9_2]\n",
    "    tempb_9 = [beta9_1,beta9_2]\n",
    "    \n",
    "    ga =[tempg_1,tempg_2,tempg_3,tempg_4,tempg_5,tempg_6, tempg_7,tempg_8,tempg_9]\n",
    "    be =[tempb_1,tempb_2,tempb_3,tempb_4,tempb_5,tempb_6, tempb_7,tempb_8,tempb_9]\n",
    "    \n",
    "    #gamma_out = np.random.normal(loc = locbr, scale = trimbr , size = (out_b.shape[0]//norm_batch,1))\n",
    "    #beta_out =   np.random.normal(scale = trimbr , size = (out_b.shape[0]//norm_batch,1))\n",
    "    \n",
    "    return ga, be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "\n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(np.multiply(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] , f[z, :, :, :])) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    #filt =np.rot90(filt, 2)  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!! A T T E N T I O N !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "def convTransp1(image, params, s = 2, pad = 1):\n",
    "    [f, b] = params\n",
    "    n_f, n_c, f_s, _ = f.shape\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2\n",
    "    res = np.zeros((n_f, target_dim, target_dim))\n",
    "    temp =np.zeros((n_c, target_dim, target_dim))\n",
    "    for z in range(n_f):\n",
    "        for _h in range(input_s):      \n",
    "            for _w in range(input_s):\n",
    "                temp[:, _h*s:_h*s+f_s, _w*s:_w*s+f_s] += image[:, _h, _w].reshape(n_c,1,1)*f[z,:,:,:] #bias will be added at the end\n",
    "        res[z] = np.sum(temp , axis = 0) + b[z]\n",
    "    return res, image\n",
    "\n",
    "def convTranspBackward1(dconv_prev, new_in, filt, s = 2):\n",
    "    n_f, n_c, f_s, _ = filt.shape\n",
    "    _, input_s, _ = new_in.shape\n",
    "    #final_dim = (new_in.shape[1] - 2)//2 + 1 \n",
    "    dc_s=dconv_prev.shape[1]\n",
    "    temp = np.zeros((n_c,dc_s,dc_s))\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    dconv_in = np.zeros(new_in.shape)\n",
    "    db = np.zeros((n_f,1))\n",
    "    for z in range(n_f):\n",
    "        for _h in range(input_s):      \n",
    "            for _w in range(input_s): \n",
    "                dfilt[z] += dconv_prev[z, _h*s:_h*s+f_s, _w*s:_w*s+f_s]*new_in[:,_h,_w].reshape(n_c,1,1)\n",
    "                temp[:, _h*s:_h*s+f_s, _w*s:_w*s+f_s] += dconv_prev[z, _h*s:_h*s+f_s, _w*s:_w*s+f_s] * filt[z]\n",
    "                for ch in range(n_c):\n",
    "                    dconv_in[ch, _h, _w] += np.sum(temp[ch, _h*s:_h*s+f_s, _w*s:_w*s+f_s])\n",
    "        db[z] = np.sum(dconv_prev[z])        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "    \n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    [f, b]=params\n",
    "    f = np.rot90(f, 2, (2,3))\n",
    "    params = [f, b]\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    \n",
    "    ### OR just: np.pad(image[:,:,:],2,'constant') # Important, we must loop with respect to the 1st dim\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    #filt = np.rot90(filt, 2, (2,3))\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "\n",
    "    idx = np.nanargmax(arr)\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h*s + a, _w*s + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[0:n_ch,:,:], img[n_ch:n_ch*2 ,:,:]\n",
    "    \n",
    "def concat(img2, img1_true):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "        print(\"Warning: Extra crop needed and handled!(%d --> %d)\" %(dim, img2.shape[1]))\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def Cross_Entropy(logs, targets):  # Pixel-Wise Cross entropy --> average accuracy\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[2]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] >= logs[:,i,j]):#Gray and above\n",
    "                out[:,i,j] = logs[:,i,j]/targets[:,i,j] \n",
    "            else:\n",
    "                out[:,i,j] = (1 - logs[:,i,j])/(1 - targets[:,i,j]) # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    res =out.sum()/mylen\n",
    "    return -np.log(res),res\n",
    "\n",
    "\n",
    "def Dice_Coef(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[2]\n",
    "    #Apply Dice coefficient\n",
    "    numerator = (logs*targets)\n",
    "    denominator = logs + targets\n",
    "    loss = 1 - (2*np.sum(numerator))/(np.sum(denominator))\n",
    "    return loss, np.exp(-loss)\n",
    "                \n",
    "    \n",
    "    \n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "def normalize(output):\n",
    "    output[output<-4]=-4\n",
    "    output[output>4] = 4\n",
    "    return output\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupnorm_forward(X, gamma_, beta_, eps=1e-5):\n",
    "   \n",
    "    C_all=X.shape[0]\n",
    "    \n",
    "    if(C_all == 1):\n",
    "        batch = 1\n",
    "    else:\n",
    "        batch =2\n",
    "    C= batch\n",
    "    \n",
    "    mu_= np.zeros(C_all//batch)\n",
    "    var_=np.zeros(C_all//batch)\n",
    "    xmu_=np.zeros((C_all,X.shape[1],X.shape[2]))\n",
    "    sqrtvar_= np.zeros(C_all//batch)\n",
    "    ivar_= np.zeros(C_all//batch)\n",
    "    xhat_= np.zeros((C_all,X.shape[1],X.shape[2]))\n",
    "    #gammax_= np.zeros((C_all,1,1))\n",
    "    out_= np.zeros((C_all,X.shape[1],X.shape[2]))\n",
    "    \n",
    "    \n",
    "    for i in range(0, C_all, batch):\n",
    "        \n",
    "        x = X[i:i+C,:,:]\n",
    "        gamma = gamma_[i//batch]  #there is a gamma,beta for each batch of channels\n",
    "        beta = beta_[i//batch]\n",
    "        ###################################################################\n",
    "        _, H, W = x.shape  #WAS N, D\n",
    "        \n",
    "        #step1: calculate mean\n",
    "        mu = np.mean(x) #scalar\n",
    "        #print(mu)\n",
    "        \n",
    "        #step2: subtract mean vector of every trainings example\n",
    "        xmu = (x - mu)\n",
    "        \n",
    "        #step3: following the lower branch - calculation denominator\n",
    "        #step4: calculate variance\n",
    "        var = np.mean(xmu ** 2)\n",
    "        \n",
    "        #step5: add eps for numerical stability, then sqrt\n",
    "        sqrtvar = np.sqrt(var + eps)\n",
    "        \n",
    "        #step6: invert sqrtvar\n",
    "        ivar = 1./sqrtvar\n",
    "        \n",
    "        #step7: execute normalization\n",
    "        xhat = xmu * ivar\n",
    "        \n",
    "        #step8: Nor the two transformation steps\n",
    "        gammax = gamma * xhat\n",
    "        #gamma,beta : scalar\n",
    "        #step9\n",
    "        out = gammax + beta\n",
    "        \n",
    "        xhat_[i:i+C,:,:]   =xhat   #.copy()\n",
    "        #gamma_[i:i+2,:,:]  =gamma\n",
    "        xmu_[i:i+C,:,:]    =xmu\n",
    "        ivar_[i//batch]  =ivar\n",
    "        sqrtvar_[i//batch]=sqrtvar\n",
    "        var_[i//batch]   =var\n",
    "        out_[i:i+C,:,:]   =out\n",
    "    #store intermediate\n",
    "    cache = (xhat_,gamma_,xmu_,ivar_,sqrtvar_,var_,eps)\n",
    "    return out_, cache\n",
    "\n",
    "def groupnorm_backward(dout_, cache):\n",
    "\n",
    "    #unfold the variables stored in cache\n",
    "    xhat_,gamma_,xmu_,ivar_,sqrtvar_,var_,eps = cache\n",
    "\n",
    "    \n",
    "    C_all =dout_.shape[0]\n",
    "    if(C_all == 1):\n",
    "        C = 1\n",
    "    else:\n",
    "        C = 2\n",
    "    \n",
    "    batch = C\n",
    "    dx_    = np.zeros((C_all,dout_.shape[1],dout_.shape[2]))\n",
    "    dgamma_= np.zeros(C_all//batch)\n",
    "    dbeta_ = np.zeros(C_all//batch)\n",
    "    \n",
    "    for i in range(0, C_all, batch): \n",
    "        dout = dout_[i:i+C,:,:]\n",
    "        xhat   =xhat_[i:i+C,:,:]\n",
    "        gamma  = gamma_[i//batch]\n",
    "        xmu    =xmu_[i:i+C,:,:]\n",
    "        ivar   =ivar_[i//batch]\n",
    "        sqrtvar=sqrtvar_[i//batch]\n",
    "        var    =var_[i//batch]\n",
    "        \n",
    "        #get the dimensions of the input/output\n",
    "        _, H, W = dout.shape #N,D = dout.shape\n",
    "\n",
    "        #step9\n",
    "        dbeta = np.sum(dout)\n",
    "        dgammax = dout #not necessary, but more understandable\n",
    "\n",
    "        #step8\n",
    "        dgamma = np.sum(dgammax*xhat)\n",
    "        dxhat = dgammax * gamma\n",
    "\n",
    "        #step7\n",
    "        divar = np.sum(dxhat*xmu)\n",
    "        dxmu1 = dxhat * ivar\n",
    "\n",
    "        #step6\n",
    "        dsqrtvar = -1. /(sqrtvar**2) * divar\n",
    "\n",
    "        #step5\n",
    "        dvar = 0.5 * 1. /np.sqrt(var+eps) * dsqrtvar\n",
    "\n",
    "        #step4\n",
    "        dsq = 1./(batch*H*W) * np.ones((C,H,W)) * dvar  #1./C\n",
    "\n",
    "        #step3\n",
    "        dxmu2 = 2 * xmu * dsq\n",
    "\n",
    "        #step2\n",
    "        dx1 = (dxmu1 + dxmu2)\n",
    "        dmu = -1 * np.sum(dxmu1+dxmu2)\n",
    "\n",
    "        #step1\n",
    "        dx2 =  1./(batch*H*W) *np.ones((C,H,W)) * dmu #1. /C *\n",
    "\n",
    "        #step0\n",
    "        dx = dx1 + dx2\n",
    "        dx_[i:i+C,:,:]    = dx\n",
    "        dgamma_[i//batch]= dgamma\n",
    "        dbeta_[i//batch] = dbeta\n",
    "\n",
    "    return dx_, dgamma_.reshape(C_all//batch,1), dbeta_.reshape(C_all//batch,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validate(X, Y, params, GN):\n",
    "    ### Unpacking ###\n",
    "    [filters, bias, f_dc, out_fb] = params\n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7,f8,f9] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "    [fb6_dc, fb7_dc, fb8_dc, fb9_dc] = f_dc\n",
    "    [out_f, out_b] = out_fb\n",
    "    if(GN == 1):\n",
    "        [ga, be] = GN_params\n",
    "    else:\n",
    "        ga, be = init_groupnorm_params(bias, out_b, 2, 0, 0.05)# quick fix\n",
    "\n",
    "    #################\n",
    "    \n",
    "    \n",
    "    dropout = 0\n",
    "    print('Calculating Forward step . . .')\n",
    "    \n",
    "    batch = 1\n",
    "    for c in range(0, X.shape[0], batch):\n",
    "        if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "            batch = X.shape[0] - c\n",
    "        X_t = X[c:(c + batch)]\n",
    "        Y_t = Y[c:(c + batch)]\n",
    "        for b in range(batch):\n",
    "            ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "            conv1_1, conv1_2, normcache1_1, normcache1_2 = Conv_Block(\"Forward\", f1, b1, X_t[b], dropout, GN, ga[0], be[0])\n",
    "            ##################################### conv1_2: 128x128x16\n",
    "    \n",
    "            pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (128-2)/2+1  = 64 \n",
    "\n",
    "            ########### 2nd Big Layer ########### \n",
    "            conv2_1, conv2_2, normcache2_1, normcache2_2 = Conv_Block(\"Forward\", f2, b2, pl1, dropout, GN, ga[1], be[1])          \n",
    "            #####################################  64x64x32\n",
    "\n",
    "            pl2 = maxpool(conv2_2, 2, 2) #pool_f = 2 , pool_s = 2    , (64 -2)/2 +1 = 32\n",
    "\n",
    "            ########### 3rd Big Layer ###########\n",
    "            conv3_1, conv3_2, normcache3_1, normcache3_2 = Conv_Block(\"Forward\", f3, b3, pl2, dropout, GN, ga[2], be[2])          \n",
    "            #####################################  32x32x64\n",
    "\n",
    "            pl3 = maxpool(conv3_2, 2, 2) #pool_f = 2 , pool_s = 2   ,  (32-2)/2 +1 = 16\n",
    "\n",
    "            ########### 4th Big Layer ###########\n",
    "            conv4_1, conv4_2, normcache4_1, normcache4_2 = Conv_Block(\"Forward\", f4, b4, pl3, dropout, GN, ga[3], be[3])             \n",
    "            #####################################     16x16x128\n",
    "\n",
    "            pl4 = maxpool(conv4_2, 2, 2) #pool_f = 2 , pool_s = 2  , (16-2)/2 +1 =8  : 8x8x128\n",
    "\n",
    "            ########### 5th Big Layer ###########   8x8x128-->8x8x256\n",
    "            conv5_1, conv5_2, normcache5_1, normcache5_2 = Conv_Block(\"Forward\", f5, b5, pl4, dropout, GN, ga[4], be[4])       \n",
    "            #####################################  8x8x256\n",
    "\n",
    "            #####################################\n",
    "            #Because of ambigious size after the upsampling the concat func must take care possible crop of the conv#_2 \n",
    "            #####################################\n",
    "            #Deconvolution/Upsampling\n",
    "            # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "            params = [fb6_dc[0], fb6_dc[1]] # deconv filter, deconv bias\n",
    "            dc6, new_in6 = convTransp(conv5_2, params, 1, 0)   #result:   =  16x16x128 , # conv5_2 requires NO crop\n",
    "            #Concat dc6 with conv4_2 so we get 256 channels (16x16x256)\n",
    "\n",
    "            c6 = concat(dc6, conv4_2) # 1st one is the right one size  \n",
    "\n",
    "            ########### 6th Big Layer ###########          16x16x256     \n",
    "            conv6_1, conv6_2, normcache6_1, normcache6_2 = Conv_Block(\"Forward\", f6, b6, c6, dropout, GN, ga[5], be[5])  \n",
    "            #####################################    16x16x128\n",
    "            #(16-1)*2 + 2 =32\n",
    "            params = [fb7_dc[0], fb7_dc[1]] # deconv filter, deconv bias\n",
    "            dc7, new_in7 = convTransp(conv6_2, params, 1, 0)   #result:   =  32x32x64\n",
    "            #Concat dc7 with conv3_2 so we get  channels (32x32x128)\n",
    "            c7 = concat(dc7, conv3_2)   \n",
    "\n",
    "            ########### 7th Big Layer ###########          32x32x128     \n",
    "            conv7_1, conv7_2, normcache7_1, normcache7_2 = Conv_Block(\"Forward\", f7, b7, c7, dropout, GN, ga[6], be[6]) \n",
    "            #####################################    32x32x64\n",
    "            #(24-1)*2 + 2 = 48\n",
    "            params = [fb8_dc[0], fb8_dc[1]] # deconv filter, deconv bias\n",
    "            dc8, new_in8 = convTransp(conv7_2, params, 1, 0)   #result:   =  64x64x32\n",
    "            #Concat dc8 with conv2_2 so we get  channels (64x64x64)\n",
    "            c8 = concat(dc8 ,conv2_2)   \n",
    "\n",
    "            ########### 8th Big Layer ###########          64x64x64    \n",
    "            conv8_1, conv8_2, normcache8_1, normcache8_2 = Conv_Block(\"Forward\", f8, b8, c8, dropout, GN, ga[7], be[7])\n",
    "            #####################################    64x64x32                              \n",
    "            #(64-1)*2 + 2 = 128\n",
    "            params = [fb9_dc[0], fb9_dc[1]] # deconv filter, deconv bias\n",
    "            dc9, new_in9 = convTransp(conv8_2, params, 1, 0)   #result:   =  128x128x16\n",
    "            #Concat dc9 with conv1_2 so we get  channels (128x128x32)\n",
    "            c9 = concat(dc9, conv1_2)                   \n",
    "\n",
    "            ########### 9th Big Layer ###########          128x128x32   \n",
    "            conv9_1, conv9_2, normcache9_1, normcache9_2 = Conv_Block(\"Forward\", f9, b9, c9, dropout, GN, ga[8], be[8])\n",
    "            #####################################    128x128x16\n",
    "\n",
    "            ############################# Last Layer conv(1x1) --> 128x128x1 ##########################\n",
    "            params = [out_f, out_b]\n",
    "            output = conv(conv9_2, params, 1, 0) #output.shape: 128x128x1\n",
    "\n",
    "            #print(output[:,0:10,0:10])\n",
    "            #output = normalize(output)\n",
    "            ## Sigmoid ##\n",
    "            Y_hat = sigmoid(output)\n",
    "            \n",
    "            Y_hat[Y_hat>0.65]=1\n",
    "            Y_hat[Y_hat<0.35]=0\n",
    "\n",
    "            plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "            cost_,accuracy_ = Dice_Coef(Y_hat, Y_t[b])#Cross_Entropy(Y_hat, Y_t[b])\n",
    "            cost = cost_\n",
    "            accuracy = accuracy_\n",
    "            print(\"Cost: {:.2f}   -   Accuracy: {:.2f}%\".format(cost/batch, (accuracy*100)/batch))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_Block(step, f, b, myin, dropout, GN, ga, be):\n",
    "    if(step == \"Forward\"):\n",
    "        bc1 = 0\n",
    "        bc2 = 0\n",
    "        ### DROPOUT ###\n",
    "        if(dropout>0):\n",
    "            d = (np.random.rand(myin.shape[0],myin.shape[1],myin.shape[2])<dropout)\n",
    "            d = d*1 #Bool --> int(0s and 1s)\n",
    "            myin = d*myin\n",
    "        ###############\n",
    "        params = [f[0], b[0]]  \n",
    "        conv1 = conv(myin, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "        #print(b[0])\n",
    "\n",
    "        ### GROUP NORM ###\n",
    "        if(GN == 1):\n",
    "            conv1, bc1 = groupnorm_forward(conv1, ga[0], be[0]) \n",
    "        ##################\n",
    "        conv1[conv1<=0] = 0 #Relu\n",
    "\n",
    "        params = [f[1], b[1]]\n",
    "        conv2 = conv(conv1, params, 1)\n",
    "        ### GROUP NORM ###\n",
    "        if(GN == 1):\n",
    "            conv2, bc2 = groupnorm_forward(conv2, ga[1], be[1]) \n",
    "        ##################\n",
    "        conv2[conv2<=0] = 0 #Relu\n",
    "        return conv1, conv2, bc1, bc2\n",
    "    else: #Backward\n",
    "        if(isinstance(GN, int)):\n",
    "            dconv_prev = b\n",
    "            conv_prev = myin\n",
    "            conv_prev1 = dropout\n",
    "            conc = ga\n",
    "            dconv_prev[conv_prev<=0] = 0\n",
    "            dconv1, df2, db2 = convolutionBackward(dconv_prev, conv_prev1, f[1], 1) #\n",
    "            #pack data\n",
    "            dconv1[conv_prev1<=0] = 0\n",
    "            conc_dconv1, df1, db1 = convolutionBackward(dconv1, conc, f[0], 1) #\n",
    "            return conc_dconv1, df2, db2, df1, db1\n",
    "        else:\n",
    "            dconv_prev = b\n",
    "            conv_prev = myin\n",
    "            conv_prev1 = dropout\n",
    "            conc = GN\n",
    "            normcache1 = ga\n",
    "            normcache2 = be\n",
    "            dconv_prev[conv_prev<=0] = 0 \n",
    "            dconv_prev, dgamma1_2, dbeta1_2 = groupnorm_backward(dconv_prev, normcache2)\n",
    "            dconv1_1, df1_2, db1_2 = convolutionBackward(dconv_prev, conv_prev1, f[1], 1) #\n",
    "            #pack data\n",
    "            dconv1_1[conv_prev1<=0] = 0\n",
    "            dconv1_1, dgamma1_1, dbeta1_1 = groupnorm_backward(dconv1_1, normcache1)\n",
    "            dga= [dgamma1_1,dgamma1_2]\n",
    "            dbe= [dbeta1_1,dbeta1_2]\n",
    "            conc_dconv1, df1_1, db1_1 = convolutionBackward(dconv1_1, conc, f[0], 1) #C9 is not needed for input,we know how to select the right gradients   \n",
    "            return conc_dconv1, df1_2, db1_2, df1_1, db1_1, dga, dbe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, GN):\n",
    "    verbose=True\n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    trim = 0.1\n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    filters,bias, f_dc = init_filters(5, 16, trim) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "    ##Final 1x1 filter\n",
    "    \n",
    "    \n",
    "    #out_f = np.random.randn(1,16,1,1)*trim\n",
    "    #out_b = np.random.randn(out_f.shape[0],1)*trim \n",
    "    out_f = (1,16,1,1)\n",
    "    out_f = np.random.normal(loc = 0, scale = trim , size = out_f) #np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "    out_b = (out_f.shape[0],1)\n",
    "    out_b = np.random.normal(loc = 0, scale = trim , size = out_b) #np.random.randn(f1.shape[0],1)* trimb\n",
    "    out_fb = [out_f, out_b]\n",
    "    \n",
    "    ### Initialize group normalization parameters\n",
    "    ga, be = init_groupnorm_params(bias, out_b, 2, 0, 0.05)#norm_batch, lockbr, trimbr\n",
    "    \n",
    "    print(\"************************************\")\n",
    "    if(GN>0):\n",
    "        print(\"Group Normalization Enabled!\")\n",
    "    else:\n",
    "        print(\"Group Normalization Disabled!\")\n",
    "    if(dropout>0):\n",
    "        print(\"Dropout Enabled! -  Value: {}\".format(dropout))\n",
    "    else:\n",
    "        print(\"Dropout Disabled!\")\n",
    "    print(\"Learning rate: {}\".format(learning_rate))\n",
    "    print(\"Dataset Size: {}\".format(X.shape[0]))\n",
    "    print(\"Weight scale: {}\".format(trim))\n",
    "    print(\"************************************\")\n",
    "    \n",
    "    #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "\n",
    "    accuracy_history=[]\n",
    "    \n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]  \n",
    "\n",
    "            \n",
    "\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7,f8,f9] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "    [fb6_dc, fb7_dc, fb8_dc, fb9_dc] = f_dc\n",
    "    \n",
    "    last_acc = 0\n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        running_loss = 0\n",
    "        cost = 0\n",
    "        accuracy = 0\n",
    "        batch = 2\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            print('Batch: {}'.format(int(c/batch +1)))\n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.92\n",
    "            beta2= 0.995\n",
    "            lr = learning_rate\n",
    "            batch_size= batch\n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            \n",
    "            \n",
    "            df =  []\n",
    "            db =  []\n",
    "            dfb=  []\n",
    "            for i in filters:\n",
    "                v1 = np.zeros(i[0].shape)\n",
    "                v2 = np.zeros(i[1].shape)\n",
    "                s1 = np.zeros(i[0].shape)\n",
    "                s2 = np.zeros(i[1].shape)\n",
    "                v_a = [v1, v2]\n",
    "                s_a = [s1, s2]\n",
    "                v_adam.append(v_a)\n",
    "                s_adam.append(s_a)\n",
    "                \n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                df2_t = np.zeros(i[1].shape)\n",
    "                f_temp = [df1_t, df2_t]\n",
    "                df.append(f_temp)\n",
    "                \n",
    "            for i in bias:\n",
    "                bv1 = np.zeros(i[0].shape)\n",
    "                bv2 = np.zeros(i[1].shape)\n",
    "                bs1 = np.zeros(i[0].shape)\n",
    "                bs2 = np.zeros(i[1].shape)    \n",
    "                bv_a = [bv1, bv2]\n",
    "                bs_a = [bs1, bs2]\n",
    "                bv_adam.append(bv_a)\n",
    "                bs_adam.append(bs_a)\n",
    "                \n",
    "                \n",
    "                db1_t = np.zeros(i[0].shape)\n",
    "                db2_t = np.zeros(i[1].shape)\n",
    "                b_temp = [db1_t, db2_t]\n",
    "                db.append(b_temp)\n",
    "            \n",
    "            for i in f_dc:\n",
    "                fdc_v1 = np.zeros(i[0].shape)\n",
    "                bdc_v2 = np.zeros(i[1].shape)\n",
    "                fdc_s1 = np.zeros(i[0].shape)\n",
    "                bdc_s2 = np.zeros(i[1].shape)    \n",
    "                fdc_v_a = [fdc_v1, bdc_v2]\n",
    "                fdc_s_a = [fdc_s1, bdc_s2]\n",
    "                fdc_v_adam.append(fdc_v_a)\n",
    "                fdc_s_adam.append(fdc_s_a)\n",
    "                \n",
    "                \n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                db1_t = np.zeros(i[1].shape)\n",
    "                fb_temp = [df1_t, db1_t]\n",
    "                dfb.append(fb_temp)\n",
    "            \n",
    "            \n",
    "            #Final layer 1x1 filter setup\n",
    "\n",
    "            v_out_f = np.zeros(out_f.shape)\n",
    "            s_out_f = np.zeros(out_f.shape)\n",
    "            bv_out_b = np.zeros(out_b.shape)\n",
    "            bs_out_b = np.zeros(out_b.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            dout_f = np.zeros(out_f.shape)\n",
    "            dout_b = np.zeros(out_b.shape)\n",
    "            \n",
    "            ######################################\n",
    "            \n",
    "            \n",
    "            #timestamp1 = time.time()\n",
    "            \n",
    "            \n",
    "            [df1,df2,df3,df4,df5,df6,df7,df8,df9] = df\n",
    "            [db1,db2,db3,db4,db5,db6,db7,db8,db9] = db \n",
    "            [dfb6_dc,dfb7_dc,dfb8_dc,dfb9_dc]     = dfb\n",
    "            \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print('Image: {}/{}'.format((b+1),batch))\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                conv1_1, conv1_2, normcache1_1, normcache1_2 = Conv_Block(\"Forward\", f1, b1, X_t[b], dropout, GN, ga[0], be[0])\n",
    "                ##################################### conv1_2: 128x128x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (128-2)/2+1  = 64 \n",
    "                \n",
    "                ########### 2nd Big Layer ########### \n",
    "                conv2_1, conv2_2, normcache2_1, normcache2_2 = Conv_Block(\"Forward\", f2, b2, pl1, dropout, GN, ga[1], be[1])          \n",
    "                #####################################  64x64x32\n",
    "\n",
    "                pl2 = maxpool(conv2_2, 2, 2) #pool_f = 2 , pool_s = 2    , (64 -2)/2 +1 = 32\n",
    "\n",
    "                ########### 3rd Big Layer ###########\n",
    "                conv3_1, conv3_2, normcache3_1, normcache3_2 = Conv_Block(\"Forward\", f3, b3, pl2, dropout, GN, ga[2], be[2])          \n",
    "                #####################################  32x32x64\n",
    "\n",
    "                pl3 = maxpool(conv3_2, 2, 2) #pool_f = 2 , pool_s = 2   ,  (32-2)/2 +1 = 16\n",
    "\n",
    "                ########### 4th Big Layer ###########\n",
    "                conv4_1, conv4_2, normcache4_1, normcache4_2 = Conv_Block(\"Forward\", f4, b4, pl3, dropout, GN, ga[3], be[3])             \n",
    "                #####################################     16x16x128\n",
    "\n",
    "                pl4 = maxpool(conv4_2, 2, 2) #pool_f = 2 , pool_s = 2  , (16-2)/2 +1 =8  : 8x8x128\n",
    "                \n",
    "                ########### 5th Big Layer ###########   8x8x128-->8x8x256\n",
    "                conv5_1, conv5_2, normcache5_1, normcache5_2 = Conv_Block(\"Forward\", f5, b5, pl4, dropout, GN, ga[4], be[4])       \n",
    "                #####################################  8x8x256\n",
    "\n",
    "                #####################################\n",
    "                #Because of ambigious size after the upsampling the concat func must take care possible crop of the conv#_2 \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "                params = [fb6_dc[0], fb6_dc[1]] # deconv filter, deconv bias\n",
    "                dc6, new_in6 = convTransp(conv5_2, params, 1, 0)   #result:   =  16x16x128 , # conv5_2 requires NO crop\n",
    "                #Concat dc6 with conv4_2 so we get 256 channels (16x16x256)\n",
    "                c6 = concat(dc6, conv4_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 6th Big Layer ###########          16x16x256     \n",
    "                conv6_1, conv6_2, normcache6_1, normcache6_2 = Conv_Block(\"Forward\", f6, b6, c6, dropout, GN, ga[5], be[5])  \n",
    "                #####################################    16x16x128\n",
    "                #(16-1)*2 + 2 =32\n",
    "                params = [fb7_dc[0], fb7_dc[1]] # deconv filter, deconv bias\n",
    "                dc7, new_in7 = convTransp(conv6_2, params, 1, 0)   #result:   =  32x32x64\n",
    "                #Concat dc7 with conv3_2 so we get  channels (32x32x128)\n",
    "                c7 = concat(dc7, conv3_2)   \n",
    "                \n",
    "                ########### 7th Big Layer ###########          32x32x128     \n",
    "                conv7_1, conv7_2, normcache7_1, normcache7_2 = Conv_Block(\"Forward\", f7, b7, c7, dropout, GN, ga[6], be[6]) \n",
    "                #####################################    32x32x64\n",
    "                #(24-1)*2 + 2 = 48\n",
    "                params = [fb8_dc[0], fb8_dc[1]] # deconv filter, deconv bias\n",
    "                dc8, new_in8 = convTransp(conv7_2, params, 1, 0)   #result:   =  64x64x32\n",
    "                #Concat dc8 with conv2_2 so we get  channels (64x64x64)\n",
    "                c8 = concat(dc8 ,conv2_2)   \n",
    "                \n",
    "                ########### 8th Big Layer ###########          64x64x64    \n",
    "                conv8_1, conv8_2, normcache8_1, normcache8_2 = Conv_Block(\"Forward\", f8, b8, c8, dropout, GN, ga[7], be[7])\n",
    "                #####################################    64x64x32                              \n",
    "                #(64-1)*2 + 2 = 128\n",
    "                params = [fb9_dc[0], fb9_dc[1]] # deconv filter, deconv bias\n",
    "                dc9, new_in9 = convTransp(conv8_2, params, 1, 0)   #result:   =  128x128x16\n",
    "                #Concat dc9 with conv1_2 so we get  channels (128x128x32)\n",
    "                c9 = concat(dc9, conv1_2)                   \n",
    "               \n",
    "                ########### 9th Big Layer ###########          128x128x32   \n",
    "                conv9_1, conv9_2, normcache9_1, normcache9_2 = Conv_Block(\"Forward\", f9, b9, c9, dropout, GN, ga[8], be[8])\n",
    "                #####################################    128x128x16\n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 128x128x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv9_2, params, 1, 0) #output.shape: 128x128x1\n",
    "                \n",
    "                #print(output[:,0:10,0:10])\n",
    "                #if(GN == 0):\n",
    "                output = normalize(output)\n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                \n",
    "                #label crop is needed\n",
    "                #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                #plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "                cost_,accuracy_ = Dice_Coef(Y_hat, Y_t[b])\n",
    "                cost += cost_\n",
    "                accuracy += accuracy_\n",
    "                print(accuracy_*100)\n",
    "                if((c+1) == X.shape[0]): #assuming that batch is always  1\n",
    "                    if (accuracy/(c+1)>last_acc):\n",
    "                        #plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "                        last_acc = accuracy/(c+1)\n",
    "                        print(\"New parameters Saved!\")\n",
    "                        GN_params = [ga, be]\n",
    "                        parameters = [filters, bias, f_dc, out_fb, GN_params]\n",
    "                        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "                        with open(path+'/weights', 'wb') as fp:\n",
    "                            pickle.dump(parameters, fp)\n",
    "                    if ((accuracy/(c+1))>0.99):\n",
    "                        print(\"Latest Accuracy: {}%\".format(accuracy*100))\n",
    "                        params_values = [filters, bias, f_dc, out_fb]\n",
    "                        return params_values\n",
    "                if(batch>1):\n",
    "                    if((c+b+1) == X.shape[0]):\n",
    "                        if((accuracy/(c+b+1))>last_acc):\n",
    "                            print(\"New parameters Saved!\")\n",
    "                            last_acc = accuracy/(c+b+1)\n",
    "                            #Saving\n",
    "                            GN_params = [ga, be]\n",
    "                            parameters = [filters, bias, f_dc, out_fb, GN_params]\n",
    "                            path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "                            with open(path+'/weights', 'wb') as fp:\n",
    "                                pickle.dump(parameters, fp)\n",
    "                    \n",
    "                \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t[b]\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv9_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv9_2, out_f, conv_s) #       \n",
    "                \n",
    "                if(GN == 0):\n",
    "                    conc_dconv9, df9_2, db9_2, df9_1, db9_1 = Conv_Block(\"Backward\", f9, dconv9_2, conv9_2, conv9_1, 0, c9, 0)\n",
    "                else:\n",
    "                    conc_dconv9, df9_2, db9_2, df9_1, db9_1, dga9, dbe9 = Conv_Block(\"Backward\", f9, dconv9_2, conv9_2, conv9_1, c9, normcache9_1, normcache9_2)\n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv9, dconv1_2 = crop2half(conc_dconv9)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                \n",
    "                dconv8_2, df9_dc, db9_dc = convTranspBackward(dconv9, new_in9, fb9_dc[0],conv_s)\n",
    "                #pack data\n",
    "\n",
    "                if(GN == 0):\n",
    "                    conc_dconv8, df8_2, db8_2, df8_1, db8_1 = Conv_Block(\"Backward\", f8, dconv8_2, conv8_2, conv8_1, 0, c8, 0)\n",
    "                else:\n",
    "                    conc_dconv8, df8_2, db8_2, df8_1, db8_1, dga8, dbe8 = Conv_Block(\"Backward\", f8, dconv8_2, conv8_2, conv8_1, c8, normcache8_1, normcache8_2)\n",
    "                    \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv8, dconv2_2 = crop2half(conc_dconv8)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #dconv2_2 = reshape(dconv2_2, conv2_2.shape[1])\n",
    "                \n",
    "                dconv7_2, df8_dc, db8_dc = convTranspBackward(dconv8, new_in8, fb8_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    conc_dconv7, df7_2, db7_2, df7_1, db7_1 = Conv_Block(\"Backward\", f7, dconv7_2, conv7_2, conv7_1, 0, c7, 0)\n",
    "                else:\n",
    "                    conc_dconv7, df7_2, db7_2, df7_1, db7_1, dga7, dbe7 = Conv_Block(\"Backward\", f7, dconv7_2, conv7_2, conv7_1, c7, normcache7_1, normcache7_2)\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv7, dconv3_2 = crop2half(conc_dconv7)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #Make sure that dconv3_2 is the same dim with the dconv3_2 that will come from maxpool in decoding side\n",
    "                #dconv3_2 = reshape(dconv3_2, conv3_2.shape[1])\n",
    "                \n",
    "                dconv6_2, df7_dc, db7_dc = convTranspBackward(dconv7, new_in7, fb7_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    conc_dconv6, df6_2, db6_2, df6_1, db6_1 = Conv_Block(\"Backward\", f6, dconv6_2, conv6_2, conv6_1, 0, c6, 0)\n",
    "                else:     \n",
    "                    conc_dconv6, df6_2, db6_2, df6_1, db6_1, dga6, dbe6 = Conv_Block(\"Backward\", f6, dconv6_2, conv6_2, conv6_1, c6, normcache6_1, normcache6_2)\n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv6, dconv4_2 = crop2half(conc_dconv6)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #dconv4_2 = reshape(dconv4_2, conv4_2.shape[1])\n",
    "                \n",
    "                dconv5_2, df6_dc, db6_dc = convTranspBackward(dconv6, new_in6, fb6_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    dpl4, df5_2, db5_2, df5_1, db5_1 = Conv_Block(\"Backward\", f5, dconv5_2, conv5_2, conv5_1, 0, pl4, 0)\n",
    "                else:     \n",
    "                    dpl4, df5_2, db5_2, df5_1, db5_1, dga5, dbe5 = Conv_Block(\"Backward\", f5, dconv5_2, conv5_2, conv5_1, pl4, normcache5_1, normcache5_2)\n",
    "\n",
    "                \n",
    "                dconv4_2 += maxpoolBackward(dpl4, conv4_2, f=2 , s=2) #Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    dpl3, df4_2, db4_2, df4_1, db4_1 = Conv_Block(\"Backward\", f4, dconv4_2, conv4_2, conv4_1, 0, pl3, 0)\n",
    "                else:     \n",
    "                    dpl3, df4_2, db4_2, df4_1, db4_1, dga4, dbe4 = Conv_Block(\"Backward\", f4, dconv4_2, conv4_2, conv4_1, pl3, normcache4_1, normcache4_2)\n",
    "\n",
    "\n",
    "                dconv3_2 += maxpoolBackward(dpl3, conv3_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    dpl2, df3_2, db3_2, df3_1, db3_1 = Conv_Block(\"Backward\", f3, dconv3_2, conv3_2, conv3_1, 0, pl2, 0)\n",
    "                else:     \n",
    "                    dpl2, df3_2, db3_2, df3_1, db3_1, dga3, dbe3 = Conv_Block(\"Backward\", f3, dconv3_2, conv3_2, conv3_1, pl2, normcache3_1, normcache3_2)\n",
    "\n",
    "                \n",
    "                dconv2_2 += maxpoolBackward(dpl2, conv2_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    dpl1, df2_2, db2_2, df2_1, db2_1 = Conv_Block(\"Backward\", f2, dconv2_2, conv2_2, conv2_1, 0, pl1, 0)\n",
    "                else:     \n",
    "                    dpl1, df2_2, db2_2, df2_1, db2_1, dga2, dbe2 = Conv_Block(\"Backward\", f2, dconv2_2, conv2_2, conv2_1, pl1, normcache2_1, normcache2_2)\n",
    "\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    _, df1_2, db1_2, df1_1, db1_1 = Conv_Block(\"Backward\", f1, dconv1_2, conv1_2, conv1_1, 0, X_t[b], 0)\n",
    "                else:     \n",
    "                    _, df1_2, db1_2, df1_1, db1_1, dga1, dbe1 = Conv_Block(\"Backward\", f1, dconv1_2, conv1_2, conv1_1, X_t[b], normcache1_1, normcache1_2)\n",
    "\n",
    "                \n",
    "                \n",
    "                if(GN == 1):\n",
    "                    dgamma = [dga1,dga2,dga3,dga4,dga5,dga6,dga7,dga8,dga9]\n",
    "                    dbeta = [dbe1,dbe2,dbe3,dbe4,dbe5,dbe6,dbe7,dbe8,dbe9]\n",
    "                \n",
    "\n",
    "                [df1,df2,df3,df4,df5,df6,df7,df8,df9] = df\n",
    "                [db1,db2,db3,db4,db5,db6,db7,db8,db9] = db \n",
    "                [dfb6_dc,dfb7_dc,dfb8_dc,dfb9_dc]     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                df4[0] += df4_1\n",
    "                df4[1] += df4_2\n",
    "                df5[0] += df5_1\n",
    "                df5[1] += df5_2\n",
    "                df6[0] += df6_1\n",
    "                df6[1] += df6_2\n",
    "                df7[0] += df7_1\n",
    "                df7[1] += df7_2\n",
    "                df8[0] += df8_1\n",
    "                df8[1] += df8_2\n",
    "                df9[0] += df9_1\n",
    "                df9[1] += df9_2\n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                db4[0] += db4_1\n",
    "                db4[1] += db4_2\n",
    "                db5[0] += db5_1\n",
    "                db5[1] += db5_2\n",
    "                db6[0] += db6_1\n",
    "                db6[1] += db6_2\n",
    "                db7[0] += db7_1\n",
    "                db7[1] += db7_2\n",
    "                db8[0] += db8_1\n",
    "                db8[1] += db8_2\n",
    "                db9[0] += db9_1\n",
    "                db9[1] += db9_2\n",
    "\n",
    "                dfb6_dc[0] += df6_dc\n",
    "                dfb6_dc[1] += db6_dc\n",
    "                dfb7_dc[0] += df7_dc\n",
    "                dfb7_dc[1] += db7_dc\n",
    "                dfb8_dc[0] += df8_dc\n",
    "                dfb8_dc[1] += db8_dc\n",
    "                dfb9_dc[0] += df9_dc\n",
    "                dfb9_dc[1] += db9_dc\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "                if(GN == 1):\n",
    "                    mytrim = 20\n",
    "                    for i in range(len(ga)):\n",
    "                        ga[i][0] -= lr*mytrim*dgamma[i][0]\n",
    "                        ga[i][1] -= lr*mytrim*dgamma[i][1]\n",
    "\n",
    "                        be[i][0] -= lr*mytrim*dbeta[i][0]\n",
    "                        be[i][1] -= lr*mytrim*dbeta[i][1]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in range(len(filters)):\n",
    "                v_adam[i][0] = beta1*v_adam[i][0] + (1-beta1)*df[i][0]/batch_size #f1\n",
    "                s_adam[i][0] = beta2*s_adam[i][0] + (1-beta2)*(df[i][0]/batch_size)**2 #f1\n",
    "                filters[i][0] -= lr*v_adam[i][0]/np.sqrt(s_adam[i][0] + 1e-7)\n",
    "\n",
    "                v_adam[i][1] = beta1*v_adam[i][1] + (1-beta1)*df[i][1]/batch_size #f2\n",
    "                s_adam[i][1] = beta2*s_adam[i][1] + (1-beta2)*(df[i][1]/batch_size)**2  #f2\n",
    "                filters[i][1] -= lr*v_adam[i][1]/np.sqrt(s_adam[i][1] + 1e-7)\n",
    "\n",
    "            for i in range(len(bias)):\n",
    "                bv_adam[i][0] = beta1*bv_adam[i][0] + (1-beta1)*db[i][0]/batch_size #b1\n",
    "                bs_adam[i][0] = beta2*bs_adam[i][0] + (1-beta2)*(db[i][0]/batch_size)**2  #b1\n",
    "                bias[i][0] -= lr*bv_adam[i][0]/np.sqrt(bs_adam[i][0] + 1e-7)\n",
    "\n",
    "                bv_adam[i][1] = beta1*bv_adam[i][1] + (1-beta1)*db[i][1]/batch_size #b2\n",
    "                bs_adam[i][1] = beta2*bs_adam[i][1] + (1-beta2)*(db[i][1]/batch_size)**2  #b2\n",
    "                bias[i][1] -= lr*bv_adam[i][1]/np.sqrt(bs_adam[i][1] + 1e-7)\n",
    "\n",
    "            for i in range(len(f_dc)):\n",
    "                fdc_v_adam[i][0] = beta1*fdc_v_adam[i][0] + (1-beta1)*dfb[i][0]/batch_size #f1\n",
    "                fdc_s_adam[i][0] = beta2*fdc_s_adam[i][0] + (1-beta2)*(dfb[i][0]/batch_size)**2  #f1\n",
    "                f_dc[i][0] -= lr*fdc_v_adam[i][0]/np.sqrt(fdc_s_adam[i][0] + 1e-7)\n",
    "\n",
    "                fdc_v_adam[i][1] = beta1*fdc_v_adam[i][1] + (1-beta1)*dfb[i][1]/batch_size #b2\n",
    "                fdc_s_adam[i][1] = beta2*fdc_s_adam[i][1] + (1-beta2)*(dfb[i][1]/batch_size)**2  #b2\n",
    "                f_dc[i][1] -= lr*fdc_v_adam[i][1]/np.sqrt(fdc_s_adam[i][1] + 1e-7)    \n",
    "\n",
    "            v_out_f = beta1*v_out_f + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out_f = beta2*s_out_f + (1 - beta2)*(dout_f/batch_size)**2  #f\n",
    "            out_fb[0] -= lr*v_out_f/np.sqrt(s_out_f + 1e-7)\n",
    "\n",
    "            bv_out_b = beta1*bv_out_b + (1 - beta1)*dout_b/batch_size #b\n",
    "            bs_out_b = beta2*bs_out_b + (1 - beta2)*(dout_b/batch_size)**2  #b\n",
    "            out_fb[1] -= lr*bv_out_b/np.sqrt(bs_out_b + 1e-7)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            '''\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            for i in range(len(filters)):\n",
    "                filters[i][0] -= lr*df[i][0]\n",
    "                bias[i][0] -= lr*db[i][0]\n",
    "            \n",
    "            for i in range(len(f_dc)):\n",
    "                f_dc[i][0] -= lr*dfb[i][0]\n",
    "            \n",
    "            out_fb[0] -= lr*dout_f\n",
    "            out_fb[1] -= lr*dout_b\n",
    "            \n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            #print(\"Batch:{}\".format(c+12))\n",
    "            \n",
    "           \n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            \n",
    "            '''\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        accuracy_history.append((accuracy*100)/(X.shape[0]))\n",
    "        if(batch == 1):\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/(c+1), (accuracy*100)/(X.shape[0])))\n",
    "        else:\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/(X.shape[0])))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "    #pack filters\n",
    "    #params_values = [filters, bias, f_dc, out_fb]\n",
    "    fp.close()\n",
    "    return parameters,accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Group Normalization Enabled!\n",
      "Dropout Disabled!\n",
      "Learning rate: 0.008\n",
      "Dataset Size: 4\n",
      "Weight scale: 0.1\n",
      "************************************\n",
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-acd2d99edc35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mparams_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.008\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-621134f16a57>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, Y, epochs, learning_rate, dropout, GN)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0mconv1_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormcache1_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormcache1_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv_Block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Forward\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mga\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0;31m##################################### conv1_2: 128x128x16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-ea235b194055>\u001b[0m in \u001b[0;36mConv_Block\u001b[0;34m(step, f, b, myin, dropout, GN, ga, be)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m###############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#conv1 shape = (num_channels, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(b[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-ba57b116fe0a>\u001b[0m in \u001b[0;36mconv\u001b[0;34m(image, params, s, pad)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_h\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mnp_o\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp_o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep-learning/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2228\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2229\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep-learning/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[1;32m     75\u001b[0m                   if v is not np._NoValue}\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep-learning/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[1;32m     75\u001b[0m                   if v is not np._NoValue}\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values,accuracy_history = train(train_images, train_labels, 65, 0.008, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Forward step . . .\n",
      "Maxpool: This took 0.72 seconds\n",
      "Transposed Conv: This took 4.47 seconds\n",
      "~1.5x Conv: This took 9.18 seconds\n",
      "Cost: 0.24   -   Accuracy: 78.40%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "with open (path+'/weights', 'rb') as fp:\n",
    "    params = pickle.load(fp)  \n",
    "fp.close()\n",
    "Validate(train_images[0:1,:,:,:], train_labels[0:1,:,:,:], params, 0) #GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(accuracy_history[:45], label=\"Dice Coefficient\")\n",
    "#plt.plot(accuracy_history2, label=\"Pixel-Wise CE\")\n",
    "#plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "#plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "################ Resizing Tool(Its used before convertion to .pgm) ###############\n",
    "def resize(path=None):\n",
    "\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\salt\n",
    "        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt2')\n",
    "    ####### TARGET DIMENSIONS ########\n",
    "    target_dim=64                  \n",
    "    ##################################\n",
    "    def resize_images(path, target_dim):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/images/\"\n",
    "        dest_folder =path + \"/images_resized/\"\n",
    "        for f in os.listdir(folder):\n",
    "            cv2.imwrite(dest_folder+f, cv2.resize(cv2.imread(folder+f, cv2.IMREAD_GRAYSCALE),(target_dim, target_dim)))\n",
    "\n",
    "    def resize_labels(path, target_dim):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        folder = path + \"/labels/\"\n",
    "        dest_folder =path + \"/labels_resized/\"\n",
    "        for f in os.listdir(folder):\n",
    "            cv2.imwrite(dest_folder+f, cv2.resize(cv2.imread(folder+f, cv2.IMREAD_GRAYSCALE),(target_dim, target_dim)))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    resize_images(path,target_dim)\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    resize_labels(path,target_dim)\n",
    "    #print(\"Test Images  : Loading . . .\")\n",
    "    #test_images = _t_images(path,dim)\n",
    "    #print(\"Test Labels  : Loading . . .\")\n",
    "    #test_labels = _t_labels(path,dim)\n",
    "    print(\"Done!\")\n",
    "    return # , test_images, test_labels\n",
    "resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 group \"/conv2d_58\" (1 members)>\n",
      "<HDF5 group \"/conv2d_59\" (1 members)>\n",
      "<HDF5 group \"/conv2d_60\" (1 members)>\n",
      "<HDF5 group \"/conv2d_61\" (1 members)>\n",
      "<HDF5 group \"/conv2d_62\" (1 members)>\n",
      "<HDF5 group \"/conv2d_63\" (1 members)>\n",
      "<HDF5 group \"/conv2d_64\" (1 members)>\n",
      "<HDF5 group \"/conv2d_65\" (1 members)>\n",
      "<HDF5 group \"/conv2d_66\" (1 members)>\n",
      "<HDF5 group \"/conv2d_67\" (1 members)>\n",
      "<HDF5 group \"/conv2d_68\" (1 members)>\n",
      "<HDF5 group \"/conv2d_69\" (1 members)>\n",
      "<HDF5 group \"/conv2d_70\" (1 members)>\n",
      "<HDF5 group \"/conv2d_71\" (1 members)>\n",
      "<HDF5 group \"/conv2d_72\" (1 members)>\n",
      "<HDF5 group \"/conv2d_73\" (1 members)>\n",
      "<HDF5 group \"/conv2d_74\" (1 members)>\n",
      "<HDF5 group \"/conv2d_75\" (1 members)>\n",
      "<HDF5 group \"/conv2d_76\" (1 members)>\n",
      "<HDF5 group \"/conv2d_transpose_13\" (1 members)>\n",
      "<HDF5 group \"/conv2d_transpose_14\" (1 members)>\n",
      "<HDF5 group \"/conv2d_transpose_15\" (1 members)>\n",
      "<HDF5 group \"/conv2d_transpose_16\" (1 members)>\n",
      "Reading from .h5 file completed!\n",
      "Now encrypting to binary files  for Python and C support. . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "############### From Keras To C weight encryption ####################\n",
    "import h5py\n",
    "\n",
    "def isgroup(obj):\n",
    "    if isinstance(obj, h5py.Group):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isdataset(obj):\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_DatasetsfromGroup(datasets, obj):\n",
    "    if isgroup(obj):\n",
    "        for key in obj:\n",
    "            x = obj[key]\n",
    "            #print(x)\n",
    "            get_DatasetsfromGroup(datasets, x)\n",
    "    else:\n",
    "        datasets.append(obj)\n",
    "\n",
    "def getweightsforlayer(layername, filename):\n",
    "    weights = []\n",
    "    with h5py.File(filename, mode='r') as f:\n",
    "        for key in f:\n",
    "            if layername in key:\n",
    "                obj= f[key]\n",
    "                print(obj)\n",
    "                datasets = []\n",
    "                get_DatasetsfromGroup(datasets, obj)\n",
    "                \n",
    "                for dataset in datasets:\n",
    "                    w = np.array(dataset)\n",
    "                    weights.append(w)\n",
    "    return weights\n",
    "\n",
    "path = os.path.join(os.path.expanduser('~/eclipse-workspace/'), 'Utilities')\n",
    "weights = getweightsforlayer(\"conv2d\",path+'/Keras_Weights.h5')\n",
    "#for w in weights:\n",
    "#    print(w.shape)\n",
    "print(\"Reading from .h5 file completed!\")\n",
    "print(\"Now encrypting to binary files  for Python and C support. . .\")\n",
    "#Extraction from keras .h5 file completed, Now we are going to save them as encrypted binary for C support\n",
    "counter=0;\n",
    "filters = []\n",
    "bias = []\n",
    "fb_dc=[]\n",
    "temp = []\n",
    "\n",
    "######  Filters  #######\n",
    "for i in range(1,37,4):\n",
    "    tmp=np.array(weights[i])\n",
    "    temp1 = np.zeros((tmp.shape[3],tmp.shape[2],tmp.shape[0],tmp.shape[1]))\n",
    "    for f_num in range(tmp.shape[3]):\n",
    "        for ch in range(tmp.shape[2]):\n",
    "            for x in range(tmp.shape[0]):\n",
    "                for y in range(tmp.shape[1]):\n",
    "                    temp1[f_num,ch,x,y] = tmp[x,y,ch,f_num]\n",
    "    #temp1 = weights[i].reshape(weights[i].shape[3],weights[i].shape[2],weights[i].shape[0],weights[i].shape[1])\n",
    "    #print((weights[i]).reshape(weights[i].shape[3],weights[i].shape[2],weights[i].shape[0],weights[i].shape[1]).shape)\n",
    "    #filters[counter].append(temp)\n",
    "    tmp=np.array(weights[i+2])\n",
    "    temp2 = np.zeros((tmp.shape[3],tmp.shape[2],tmp.shape[0],tmp.shape[1]))\n",
    "    for f_num in range(tmp.shape[3]):\n",
    "        for ch in range(tmp.shape[2]):\n",
    "            for x in range(tmp.shape[0]):\n",
    "                for y in range(tmp.shape[1]):\n",
    "                    temp2[f_num,ch,x,y] = tmp[x,y,ch,f_num]\n",
    "    f = [temp1, temp2].copy()\n",
    "    filters.append(f)\n",
    "tmp=np.array(weights[37])\n",
    "temp2 = np.zeros((tmp.shape[3],tmp.shape[2],tmp.shape[0],tmp.shape[1]))\n",
    "for f_num in range(tmp.shape[3]):\n",
    "    for ch in range(tmp.shape[2]):\n",
    "        for x in range(tmp.shape[0]):\n",
    "            for y in range(tmp.shape[1]):\n",
    "                temp2[f_num,ch,x,y] = tmp[x,y,ch,f_num]\n",
    "out_f = temp2.copy()\n",
    "\n",
    "\n",
    "##### BIAS ######\n",
    "for i in range(0,36,4):\n",
    "    temp1 = weights[i] #b1\n",
    "    temp2 =  weights[i+2] #b2\n",
    "    b = [temp1 , temp2]\n",
    "    bias.append(b)\n",
    "out_b = weights[36]\n",
    "\n",
    "\n",
    "##### F_DC  ######\n",
    "for i in range(39,46,2):\n",
    "    tmp=np.array(weights[i])\n",
    "    temp2 = np.zeros((tmp.shape[2],tmp.shape[3],tmp.shape[0],tmp.shape[1]))\n",
    "    for f_num in range(tmp.shape[2]):\n",
    "        for ch in range(tmp.shape[3]):\n",
    "            for x in range(tmp.shape[0]):\n",
    "                for y in range(tmp.shape[1]):\n",
    "                    temp2[f_num,ch,x,y] = tmp[x,y,f_num,ch]\n",
    "    f_dc = temp2.copy()\n",
    "    b_dc = weights[i-1]\n",
    "    temp = [f_dc, b_dc]\n",
    "    fb_dc.append(temp)\n",
    "    \n",
    "## Packing and Saving##\n",
    "out_fb = [out_f,out_b]\n",
    "params = [filters, bias, fb_dc, out_fb] \n",
    "################# for C porting - #TODO: remove gamma,beta from encryption to C\n",
    "#ga, be = init_groupnorm_params(bias, out_b, 2, 0, 0.05)# quick fix\n",
    "#################\n",
    "#GN_params = []\n",
    "parameters = [filters, bias, fb_dc, out_fb]\n",
    "path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "with open(path+'/weights', 'wb') as fp:\n",
    "    pickle.dump(parameters, fp)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Conversion . .  .\n",
      "Starting . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "############### From Python To C weight encryption ####################\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "## read and extrada data from file\n",
    "print(\"Initializing Conversion . .  .\")\n",
    "path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "with open (path+'/weights', 'rb') as fp:\n",
    "    params = pickle.load(fp)  \n",
    "fp.close()\n",
    "### Unpacking ###\n",
    "[filters, bias, f_dc, out_fb] = params\n",
    "#[ga, be] = GN_params\n",
    "\n",
    "[f1,f2,f3,f4,f5,f6,f7,f8,f9] = filters\n",
    "[b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "[fb6_dc, fb7_dc, fb8_dc, fb9_dc] = f_dc\n",
    "[out_f, out_b] = out_fb\n",
    "\n",
    "#List --> Numpy\n",
    "filters = np.array(filters)\n",
    "bias = np.array(bias)\n",
    "f_dc = np.array(f_dc)\n",
    "out_f = np.array(out_f)\n",
    "out_b = np.array(out_b)\n",
    "#ga=np.array(ga)\n",
    "#be = np.array(be)\n",
    "\n",
    "print(\"Starting . . .\")\n",
    "#################\n",
    "#Validate(train_images[2:3,:,:,:], train_labels[2:3,:,:,:], params, 1)\n",
    "\n",
    "## Now encode the info to a different binary file\n",
    "path = os.path.join(os.path.expanduser('~/eclipse-workspace/'), 'Utilities')\n",
    "\n",
    "from array import array\n",
    "output_file = open(path+'/weights_encrypted.bin', 'wb')\n",
    "\n",
    "for i in range(9):# 9*2 filters\n",
    "    float_array = array('f', filters[i][0].flatten())# f#_1\n",
    "    float_array.tofile(output_file)\n",
    "    float_array = array('f', filters[i][1].flatten())# f#_2\n",
    "    float_array.tofile(output_file)\n",
    "float_array = array('f', out_f.flatten())#out_f\n",
    "float_array.tofile(output_file)\n",
    "## save bias\n",
    "for i in range(9):# 9*2 bias\n",
    "    float_array = array('f', bias[i][0].flatten()) #b#_1\n",
    "    float_array.tofile(output_file)\n",
    "    float_array = array('f', bias[i][1].flatten()) #b#_2\n",
    "    float_array.tofile(output_file)\n",
    "float_array = array('f', out_b.flatten()) #out_b \n",
    "float_array.tofile(output_file)\n",
    "#save fb_dc\n",
    "for i in range(4):\n",
    "    float_array = array('f', f_dc[i][0].flatten())# 4 dc filters\n",
    "    float_array.tofile(output_file)\n",
    "for i in range(4):\n",
    "    float_array = array('f', f_dc[i][1].flatten())# 4 dc bias\n",
    "    float_array.tofile(output_file)\n",
    "\"\"\"\n",
    "for i in range(9): #9*2 gamma\n",
    "    float_array = array('f', ga[i][0].flatten()) #ga#_1  ,shape: b.shape[0]//2\n",
    "    float_array.tofile(output_file)   \n",
    "    float_array = array('f', ga[i][1].flatten()) #ga#_1\n",
    "    float_array.tofile(output_file) \n",
    "for i in range(9): #9*2 beta\n",
    "    float_array = array('f', be[i][0].flatten()) #be#_1  ,shape: b.shape[0]//2\n",
    "    float_array.tofile(output_file)   \n",
    "    float_array = array('f', be[i][1].flatten()) #be#_1\n",
    "    float_array.tofile(output_file)     \n",
    "#close file\n",
    "\"\"\"\n",
    "print(\"Done!\")\n",
    "output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3cf98f329147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mValidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#GN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "Validate(train_images[0:1,:,:,:], train_labels[0:1,:,:,:], params, 0) #GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
