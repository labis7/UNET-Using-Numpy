{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\salt\n",
    "        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt2')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    #os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\"\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "    \"\"\"\n",
    "    dim=64\n",
    "    dataset=4\n",
    "    def _images(path,dim):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/images/\"\n",
    "        #cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY)\n",
    "        onlyfiles = [cv2.imread(folder+f, cv2.IMREAD_GRAYSCALE) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,dim,dim).astype('float32')/255\n",
    "        return pixels[:dataset,:,:,:]\n",
    "\n",
    "    def _labels(path,dim):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        \n",
    "        folder = path + \"/labels/\"\n",
    "        #onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(dim, dim)) for f in os.listdir(folder)]\n",
    "        #onlyfiles = [cv2.resize(cv2.imread(folder+f, cv2.IMREAD_GRAYSCALE),(dim, dim)) for f in os.listdir(folder)]\n",
    "        onlyfiles = [cv2.imread(folder+f, cv2.IMREAD_GRAYSCALE) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,dim,dim).astype('float32')/255\n",
    "        return pixels[:dataset,:,:,:]\n",
    "    \n",
    "    def _t_images(path,dim):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/t_images/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(dim, dim)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,dim,dim).astype('float32')#/255\n",
    "        return pixels[0:2,:,:,:]\n",
    "    def _t_labels(path,dim):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        \n",
    "        folder = path + \"/t_labels/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(dim, dim)) for f in os.listdir(folder)]\n",
    "        #onlyfiles = [cv2.resize(image.imread(folder+f),(32, 32)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,dim,dim).astype('float32') #/255\n",
    "        return pixels[0:2,:,:,:]\n",
    "\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(path,dim)\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(path,dim)\n",
    "    #print(\"Test Images  : Loading . . .\")\n",
    "    #test_images = _t_images(path,dim)\n",
    "    #print(\"Test Labels  : Loading . . .\")\n",
    "    #test_labels = _t_labels(path,dim)\n",
    "    print(\"Done!\")\n",
    "    return train_images, train_labels# , test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 64, 64)\n",
      "(4, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape) # ONE-HOT !!!\n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "#plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(train_labels[0].squeeze(), cmap='Greys_r');\n",
    "plt.imshow(train_labels[0].squeeze(),cmap='gray', vmin=0, vmax=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(train_labels[0].squeeze(), cmap='Greys_r');\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(train_labels[1].squeeze(), cmap='Greys_r');\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(train_labels[2].squeeze(), cmap='Greys_r');\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(train_labels[3].squeeze(), cmap='Greys_r');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(test_images[0].squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Filter/Parameter Initializattions  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f ,trim):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    \n",
    "    trimf = trim\n",
    "    trimb = trim*5\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    \"\"\"\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trimf #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trimb\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \"\"\"\n",
    "    trimbr = trim\n",
    "    locbr = 0\n",
    "    scb=1\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.normal(loc = locbr, scale = trimbr , size = f1) #np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.normal(loc = locbr, scale = trimbr*scb , size = (f1.shape[0],1)) #np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.normal(loc = locbr, scale = trimbr , size = f2)\n",
    "        b2 = np.random.normal(loc = locbr, scale = trimbr*scb, size = (f2.shape[0],1))\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc =  np.random.normal(loc = locbr, scale = trimbr , size = (n_f,ch_in,2,2))#upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.normal(loc = locbr, scale = trimbr*scb , size = (fdc.shape[0],1))\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.normal(loc = locbr, scale = trimbr , size = (n_f, ch_in, 3, 3))\n",
    "        b1 = np.random.normal(loc = locbr, scale = trimbr*scb , size = (f1.shape[0],1))\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.normal(loc = locbr, scale = trimbr , size = f2)\n",
    "        b2 = np.random.normal(loc = locbr, scale = trimbr*scb , size = (f2.shape[0],1))\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "    return filters, bias, f_dc   \n",
    "\n",
    "\n",
    "def init_groupnorm_params(bias, out_b, norm_batch, locbr, trimbr):\n",
    "    [b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "    \n",
    "    \n",
    "    t_1,_ = b1\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma1_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) #MAKE IT FLOAT\n",
    "    beta1_1  = np.random.normal( scale = trimbr , size = gb_size)\n",
    "    gamma1_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta1_2  = np.random.normal( scale = trimbr , size = gb_size)\n",
    "    tempg_1 = [gamma1_1,gamma1_2]\n",
    "    tempb_1 = [beta1_1,beta1_2]\n",
    "    \n",
    "    t_1,_ = b2\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma2_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta2_1  = np.random.normal( scale = trimbr , size = gb_size)\n",
    "    gamma2_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta2_2  = np.random.normal(scale = trimbr , size = gb_size)  \n",
    "    tempg_2 = [gamma2_1,gamma2_2]\n",
    "    tempb_2 = [beta2_1,beta2_2]\n",
    "    \n",
    "    t_1,_ = b3\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma3_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta3_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma3_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta3_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_3 = [gamma3_1,gamma3_2]\n",
    "    tempb_3 = [beta3_1,beta3_2]\n",
    "    \n",
    "    t_1,_ = b4\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma4_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta4_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma4_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta4_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_4 = [gamma4_1,gamma4_2]\n",
    "    tempb_4 = [beta4_1,beta4_2]\n",
    "    \n",
    "    t_1,_ = b5\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma5_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta5_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma5_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta5_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_5 = [gamma5_1,gamma5_2]\n",
    "    tempb_5 = [beta5_1,beta5_2]\n",
    "    \n",
    "    t_1,_ = b6\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma6_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta6_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma6_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta6_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_6 = [gamma6_1,gamma6_2]\n",
    "    tempb_6 = [beta6_1,beta6_2]\n",
    "    \n",
    "    t_1,_ = b7\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma7_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta7_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma7_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta7_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_7 = [gamma7_1,gamma7_2]\n",
    "    tempb_7 = [beta7_1,beta7_2]\n",
    "    \n",
    "    t_1,_ = b8\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma8_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta8_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma8_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta8_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_8 = [gamma8_1,gamma8_2]\n",
    "    tempb_8 = [beta8_1,beta8_2]\n",
    "    \n",
    "    t_1,_ = b9\n",
    "    gb_size =(t_1.shape[0]//norm_batch,1)\n",
    "    gamma9_1 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta9_1  = np.random.normal(scale = trimbr , size = gb_size)\n",
    "    gamma9_2 = np.random.normal(loc = locbr, scale = trimbr , size = gb_size) \n",
    "    beta9_2  = np.random.normal(scale = trimbr ,size =  gb_size)  \n",
    "    tempg_9 = [gamma9_1,gamma9_2]\n",
    "    tempb_9 = [beta9_1,beta9_2]\n",
    "    \n",
    "    ga =[tempg_1,tempg_2,tempg_3,tempg_4,tempg_5,tempg_6, tempg_7,tempg_8,tempg_9]\n",
    "    be =[tempb_1,tempb_2,tempb_3,tempb_4,tempb_5,tempb_6, tempb_7,tempb_8,tempb_9]\n",
    "    \n",
    "    #gamma_out = np.random.normal(loc = locbr, scale = trimbr , size = (out_b.shape[0]//norm_batch,1))\n",
    "    #beta_out =   np.random.normal(scale = trimbr , size = (out_b.shape[0]//norm_batch,1))\n",
    "    \n",
    "    return ga, be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "\n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(np.multiply(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] , f[z, :, :, :])) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    #filt =np.rot90(filt, 2)  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!! A T T E N T I O N !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "def convTransp1(image, params, s = 2, pad = 1):\n",
    "    [f, b] = params\n",
    "    n_f, n_c, f_s, _ = f.shape\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2\n",
    "    res = np.zeros((n_f, target_dim, target_dim))\n",
    "    temp =np.zeros((n_c, target_dim, target_dim))\n",
    "    for z in range(n_f):\n",
    "        for _h in range(input_s):      \n",
    "            for _w in range(input_s):\n",
    "                temp[:, _h*s:_h*s+f_s, _w*s:_w*s+f_s] += image[:, _h, _w].reshape(n_c,1,1)*f[z,:,:,:] #bias will be added at the end\n",
    "        res[z] = np.sum(temp , axis = 0) + b[z]\n",
    "    return res, image\n",
    "\n",
    "def convTranspBackward1(dconv_prev, new_in, filt, s = 2):\n",
    "    n_f, n_c, f_s, _ = filt.shape\n",
    "    _, input_s, _ = new_in.shape\n",
    "    #final_dim = (new_in.shape[1] - 2)//2 + 1 \n",
    "    dc_s=dconv_prev.shape[1]\n",
    "    temp = np.zeros((n_c,dc_s,dc_s))\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    dconv_in = np.zeros(new_in.shape)\n",
    "    db = np.zeros((n_f,1))\n",
    "    for z in range(n_f):\n",
    "        for _h in range(input_s):      \n",
    "            for _w in range(input_s): \n",
    "                dfilt[z] += dconv_prev[z, _h*s:_h*s+f_s, _w*s:_w*s+f_s]*new_in[:,_h,_w].reshape(n_c,1,1)\n",
    "                temp[:, _h*s:_h*s+f_s, _w*s:_w*s+f_s] += dconv_prev[z, _h*s:_h*s+f_s, _w*s:_w*s+f_s] * filt[z]\n",
    "                for ch in range(n_c):\n",
    "                    dconv_in[ch, _h, _w] += np.sum(temp[ch, _h*s:_h*s+f_s, _w*s:_w*s+f_s])\n",
    "        db[z] = np.sum(dconv_prev[z])        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "    \n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    [f, b]=params\n",
    "    f = np.rot90(f, 2, (2,3))\n",
    "    params = [f, b]\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    \n",
    "    ### OR just: np.pad(image[:,:,:],2,'constant') # Important, we must loop with respect to the 1st dim\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    #filt = np.rot90(filt, 2, (2,3))\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "\n",
    "    idx = np.nanargmax(arr)\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h*s + a, _w*s + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "        print(\"Warning: Extra crop needed and handled!(%d --> %d)\" %(dim, img2.shape[1]))\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def Cross_Entropy(logs, targets):  # Pixel-Wise Cross entropy --> average accuracy\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[2]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] >= logs[:,i,j]):#Gray and above\n",
    "                out[:,i,j] = logs[:,i,j]/targets[:,i,j] \n",
    "            else:\n",
    "                out[:,i,j] = (1 - logs[:,i,j])/(1 - targets[:,i,j]) # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    res =out.sum()/mylen\n",
    "    return -np.log(res),res\n",
    "\n",
    "\n",
    "def Dice_Coef(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[2]\n",
    "    #Apply Dice coefficient\n",
    "    numerator = (logs*targets)\n",
    "    denominator = logs + targets\n",
    "    loss = 1 - (2*np.sum(numerator))/(np.sum(denominator))\n",
    "    return loss, np.exp(-loss)\n",
    "                \n",
    "    \n",
    "    \n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "def normalize(output):\n",
    "    output[output<-4]=-4\n",
    "    output[output>4] = 4\n",
    "    return output\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupnorm_forward(X, gamma_, beta_, eps=1e-5):\n",
    "   \n",
    "    C_all=X.shape[0]\n",
    "    \n",
    "    if(C_all == 1):\n",
    "        batch = 1\n",
    "    else:\n",
    "        batch =2\n",
    "    C= batch\n",
    "    \n",
    "    mu_= np.zeros(C_all//batch)\n",
    "    var_=np.zeros(C_all//batch)\n",
    "    xmu_=np.zeros((C_all,X.shape[1],X.shape[2]))\n",
    "    sqrtvar_= np.zeros(C_all//batch)\n",
    "    ivar_= np.zeros(C_all//batch)\n",
    "    xhat_= np.zeros((C_all,X.shape[1],X.shape[2]))\n",
    "    #gammax_= np.zeros((C_all,1,1))\n",
    "    out_= np.zeros((C_all,X.shape[1],X.shape[2]))\n",
    "    \n",
    "    \n",
    "    for i in range(0, C_all, batch):\n",
    "        \n",
    "        x = X[i:i+C,:,:]\n",
    "        gamma = gamma_[i//batch]  #there is a gamma,beta for each batch of channels\n",
    "        beta = beta_[i//batch]\n",
    "        ###################################################################\n",
    "        _, H, W = x.shape  #WAS N, D\n",
    "        \n",
    "        #step1: calculate mean\n",
    "        mu = np.mean(x) #scalar\n",
    "        #print(mu)\n",
    "        \n",
    "        #step2: subtract mean vector of every trainings example\n",
    "        xmu = (x - mu)\n",
    "        \n",
    "        #step3: following the lower branch - calculation denominator\n",
    "        #step4: calculate variance\n",
    "        var = np.mean(xmu ** 2)\n",
    "        \n",
    "        #step5: add eps for numerical stability, then sqrt\n",
    "        sqrtvar = np.sqrt(var + eps)\n",
    "        \n",
    "        #step6: invert sqrtvar\n",
    "        ivar = 1./sqrtvar\n",
    "        \n",
    "        #step7: execute normalization\n",
    "        xhat = xmu * ivar\n",
    "        \n",
    "        #step8: Nor the two transformation steps\n",
    "        gammax = gamma * xhat\n",
    "        #gamma,beta : scalar\n",
    "        #step9\n",
    "        out = gammax + beta\n",
    "        \n",
    "        xhat_[i:i+C,:,:]   =xhat   #.copy()\n",
    "        #gamma_[i:i+2,:,:]  =gamma\n",
    "        xmu_[i:i+C,:,:]    =xmu\n",
    "        ivar_[i//batch]  =ivar\n",
    "        sqrtvar_[i//batch]=sqrtvar\n",
    "        var_[i//batch]   =var\n",
    "        out_[i:i+C,:,:]   =out\n",
    "    #store intermediate\n",
    "    cache = (xhat_,gamma_,xmu_,ivar_,sqrtvar_,var_,eps)\n",
    "    return out_, cache\n",
    "\n",
    "def groupnorm_backward(dout_, cache):\n",
    "\n",
    "    #unfold the variables stored in cache\n",
    "    xhat_,gamma_,xmu_,ivar_,sqrtvar_,var_,eps = cache\n",
    "\n",
    "    \n",
    "    C_all =dout_.shape[0]\n",
    "    if(C_all == 1):\n",
    "        C = 1\n",
    "    else:\n",
    "        C = 2\n",
    "    \n",
    "    batch = C\n",
    "    dx_    = np.zeros((C_all,dout_.shape[1],dout_.shape[2]))\n",
    "    dgamma_= np.zeros(C_all//batch)\n",
    "    dbeta_ = np.zeros(C_all//batch)\n",
    "    \n",
    "    for i in range(0, C_all, batch): \n",
    "        dout = dout_[i:i+C,:,:]\n",
    "        xhat   =xhat_[i:i+C,:,:]\n",
    "        gamma  = gamma_[i//batch]\n",
    "        xmu    =xmu_[i:i+C,:,:]\n",
    "        ivar   =ivar_[i//batch]\n",
    "        sqrtvar=sqrtvar_[i//batch]\n",
    "        var    =var_[i//batch]\n",
    "        \n",
    "        #get the dimensions of the input/output\n",
    "        _, H, W = dout.shape #N,D = dout.shape\n",
    "\n",
    "        #step9\n",
    "        dbeta = np.sum(dout)\n",
    "        dgammax = dout #not necessary, but more understandable\n",
    "\n",
    "        #step8\n",
    "        dgamma = np.sum(dgammax*xhat)\n",
    "        dxhat = dgammax * gamma\n",
    "\n",
    "        #step7\n",
    "        divar = np.sum(dxhat*xmu)\n",
    "        dxmu1 = dxhat * ivar\n",
    "\n",
    "        #step6\n",
    "        dsqrtvar = -1. /(sqrtvar**2) * divar\n",
    "\n",
    "        #step5\n",
    "        dvar = 0.5 * 1. /np.sqrt(var+eps) * dsqrtvar\n",
    "\n",
    "        #step4\n",
    "        dsq = 1./(batch*H*W) * np.ones((C,H,W)) * dvar  #1./C\n",
    "\n",
    "        #step3\n",
    "        dxmu2 = 2 * xmu * dsq\n",
    "\n",
    "        #step2\n",
    "        dx1 = (dxmu1 + dxmu2)\n",
    "        dmu = -1 * np.sum(dxmu1+dxmu2)\n",
    "\n",
    "        #step1\n",
    "        dx2 =  1./(batch*H*W) *np.ones((C,H,W)) * dmu #1. /C *\n",
    "\n",
    "        #step0\n",
    "        dx = dx1 + dx2\n",
    "        dx_[i:i+C,:,:]    = dx\n",
    "        dgamma_[i//batch]= dgamma\n",
    "        dbeta_[i//batch] = dbeta\n",
    "\n",
    "    return dx_, dgamma_.reshape(C_all//batch,1), dbeta_.reshape(C_all//batch,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validate(X, Y, params, GN):\n",
    "    ### Unpacking ###\n",
    "    [filters, bias, f_dc, out_fb, GN_params] = params\n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7,f8,f9] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "    [fb6_dc, fb7_dc, fb8_dc, fb9_dc] = f_dc\n",
    "    [out_f, out_b] = out_fb\n",
    "    if(GN == 1):\n",
    "        [ga, be] = GN_params\n",
    "    else:\n",
    "        ga, be = init_groupnorm_params(bias, out_b, 2, 0, 0.05)# quick fix\n",
    "\n",
    "    #################\n",
    "    \n",
    "    \n",
    "    dropout = 0\n",
    "    print('Calculating Forward step . . .')\n",
    "    \n",
    "    batch = 1\n",
    "    for c in range(0, X.shape[0], batch):\n",
    "        if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "            batch = X.shape[0] - c\n",
    "        X_t = X[c:(c + batch)]\n",
    "        Y_t = Y[c:(c + batch)]\n",
    "        for b in range(batch):\n",
    "            ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "            conv1_1, conv1_2, normcache1_1, normcache1_2 = Conv_Block(\"Forward\", f1, b1, X_t[b], dropout, GN, ga[0], be[0])\n",
    "            ##################################### conv1_2: 128x128x16\n",
    "\n",
    "            pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (128-2)/2+1  = 64 \n",
    "\n",
    "            ########### 2nd Big Layer ########### \n",
    "            conv2_1, conv2_2, normcache2_1, normcache2_2 = Conv_Block(\"Forward\", f2, b2, pl1, dropout, GN, ga[1], be[1])          \n",
    "            #####################################  64x64x32\n",
    "\n",
    "            pl2 = maxpool(conv2_2, 2, 2) #pool_f = 2 , pool_s = 2    , (64 -2)/2 +1 = 32\n",
    "\n",
    "            ########### 3rd Big Layer ###########\n",
    "            conv3_1, conv3_2, normcache3_1, normcache3_2 = Conv_Block(\"Forward\", f3, b3, pl2, dropout, GN, ga[2], be[2])          \n",
    "            #####################################  32x32x64\n",
    "\n",
    "            pl3 = maxpool(conv3_2, 2, 2) #pool_f = 2 , pool_s = 2   ,  (32-2)/2 +1 = 16\n",
    "\n",
    "            ########### 4th Big Layer ###########\n",
    "            conv4_1, conv4_2, normcache4_1, normcache4_2 = Conv_Block(\"Forward\", f4, b4, pl3, dropout, GN, ga[3], be[3])             \n",
    "            #####################################     16x16x128\n",
    "\n",
    "            pl4 = maxpool(conv4_2, 2, 2) #pool_f = 2 , pool_s = 2  , (16-2)/2 +1 =8  : 8x8x128\n",
    "\n",
    "            ########### 5th Big Layer ###########   8x8x128-->8x8x256\n",
    "            conv5_1, conv5_2, normcache5_1, normcache5_2 = Conv_Block(\"Forward\", f5, b5, pl4, dropout, GN, ga[4], be[4])       \n",
    "            #####################################  8x8x256\n",
    "\n",
    "            #####################################\n",
    "            #Because of ambigious size after the upsampling the concat func must take care possible crop of the conv#_2 \n",
    "            #####################################\n",
    "            #Deconvolution/Upsampling\n",
    "            # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "            params = [fb6_dc[0], fb6_dc[1]] # deconv filter, deconv bias\n",
    "            dc6, new_in6 = convTransp(conv5_2, params, 1, 0)   #result:   =  16x16x128 , # conv5_2 requires NO crop\n",
    "            #Concat dc6 with conv4_2 so we get 256 channels (16x16x256)\n",
    "            c6 = concat(dc6, conv4_2) # 1st one is the right one size  \n",
    "\n",
    "            ########### 6th Big Layer ###########          16x16x256     \n",
    "            conv6_1, conv6_2, normcache6_1, normcache6_2 = Conv_Block(\"Forward\", f6, b6, c6, dropout, GN, ga[5], be[5])  \n",
    "            #####################################    16x16x128\n",
    "            #(16-1)*2 + 2 =32\n",
    "            params = [fb7_dc[0], fb7_dc[1]] # deconv filter, deconv bias\n",
    "            dc7, new_in7 = convTransp(conv6_2, params, 1, 0)   #result:   =  32x32x64\n",
    "            #Concat dc7 with conv3_2 so we get  channels (32x32x128)\n",
    "            c7 = concat(dc7, conv3_2)   \n",
    "\n",
    "            ########### 7th Big Layer ###########          32x32x128     \n",
    "            conv7_1, conv7_2, normcache7_1, normcache7_2 = Conv_Block(\"Forward\", f7, b7, c7, dropout, GN, ga[6], be[6]) \n",
    "            #####################################    32x32x64\n",
    "            #(24-1)*2 + 2 = 48\n",
    "            params = [fb8_dc[0], fb8_dc[1]] # deconv filter, deconv bias\n",
    "            dc8, new_in8 = convTransp(conv7_2, params, 1, 0)   #result:   =  64x64x32\n",
    "            #Concat dc8 with conv2_2 so we get  channels (64x64x64)\n",
    "            c8 = concat(dc8 ,conv2_2)   \n",
    "\n",
    "            ########### 8th Big Layer ###########          64x64x64    \n",
    "            conv8_1, conv8_2, normcache8_1, normcache8_2 = Conv_Block(\"Forward\", f8, b8, c8, dropout, GN, ga[7], be[7])\n",
    "            #####################################    64x64x32                              \n",
    "            #(64-1)*2 + 2 = 128\n",
    "            params = [fb9_dc[0], fb9_dc[1]] # deconv filter, deconv bias\n",
    "            dc9, new_in9 = convTransp(conv8_2, params, 1, 0)   #result:   =  128x128x16\n",
    "            #Concat dc9 with conv1_2 so we get  channels (128x128x32)\n",
    "            c9 = concat(dc9, conv1_2)                   \n",
    "\n",
    "            ########### 9th Big Layer ###########          128x128x32   \n",
    "            conv9_1, conv9_2, normcache9_1, normcache9_2 = Conv_Block(\"Forward\", f9, b9, c9, dropout, GN, ga[8], be[8])\n",
    "            #####################################    128x128x16\n",
    "\n",
    "            ############################# Last Layer conv(1x1) --> 128x128x1 ##########################\n",
    "            params = [out_f, out_b]\n",
    "            output = conv(conv9_2, params, 1, 0) #output.shape: 128x128x1\n",
    "\n",
    "            #print(output[:,0:10,0:10])\n",
    "            #output = normalize(output)\n",
    "            ## Sigmoid ##\n",
    "            Y_hat = sigmoid(output)\n",
    "            \n",
    "            #Y_hat[Y_hat>0.65]=1\n",
    "            #Y_hat[Y_hat<0.35]=0\n",
    "\n",
    "            plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "            cost_,accuracy_ = Dice_Coef(Y_hat, Y_t[b])#Cross_Entropy(Y_hat, Y_t[b])\n",
    "            cost = cost_\n",
    "            accuracy = accuracy_\n",
    "            print(\"Cost: {:.2f}   -   Accuracy: {:.2f}%\".format(cost/batch, (accuracy*100)/batch))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_Block(step, f, b, myin, dropout, GN, ga, be):\n",
    "    if(step == \"Forward\"):\n",
    "        bc1 = 0\n",
    "        bc2 = 0\n",
    "        ### DROPOUT ###\n",
    "        if(dropout>0):\n",
    "            d = (np.random.rand(myin.shape[0],myin.shape[1],myin.shape[2])<dropout)\n",
    "            d = d*1 #Bool --> int(0s and 1s)\n",
    "            myin = d*myin\n",
    "        ###############\n",
    "        params = [f[0], b[0]]  \n",
    "        conv1 = conv(myin, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "        ### GROUP NORM ###\n",
    "        if(GN == 1):\n",
    "            conv1, bc1 = groupnorm_forward(conv1, ga[0], be[0]) \n",
    "        ##################\n",
    "        conv1[conv1<=0] = 0 #Relu\n",
    "\n",
    "        params = [f[1], b[1]]\n",
    "        conv2 = conv(conv1, params, 1)\n",
    "        ### GROUP NORM ###\n",
    "        if(GN == 1):\n",
    "            conv2, bc2 = groupnorm_forward(conv2, ga[1], be[1]) \n",
    "        ##################\n",
    "        conv2[conv2<=0] = 0 #Relu\n",
    "        return conv1, conv2, bc1, bc2\n",
    "    else: #Backward\n",
    "        if(isinstance(GN, int)):\n",
    "            dconv_prev = b\n",
    "            conv_prev = myin\n",
    "            conv_prev1 = dropout\n",
    "            conc = ga\n",
    "            dconv_prev[conv_prev<=0] = 0\n",
    "            dconv1, df2, db2 = convolutionBackward(dconv_prev, conv_prev1, f[1], 1) #\n",
    "            #pack data\n",
    "            dconv1[conv_prev1<=0] = 0\n",
    "            conc_dconv1, df1, db1 = convolutionBackward(dconv1, conc, f[0], 1) #\n",
    "            return conc_dconv1, df2, db2, df1, db1\n",
    "        else:\n",
    "            dconv_prev = b\n",
    "            conv_prev = myin\n",
    "            conv_prev1 = dropout\n",
    "            conc = GN\n",
    "            normcache1 = ga\n",
    "            normcache2 = be\n",
    "            dconv_prev[conv_prev<=0] = 0 \n",
    "            dconv_prev, dgamma1_2, dbeta1_2 = groupnorm_backward(dconv_prev, normcache2)\n",
    "            dconv1_1, df1_2, db1_2 = convolutionBackward(dconv_prev, conv_prev1, f[1], 1) #\n",
    "            #pack data\n",
    "            dconv1_1[conv_prev1<=0] = 0\n",
    "            dconv1_1, dgamma1_1, dbeta1_1 = groupnorm_backward(dconv1_1, normcache1)\n",
    "            dga= [dgamma1_1,dgamma1_2]\n",
    "            dbe= [dbeta1_1,dbeta1_2]\n",
    "            conc_dconv1, df1_1, db1_1 = convolutionBackward(dconv1_1, conc, f[0], 1) #C9 is not needed for input,we know how to select the right gradients   \n",
    "            return conc_dconv1, df1_2, db1_2, df1_1, db1_1, dga, dbe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, GN):\n",
    "    verbose=True\n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    trim = 0.1\n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    filters,bias, f_dc = init_filters(5, 16, trim) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "    ##Final 1x1 filter\n",
    "    \n",
    "    \n",
    "    #out_f = np.random.randn(1,16,1,1)*trim\n",
    "    #out_b = np.random.randn(out_f.shape[0],1)*trim \n",
    "    out_f = (1,16,1,1)\n",
    "    out_f = np.random.normal(loc = 0, scale = trim , size = out_f) #np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "    out_b = (out_f.shape[0],1)\n",
    "    out_b = np.random.normal(loc = 0, scale = trim , size = out_b) #np.random.randn(f1.shape[0],1)* trimb\n",
    "    out_fb = [out_f, out_b]\n",
    "    \n",
    "    ### Initialize group normalization parameters\n",
    "    ga, be = init_groupnorm_params(bias, out_b, 2, 0, 0.05)#norm_batch, lockbr, trimbr\n",
    "    \n",
    "    print(\"************************************\")\n",
    "    if(GN>0):\n",
    "        print(\"Group Normalization Enabled!\")\n",
    "    else:\n",
    "        print(\"Group Normalization Disabled!\")\n",
    "    if(dropout>0):\n",
    "        print(\"Dropout Enabled! -  Value: {}\".format(dropout))\n",
    "    else:\n",
    "        print(\"Dropout Disabled!\")\n",
    "    print(\"Learning rate: {}\".format(learning_rate))\n",
    "    print(\"Dataset Size: {}\".format(X.shape[0]))\n",
    "    print(\"Weight scale: {}\".format(trim))\n",
    "    print(\"************************************\")\n",
    "    \n",
    "    #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "\n",
    "    accuracy_history=[]\n",
    "    \n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]  \n",
    "\n",
    "            \n",
    "\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7,f8,f9] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "    [fb6_dc, fb7_dc, fb8_dc, fb9_dc] = f_dc\n",
    "    \n",
    "    last_acc = 0\n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        running_loss = 0\n",
    "        cost = 0\n",
    "        accuracy = 0\n",
    "        batch = 2\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            print('Batch: {}'.format(int(c/batch +1)))\n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.92\n",
    "            beta2= 0.995\n",
    "            lr = learning_rate\n",
    "            batch_size= batch\n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            \n",
    "            \n",
    "            df =  []\n",
    "            db =  []\n",
    "            dfb=  []\n",
    "            for i in filters:\n",
    "                v1 = np.zeros(i[0].shape)\n",
    "                v2 = np.zeros(i[1].shape)\n",
    "                s1 = np.zeros(i[0].shape)\n",
    "                s2 = np.zeros(i[1].shape)\n",
    "                v_a = [v1, v2]\n",
    "                s_a = [s1, s2]\n",
    "                v_adam.append(v_a)\n",
    "                s_adam.append(s_a)\n",
    "                \n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                df2_t = np.zeros(i[1].shape)\n",
    "                f_temp = [df1_t, df2_t]\n",
    "                df.append(f_temp)\n",
    "                \n",
    "            for i in bias:\n",
    "                bv1 = np.zeros(i[0].shape)\n",
    "                bv2 = np.zeros(i[1].shape)\n",
    "                bs1 = np.zeros(i[0].shape)\n",
    "                bs2 = np.zeros(i[1].shape)    \n",
    "                bv_a = [bv1, bv2]\n",
    "                bs_a = [bs1, bs2]\n",
    "                bv_adam.append(bv_a)\n",
    "                bs_adam.append(bs_a)\n",
    "                \n",
    "                \n",
    "                db1_t = np.zeros(i[0].shape)\n",
    "                db2_t = np.zeros(i[1].shape)\n",
    "                b_temp = [db1_t, db2_t]\n",
    "                db.append(b_temp)\n",
    "            \n",
    "            for i in f_dc:\n",
    "                fdc_v1 = np.zeros(i[0].shape)\n",
    "                bdc_v2 = np.zeros(i[1].shape)\n",
    "                fdc_s1 = np.zeros(i[0].shape)\n",
    "                bdc_s2 = np.zeros(i[1].shape)    \n",
    "                fdc_v_a = [fdc_v1, bdc_v2]\n",
    "                fdc_s_a = [fdc_s1, bdc_s2]\n",
    "                fdc_v_adam.append(fdc_v_a)\n",
    "                fdc_s_adam.append(fdc_s_a)\n",
    "                \n",
    "                \n",
    "                df1_t = np.zeros(i[0].shape)\n",
    "                db1_t = np.zeros(i[1].shape)\n",
    "                fb_temp = [df1_t, db1_t]\n",
    "                dfb.append(fb_temp)\n",
    "            \n",
    "            \n",
    "            #Final layer 1x1 filter setup\n",
    "\n",
    "            v_out_f = np.zeros(out_f.shape)\n",
    "            s_out_f = np.zeros(out_f.shape)\n",
    "            bv_out_b = np.zeros(out_b.shape)\n",
    "            bs_out_b = np.zeros(out_b.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            dout_f = np.zeros(out_f.shape)\n",
    "            dout_b = np.zeros(out_b.shape)\n",
    "            \n",
    "            ######################################\n",
    "            \n",
    "            \n",
    "            #timestamp1 = time.time()\n",
    "            \n",
    "            \n",
    "            [df1,df2,df3,df4,df5,df6,df7,df8,df9] = df\n",
    "            [db1,db2,db3,db4,db5,db6,db7,db8,db9] = db \n",
    "            [dfb6_dc,dfb7_dc,dfb8_dc,dfb9_dc]     = dfb\n",
    "            \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print('Image: {}/{}'.format((b+1),batch))\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                conv1_1, conv1_2, normcache1_1, normcache1_2 = Conv_Block(\"Forward\", f1, b1, X_t[b], dropout, GN, ga[0], be[0])\n",
    "                ##################################### conv1_2: 128x128x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (128-2)/2+1  = 64 \n",
    "                \n",
    "                ########### 2nd Big Layer ########### \n",
    "                conv2_1, conv2_2, normcache2_1, normcache2_2 = Conv_Block(\"Forward\", f2, b2, pl1, dropout, GN, ga[1], be[1])          \n",
    "                #####################################  64x64x32\n",
    "\n",
    "                pl2 = maxpool(conv2_2, 2, 2) #pool_f = 2 , pool_s = 2    , (64 -2)/2 +1 = 32\n",
    "\n",
    "                ########### 3rd Big Layer ###########\n",
    "                conv3_1, conv3_2, normcache3_1, normcache3_2 = Conv_Block(\"Forward\", f3, b3, pl2, dropout, GN, ga[2], be[2])          \n",
    "                #####################################  32x32x64\n",
    "\n",
    "                pl3 = maxpool(conv3_2, 2, 2) #pool_f = 2 , pool_s = 2   ,  (32-2)/2 +1 = 16\n",
    "\n",
    "                ########### 4th Big Layer ###########\n",
    "                conv4_1, conv4_2, normcache4_1, normcache4_2 = Conv_Block(\"Forward\", f4, b4, pl3, dropout, GN, ga[3], be[3])             \n",
    "                #####################################     16x16x128\n",
    "\n",
    "                pl4 = maxpool(conv4_2, 2, 2) #pool_f = 2 , pool_s = 2  , (16-2)/2 +1 =8  : 8x8x128\n",
    "                \n",
    "                ########### 5th Big Layer ###########   8x8x128-->8x8x256\n",
    "                conv5_1, conv5_2, normcache5_1, normcache5_2 = Conv_Block(\"Forward\", f5, b5, pl4, dropout, GN, ga[4], be[4])       \n",
    "                #####################################  8x8x256\n",
    "\n",
    "                #####################################\n",
    "                #Because of ambigious size after the upsampling the concat func must take care possible crop of the conv#_2 \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "                params = [fb6_dc[0], fb6_dc[1]] # deconv filter, deconv bias\n",
    "                dc6, new_in6 = convTransp(conv5_2, params, 1, 0)   #result:   =  16x16x128 , # conv5_2 requires NO crop\n",
    "                #Concat dc6 with conv4_2 so we get 256 channels (16x16x256)\n",
    "                c6 = concat(dc6, conv4_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 6th Big Layer ###########          16x16x256     \n",
    "                conv6_1, conv6_2, normcache6_1, normcache6_2 = Conv_Block(\"Forward\", f6, b6, c6, dropout, GN, ga[5], be[5])  \n",
    "                #####################################    16x16x128\n",
    "                #(16-1)*2 + 2 =32\n",
    "                params = [fb7_dc[0], fb7_dc[1]] # deconv filter, deconv bias\n",
    "                dc7, new_in7 = convTransp(conv6_2, params, 1, 0)   #result:   =  32x32x64\n",
    "                #Concat dc7 with conv3_2 so we get  channels (32x32x128)\n",
    "                c7 = concat(dc7, conv3_2)   \n",
    "                \n",
    "                ########### 7th Big Layer ###########          32x32x128     \n",
    "                conv7_1, conv7_2, normcache7_1, normcache7_2 = Conv_Block(\"Forward\", f7, b7, c7, dropout, GN, ga[6], be[6]) \n",
    "                #####################################    32x32x64\n",
    "                #(24-1)*2 + 2 = 48\n",
    "                params = [fb8_dc[0], fb8_dc[1]] # deconv filter, deconv bias\n",
    "                dc8, new_in8 = convTransp(conv7_2, params, 1, 0)   #result:   =  64x64x32\n",
    "                #Concat dc8 with conv2_2 so we get  channels (64x64x64)\n",
    "                c8 = concat(dc8 ,conv2_2)   \n",
    "                \n",
    "                ########### 8th Big Layer ###########          64x64x64    \n",
    "                conv8_1, conv8_2, normcache8_1, normcache8_2 = Conv_Block(\"Forward\", f8, b8, c8, dropout, GN, ga[7], be[7])\n",
    "                #####################################    64x64x32                              \n",
    "                #(64-1)*2 + 2 = 128\n",
    "                params = [fb9_dc[0], fb9_dc[1]] # deconv filter, deconv bias\n",
    "                dc9, new_in9 = convTransp(conv8_2, params, 1, 0)   #result:   =  128x128x16\n",
    "                #Concat dc9 with conv1_2 so we get  channels (128x128x32)\n",
    "                c9 = concat(dc9, conv1_2)                   \n",
    "               \n",
    "                ########### 9th Big Layer ###########          128x128x32   \n",
    "                conv9_1, conv9_2, normcache9_1, normcache9_2 = Conv_Block(\"Forward\", f9, b9, c9, dropout, GN, ga[8], be[8])\n",
    "                #####################################    128x128x16\n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 128x128x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv9_2, params, 1, 0) #output.shape: 128x128x1\n",
    "                \n",
    "                #print(output[:,0:10,0:10])\n",
    "                #if(GN == 0):\n",
    "                output = normalize(output)\n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                \n",
    "                #label crop is needed\n",
    "                #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                #plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "                cost_,accuracy_ = Dice_Coef(Y_hat, Y_t[b])\n",
    "                cost += cost_\n",
    "                accuracy += accuracy_\n",
    "                print(accuracy_*100)\n",
    "                if((c+1) == X.shape[0]): #assuming that batch is always  1\n",
    "                    if (accuracy/(c+1)>last_acc):\n",
    "                        #plt.imshow(Y_hat.squeeze(), cmap='Greys_r');\n",
    "                        last_acc = accuracy/(c+1)\n",
    "                        print(\"New parameters Saved!\")\n",
    "                        GN_params = [ga, be]\n",
    "                        parameters = [filters, bias, f_dc, out_fb, GN_params]\n",
    "                        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "                        with open(path+'/weights', 'wb') as fp:\n",
    "                            pickle.dump(parameters, fp)\n",
    "                    if ((accuracy/(c+1))>0.99):\n",
    "                        print(\"Latest Accuracy: {}%\".format(accuracy*100))\n",
    "                        params_values = [filters, bias, f_dc, out_fb]\n",
    "                        return params_values\n",
    "                if(batch>1):\n",
    "                    if((c+b+1) == X.shape[0]):\n",
    "                        if((accuracy/(c+b+1))>last_acc):\n",
    "                            print(\"New parameters Saved!\")\n",
    "                            last_acc = accuracy/(c+b+1)\n",
    "                            #Saving\n",
    "                            GN_params = [ga, be]\n",
    "                            parameters = [filters, bias, f_dc, out_fb, GN_params]\n",
    "                            path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "                            with open(path+'/weights', 'wb') as fp:\n",
    "                                pickle.dump(parameters, fp)\n",
    "                    \n",
    "                \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = Y_hat - Y_t[b]\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv9_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv9_2, out_f, conv_s) #       \n",
    "                \n",
    "                if(GN == 0):\n",
    "                    conc_dconv9, df9_2, db9_2, df9_1, db9_1 = Conv_Block(\"Backward\", f9, dconv9_2, conv9_2, conv9_1, 0, c9, 0)\n",
    "                else:\n",
    "                    conc_dconv9, df9_2, db9_2, df9_1, db9_1, dga9, dbe9 = Conv_Block(\"Backward\", f9, dconv9_2, conv9_2, conv9_1, c9, normcache9_1, normcache9_2)\n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv9, dconv1_2 = crop2half(conc_dconv9)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                \n",
    "                dconv8_2, df9_dc, db9_dc = convTranspBackward(dconv9, new_in9, fb9_dc[0],conv_s)\n",
    "                #pack data\n",
    "\n",
    "                if(GN == 0):\n",
    "                    conc_dconv8, df8_2, db8_2, df8_1, db8_1 = Conv_Block(\"Backward\", f8, dconv8_2, conv8_2, conv8_1, 0, c8, 0)\n",
    "                else:\n",
    "                    conc_dconv8, df8_2, db8_2, df8_1, db8_1, dga8, dbe8 = Conv_Block(\"Backward\", f8, dconv8_2, conv8_2, conv8_1, c8, normcache8_1, normcache8_2)\n",
    "                    \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv8, dconv2_2 = crop2half(conc_dconv8)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #dconv2_2 = reshape(dconv2_2, conv2_2.shape[1])\n",
    "                \n",
    "                dconv7_2, df8_dc, db8_dc = convTranspBackward(dconv8, new_in8, fb8_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    conc_dconv7, df7_2, db7_2, df7_1, db7_1 = Conv_Block(\"Backward\", f7, dconv7_2, conv7_2, conv7_1, 0, c7, 0)\n",
    "                else:\n",
    "                    conc_dconv7, df7_2, db7_2, df7_1, db7_1, dga7, dbe7 = Conv_Block(\"Backward\", f7, dconv7_2, conv7_2, conv7_1, c7, normcache7_1, normcache7_2)\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv7, dconv3_2 = crop2half(conc_dconv7)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #Make sure that dconv3_2 is the same dim with the dconv3_2 that will come from maxpool in decoding side\n",
    "                #dconv3_2 = reshape(dconv3_2, conv3_2.shape[1])\n",
    "                \n",
    "                dconv6_2, df7_dc, db7_dc = convTranspBackward(dconv7, new_in7, fb7_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    conc_dconv6, df6_2, db6_2, df6_1, db6_1 = Conv_Block(\"Backward\", f6, dconv6_2, conv6_2, conv6_1, 0, c6, 0)\n",
    "                else:     \n",
    "                    conc_dconv6, df6_2, db6_2, df6_1, db6_1, dga6, dbe6 = Conv_Block(\"Backward\", f6, dconv6_2, conv6_2, conv6_1, c6, normcache6_1, normcache6_2)\n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv6, dconv4_2 = crop2half(conc_dconv6)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #dconv4_2 = reshape(dconv4_2, conv4_2.shape[1])\n",
    "                \n",
    "                dconv5_2, df6_dc, db6_dc = convTranspBackward(dconv6, new_in6, fb6_dc[0],conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    dpl4, df5_2, db5_2, df5_1, db5_1 = Conv_Block(\"Backward\", f5, dconv5_2, conv5_2, conv5_1, 0, pl4, 0)\n",
    "                else:     \n",
    "                    dpl4, df5_2, db5_2, df5_1, db5_1, dga5, dbe5 = Conv_Block(\"Backward\", f5, dconv5_2, conv5_2, conv5_1, pl4, normcache5_1, normcache5_2)\n",
    "\n",
    "                \n",
    "                dconv4_2 += maxpoolBackward(dpl4, conv4_2, f=2 , s=2) #Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    dpl3, df4_2, db4_2, df4_1, db4_1 = Conv_Block(\"Backward\", f4, dconv4_2, conv4_2, conv4_1, 0, pl3, 0)\n",
    "                else:     \n",
    "                    dpl3, df4_2, db4_2, df4_1, db4_1, dga4, dbe4 = Conv_Block(\"Backward\", f4, dconv4_2, conv4_2, conv4_1, pl3, normcache4_1, normcache4_2)\n",
    "\n",
    "\n",
    "                dconv3_2 += maxpoolBackward(dpl3, conv3_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    dpl2, df3_2, db3_2, df3_1, db3_1 = Conv_Block(\"Backward\", f3, dconv3_2, conv3_2, conv3_1, 0, pl2, 0)\n",
    "                else:     \n",
    "                    dpl2, df3_2, db3_2, df3_1, db3_1, dga3, dbe3 = Conv_Block(\"Backward\", f3, dconv3_2, conv3_2, conv3_1, pl2, normcache3_1, normcache3_2)\n",
    "\n",
    "                \n",
    "                dconv2_2 += maxpoolBackward(dpl2, conv2_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    dpl1, df2_2, db2_2, df2_1, db2_1 = Conv_Block(\"Backward\", f2, dconv2_2, conv2_2, conv2_1, 0, pl1, 0)\n",
    "                else:     \n",
    "                    dpl1, df2_2, db2_2, df2_1, db2_1, dga2, dbe2 = Conv_Block(\"Backward\", f2, dconv2_2, conv2_2, conv2_1, pl1, normcache2_1, normcache2_2)\n",
    "\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)#Very important += merge with the gradients from concat backprop\n",
    "                \n",
    "                if(GN == 0):\n",
    "                    _, df1_2, db1_2, df1_1, db1_1 = Conv_Block(\"Backward\", f1, dconv1_2, conv1_2, conv1_1, 0, X_t[b], 0)\n",
    "                else:     \n",
    "                    _, df1_2, db1_2, df1_1, db1_1, dga1, dbe1 = Conv_Block(\"Backward\", f1, dconv1_2, conv1_2, conv1_1, X_t[b], normcache1_1, normcache1_2)\n",
    "\n",
    "                \n",
    "                \n",
    "                if(GN == 1):\n",
    "                    dgamma = [dga1,dga2,dga3,dga4,dga5,dga6,dga7,dga8,dga9]\n",
    "                    dbeta = [dbe1,dbe2,dbe3,dbe4,dbe5,dbe6,dbe7,dbe8,dbe9]\n",
    "                \n",
    "\n",
    "                [df1,df2,df3,df4,df5,df6,df7,df8,df9] = df\n",
    "                [db1,db2,db3,db4,db5,db6,db7,db8,db9] = db \n",
    "                [dfb6_dc,dfb7_dc,dfb8_dc,dfb9_dc]     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                df4[0] += df4_1\n",
    "                df4[1] += df4_2\n",
    "                df5[0] += df5_1\n",
    "                df5[1] += df5_2\n",
    "                df6[0] += df6_1\n",
    "                df6[1] += df6_2\n",
    "                df7[0] += df7_1\n",
    "                df7[1] += df7_2\n",
    "                df8[0] += df8_1\n",
    "                df8[1] += df8_2\n",
    "                df9[0] += df9_1\n",
    "                df9[1] += df9_2\n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                db4[0] += db4_1\n",
    "                db4[1] += db4_2\n",
    "                db5[0] += db5_1\n",
    "                db5[1] += db5_2\n",
    "                db6[0] += db6_1\n",
    "                db6[1] += db6_2\n",
    "                db7[0] += db7_1\n",
    "                db7[1] += db7_2\n",
    "                db8[0] += db8_1\n",
    "                db8[1] += db8_2\n",
    "                db9[0] += db9_1\n",
    "                db9[1] += db9_2\n",
    "\n",
    "                dfb6_dc[0] += df6_dc\n",
    "                dfb6_dc[1] += db6_dc\n",
    "                dfb7_dc[0] += df7_dc\n",
    "                dfb7_dc[1] += db7_dc\n",
    "                dfb8_dc[0] += df8_dc\n",
    "                dfb8_dc[1] += db8_dc\n",
    "                dfb9_dc[0] += df9_dc\n",
    "                dfb9_dc[1] += db9_dc\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "                if(GN == 1):\n",
    "                    mytrim = 20\n",
    "                    for i in range(len(ga)):\n",
    "                        ga[i][0] -= lr*mytrim*dgamma[i][0]\n",
    "                        ga[i][1] -= lr*mytrim*dgamma[i][1]\n",
    "\n",
    "                        be[i][0] -= lr*mytrim*dbeta[i][0]\n",
    "                        be[i][1] -= lr*mytrim*dbeta[i][1]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in range(len(filters)):\n",
    "                v_adam[i][0] = beta1*v_adam[i][0] + (1-beta1)*df[i][0]/batch_size #f1\n",
    "                s_adam[i][0] = beta2*s_adam[i][0] + (1-beta2)*(df[i][0]/batch_size)**2 #f1\n",
    "                filters[i][0] -= lr*v_adam[i][0]/np.sqrt(s_adam[i][0] + 1e-7)\n",
    "\n",
    "                v_adam[i][1] = beta1*v_adam[i][1] + (1-beta1)*df[i][1]/batch_size #f2\n",
    "                s_adam[i][1] = beta2*s_adam[i][1] + (1-beta2)*(df[i][1]/batch_size)**2  #f2\n",
    "                filters[i][1] -= lr*v_adam[i][1]/np.sqrt(s_adam[i][1] + 1e-7)\n",
    "\n",
    "            for i in range(len(bias)):\n",
    "                bv_adam[i][0] = beta1*bv_adam[i][0] + (1-beta1)*db[i][0]/batch_size #b1\n",
    "                bs_adam[i][0] = beta2*bs_adam[i][0] + (1-beta2)*(db[i][0]/batch_size)**2  #b1\n",
    "                bias[i][0] -= lr*bv_adam[i][0]/np.sqrt(bs_adam[i][0] + 1e-7)\n",
    "\n",
    "                bv_adam[i][1] = beta1*bv_adam[i][1] + (1-beta1)*db[i][1]/batch_size #b2\n",
    "                bs_adam[i][1] = beta2*bs_adam[i][1] + (1-beta2)*(db[i][1]/batch_size)**2  #b2\n",
    "                bias[i][1] -= lr*bv_adam[i][1]/np.sqrt(bs_adam[i][1] + 1e-7)\n",
    "\n",
    "            for i in range(len(f_dc)):\n",
    "                fdc_v_adam[i][0] = beta1*fdc_v_adam[i][0] + (1-beta1)*dfb[i][0]/batch_size #f1\n",
    "                fdc_s_adam[i][0] = beta2*fdc_s_adam[i][0] + (1-beta2)*(dfb[i][0]/batch_size)**2  #f1\n",
    "                f_dc[i][0] -= lr*fdc_v_adam[i][0]/np.sqrt(fdc_s_adam[i][0] + 1e-7)\n",
    "\n",
    "                fdc_v_adam[i][1] = beta1*fdc_v_adam[i][1] + (1-beta1)*dfb[i][1]/batch_size #b2\n",
    "                fdc_s_adam[i][1] = beta2*fdc_s_adam[i][1] + (1-beta2)*(dfb[i][1]/batch_size)**2  #b2\n",
    "                f_dc[i][1] -= lr*fdc_v_adam[i][1]/np.sqrt(fdc_s_adam[i][1] + 1e-7)    \n",
    "\n",
    "            v_out_f = beta1*v_out_f + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out_f = beta2*s_out_f + (1 - beta2)*(dout_f/batch_size)**2  #f\n",
    "            out_fb[0] -= lr*v_out_f/np.sqrt(s_out_f + 1e-7)\n",
    "\n",
    "            bv_out_b = beta1*bv_out_b + (1 - beta1)*dout_b/batch_size #b\n",
    "            bs_out_b = beta2*bs_out_b + (1 - beta2)*(dout_b/batch_size)**2  #b\n",
    "            out_fb[1] -= lr*bv_out_b/np.sqrt(bs_out_b + 1e-7)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            '''\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            for i in range(len(filters)):\n",
    "                filters[i][0] -= lr*df[i][0]\n",
    "                bias[i][0] -= lr*db[i][0]\n",
    "            \n",
    "            for i in range(len(f_dc)):\n",
    "                f_dc[i][0] -= lr*dfb[i][0]\n",
    "            \n",
    "            out_fb[0] -= lr*dout_f\n",
    "            out_fb[1] -= lr*dout_b\n",
    "            \n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            #print(\"Batch:{}\".format(c+12))\n",
    "            \n",
    "           \n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            \n",
    "            '''\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        accuracy_history.append((accuracy*100)/(X.shape[0]))\n",
    "        if(batch == 1):\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/(c+1), (accuracy*100)/(X.shape[0])))\n",
    "        else:\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/(X.shape[0])))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "    #pack filters\n",
    "    #params_values = [filters, bias, f_dc, out_fb]\n",
    "    fp.close()\n",
    "    return parameters,accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Group Normalization Enabled!\n",
      "Dropout Disabled!\n",
      "Learning rate: 0.008\n",
      "Dataset Size: 4\n",
      "Weight scale: 0.1\n",
      "************************************\n",
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "62.68823665562904\n",
      "Image: 2/2\n",
      "69.41722774353994\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "56.87131876036052\n",
      "Image: 2/2\n",
      "48.26842091297506\n",
      "New parameters Saved!\n",
      "Epoch:     1   -   cost: 1.06   -   Accuracy: 59.31%\n",
      "Epoch: {2}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "74.44943538057542\n",
      "Image: 2/2\n",
      "72.24526841925184\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "59.80340558671743\n",
      "Image: 2/2\n",
      "55.92502160009377\n",
      "New parameters Saved!\n",
      "Epoch:     2   -   cost: 0.86   -   Accuracy: 65.61%\n",
      "Epoch: {3}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "64.71405016861775\n",
      "Image: 2/2\n",
      "67.16216221993434\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "60.37047871770939\n",
      "Image: 2/2\n",
      "61.722613984323715\n",
      "Epoch:     3   -   cost: 0.91   -   Accuracy: 63.49%\n",
      "Epoch: {4}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "62.97712918769472\n",
      "Image: 2/2\n",
      "69.43117710609474\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "60.62759701758953\n",
      "Image: 2/2\n",
      "64.1783240846373\n",
      "Epoch:     4   -   cost: 0.89   -   Accuracy: 64.30%\n",
      "Epoch: {5}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "67.09043824548053\n",
      "Image: 2/2\n",
      "73.13769194193577\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "65.25896396194817\n",
      "Image: 2/2\n",
      "69.33123431584006\n",
      "New parameters Saved!\n",
      "Epoch:     5   -   cost: 0.75   -   Accuracy: 68.70%\n",
      "Epoch: {6}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "72.38054075515275\n",
      "Image: 2/2\n",
      "80.10333887551126\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "69.26051325247971\n",
      "Image: 2/2\n",
      "77.23057397459378\n",
      "New parameters Saved!\n",
      "Epoch:     6   -   cost: 0.59   -   Accuracy: 74.74%\n",
      "Epoch: {7}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "57.01902566316027\n",
      "Image: 2/2\n",
      "76.52290980389542\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "68.16648555543088\n",
      "Image: 2/2\n",
      "76.82020912493697\n",
      "Epoch:     7   -   cost: 0.74   -   Accuracy: 69.63%\n",
      "Epoch: {8}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "76.16804662488099\n",
      "Image: 2/2\n",
      "82.70508655538134\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "70.68641490819368\n",
      "Image: 2/2\n",
      "79.7352256911067\n",
      "New parameters Saved!\n",
      "Epoch:     8   -   cost: 0.52   -   Accuracy: 77.32%\n",
      "Epoch: {9}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "79.49084281677794\n",
      "Image: 2/2\n",
      "86.14928221823261\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "78.2355608369754\n",
      "Image: 2/2\n",
      "80.38409843302853\n",
      "New parameters Saved!\n",
      "Epoch:     9   -   cost: 0.42   -   Accuracy: 81.06%\n",
      "Epoch: {10}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "80.97424542437534\n",
      "Image: 2/2\n",
      "87.2449903453918\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "77.48168398632598\n",
      "Image: 2/2\n",
      "83.35542373026526\n",
      "New parameters Saved!\n",
      "Epoch:    10   -   cost: 0.39   -   Accuracy: 82.26%\n",
      "Epoch: {11}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "83.95323106977042\n",
      "Image: 2/2\n",
      "88.09628121518888\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "80.75333242584547\n",
      "Image: 2/2\n",
      "84.84423249894874\n",
      "New parameters Saved!\n",
      "Epoch:    11   -   cost: 0.34   -   Accuracy: 84.41%\n",
      "Epoch: {12}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "85.75461837086453\n",
      "Image: 2/2\n",
      "89.36007109400366\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "82.89096463667258\n",
      "Image: 2/2\n",
      "86.29609443349452\n",
      "New parameters Saved!\n",
      "Epoch:    12   -   cost: 0.30   -   Accuracy: 86.08%\n",
      "Epoch: {13}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "87.81476424157529\n",
      "Image: 2/2\n",
      "90.43366430817903\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "84.64817764168153\n",
      "Image: 2/2\n",
      "87.81734957810038\n",
      "New parameters Saved!\n",
      "Epoch:    13   -   cost: 0.26   -   Accuracy: 87.68%\n",
      "Epoch: {14}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "88.59828942213433\n",
      "Image: 2/2\n",
      "91.35706684676414\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "85.51095390194261\n",
      "Image: 2/2\n",
      "88.67964526311624\n",
      "New parameters Saved!\n",
      "Epoch:    14   -   cost: 0.24   -   Accuracy: 88.54%\n",
      "Epoch: {15}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "90.0608426336379\n",
      "Image: 2/2\n",
      "92.14303952035306\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "87.43103164530064\n",
      "Image: 2/2\n",
      "88.7617634926638\n",
      "New parameters Saved!\n",
      "Epoch:    15   -   cost: 0.22   -   Accuracy: 89.60%\n",
      "Epoch: {16}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "89.68972448139026\n",
      "Image: 2/2\n",
      "92.5766894152609\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "84.1771290418142\n",
      "Image: 2/2\n",
      "84.01760334738437\n",
      "Epoch:    16   -   cost: 0.27   -   Accuracy: 87.62%\n",
      "Epoch: {17}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "88.3363592539156\n",
      "Image: 2/2\n",
      "92.36065136087569\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "87.05483360828819\n",
      "Image: 2/2\n",
      "88.09906553652759\n",
      "Epoch:    17   -   cost: 0.23   -   Accuracy: 88.96%\n",
      "Epoch: {18}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "88.52647313290338\n",
      "Image: 2/2\n",
      "92.4898283884939\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "87.12786997633617\n",
      "Image: 2/2\n",
      "88.2484372610758\n",
      "Epoch:    18   -   cost: 0.23   -   Accuracy: 89.10%\n",
      "Epoch: {19}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "89.84729285207138\n",
      "Image: 2/2\n",
      "92.69382605868023\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "88.50162473242142\n",
      "Image: 2/2\n",
      "88.70861670228264\n",
      "New parameters Saved!\n",
      "Epoch:    19   -   cost: 0.21   -   Accuracy: 89.94%\n",
      "Epoch: {20}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "90.77323610393093\n",
      "Image: 2/2\n",
      "93.12669677507976\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "89.2928829434801\n",
      "Image: 2/2\n",
      "89.45885789717335\n",
      "New parameters Saved!\n",
      "Epoch:    20   -   cost: 0.20   -   Accuracy: 90.66%\n",
      "Epoch: {21}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "91.26672294620532\n",
      "Image: 2/2\n",
      "93.41017027349059\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "89.75290476420129\n",
      "Image: 2/2\n",
      "90.27248469622953\n",
      "New parameters Saved!\n",
      "Epoch:    21   -   cost: 0.19   -   Accuracy: 91.18%\n",
      "Epoch: {22}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "92.04031738569856\n",
      "Image: 2/2\n",
      "93.6088552651555\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "90.42335224293736\n",
      "Image: 2/2\n",
      "90.96079687212581\n",
      "New parameters Saved!\n",
      "Epoch:    22   -   cost: 0.17   -   Accuracy: 91.76%\n",
      "Epoch: {23}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "92.64503522621848\n",
      "Image: 2/2\n",
      "94.14790226691893\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "91.49218295382674\n",
      "Image: 2/2\n",
      "91.41402044912633\n",
      "New parameters Saved!\n",
      "Epoch:    23   -   cost: 0.16   -   Accuracy: 92.42%\n",
      "Epoch: {24}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "93.03914984151174\n",
      "Image: 2/2\n",
      "94.56209732351206\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "91.89675127110992\n",
      "Image: 2/2\n",
      "92.06284298430774\n",
      "New parameters Saved!\n",
      "Epoch:    24   -   cost: 0.15   -   Accuracy: 92.89%\n",
      "Epoch: {25}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "93.28319491455522\n",
      "Image: 2/2\n",
      "94.62909096526315\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "92.16203268389575\n",
      "Image: 2/2\n",
      "92.42382078158646\n",
      "New parameters Saved!\n",
      "Epoch:    25   -   cost: 0.14   -   Accuracy: 93.12%\n",
      "Epoch: {26}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "93.4289830317397\n",
      "Image: 2/2\n",
      "94.98653230300617\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "92.258247537884\n",
      "Image: 2/2\n",
      "92.56688471029676\n",
      "New parameters Saved!\n",
      "Epoch:    26   -   cost: 0.14   -   Accuracy: 93.31%\n",
      "Epoch: {27}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "93.5930202772297\n",
      "Image: 2/2\n",
      "95.01952922413419\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "93.5362365657687\n",
      "Image: 2/2\n",
      "92.55521935061913\n",
      "New parameters Saved!\n",
      "Epoch:    27   -   cost: 0.13   -   Accuracy: 93.68%\n",
      "Epoch: {28}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "93.93424132983023\n",
      "Image: 2/2\n",
      "95.09204429324109\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "93.71040430021603\n",
      "Image: 2/2\n",
      "92.56065890106397\n",
      "New parameters Saved!\n",
      "Epoch:    28   -   cost: 0.13   -   Accuracy: 93.82%\n",
      "Epoch: {29}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "94.08791967978566\n",
      "Image: 2/2\n",
      "95.28469704224496\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "94.08968427487135\n",
      "Image: 2/2\n",
      "93.43332697963791\n",
      "New parameters Saved!\n",
      "Epoch:    29   -   cost: 0.12   -   Accuracy: 94.22%\n",
      "Epoch: {30}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "94.35599391165606\n",
      "Image: 2/2\n",
      "95.40426586801291\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "94.27740828319789\n",
      "Image: 2/2\n",
      "93.66118538002385\n",
      "New parameters Saved!\n",
      "Epoch:    30   -   cost: 0.11   -   Accuracy: 94.42%\n",
      "Epoch: {31}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "94.2519131995588\n",
      "Image: 2/2\n",
      "95.69406994087709\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "91.9956740061398\n",
      "Image: 2/2\n",
      "92.3496179963014\n",
      "Epoch:    31   -   cost: 0.13   -   Accuracy: 93.57%\n",
      "Epoch: {32}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "92.90702436058294\n",
      "Image: 2/2\n",
      "95.67292992714749\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "93.76376861838622\n",
      "Image: 2/2\n",
      "91.24433635659153\n",
      "Epoch:    32   -   cost: 0.14   -   Accuracy: 93.40%\n",
      "Epoch: {33}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "90.01529603733796\n",
      "Image: 2/2\n",
      "94.00204201084591\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "81.1497404055038\n",
      "Image: 2/2\n",
      "89.94546076666894\n",
      "Epoch:    33   -   cost: 0.24   -   Accuracy: 88.78%\n",
      "Epoch: {34}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "93.11643448089626\n",
      "Image: 2/2\n",
      "94.37518272707848\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "89.08216519041669\n",
      "Image: 2/2\n",
      "90.92150061840243\n",
      "Epoch:    34   -   cost: 0.17   -   Accuracy: 91.87%\n",
      "Epoch: {35}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "93.24831702765472\n",
      "Image: 2/2\n",
      "95.40052717465903\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "89.98175725398441\n",
      "Image: 2/2\n",
      "90.79089407040264\n",
      "Epoch:    35   -   cost: 0.16   -   Accuracy: 92.36%\n",
      "Epoch: {36}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "93.03475163866888\n",
      "Image: 2/2\n",
      "95.31522504989785\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "90.96032006400799\n",
      "Image: 2/2\n",
      "90.62583209832079\n",
      "Epoch:    36   -   cost: 0.16   -   Accuracy: 92.48%\n",
      "Epoch: {37}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "94.11384226443234\n",
      "Image: 2/2\n",
      "95.37029039040912\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "92.19828955590512\n",
      "Image: 2/2\n",
      "89.8978208637254\n",
      "Epoch:    37   -   cost: 0.15   -   Accuracy: 92.90%\n",
      "Epoch: {38}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "94.38496858688077\n",
      "Image: 2/2\n",
      "95.46585316671036\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "92.22634131727698\n",
      "Image: 2/2\n",
      "90.94223878915163\n",
      "Epoch:    38   -   cost: 0.14   -   Accuracy: 93.25%\n",
      "Epoch: {39}\n",
      "Batch: 1\n",
      "Image: 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.13515639373246\n",
      "Image: 2/2\n",
      "95.43985423580929\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "93.2206872359939\n",
      "Image: 2/2\n",
      "91.1570664343054\n",
      "Epoch:    39   -   cost: 0.13   -   Accuracy: 93.49%\n",
      "Epoch: {40}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "94.52118780908421\n",
      "Image: 2/2\n",
      "95.46539018103283\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "93.22596569846398\n",
      "Image: 2/2\n",
      "91.71683683732688\n",
      "Epoch:    40   -   cost: 0.13   -   Accuracy: 93.73%\n",
      "Epoch: {41}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "94.48542879369377\n",
      "Image: 2/2\n",
      "95.74621847348283\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "93.05229566624148\n",
      "Image: 2/2\n",
      "91.90948566965798\n",
      "Epoch:    41   -   cost: 0.13   -   Accuracy: 93.80%\n",
      "Epoch: {42}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "94.52766753711758\n",
      "Image: 2/2\n",
      "95.84322122418077\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "93.60291104117861\n",
      "Image: 2/2\n",
      "92.0063854588107\n",
      "Epoch:    42   -   cost: 0.12   -   Accuracy: 94.00%\n",
      "Epoch: {43}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "94.34074536614823\n",
      "Image: 2/2\n",
      "95.30250019483664\n",
      "Batch: 2\n",
      "Image: 1/2\n",
      "93.31307533703703\n",
      "Image: 2/2\n",
      "92.14940003486963\n",
      "Epoch:    43   -   cost: 0.13   -   Accuracy: 93.78%\n",
      "Epoch: {44}\n",
      "Batch: 1\n",
      "Image: 1/2\n",
      "94.90378827319842\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-acd2d99edc35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mparams_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m65\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.008\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-142-621134f16a57>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(X, Y, epochs, learning_rate, dropout, GN)\u001b[0m\n\u001b[0;32m    388\u001b[0m                     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb1_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb1_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv_Block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Backward\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdconv1_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv1_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv1_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb1_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb1_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdga1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbe1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv_Block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Backward\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdconv1_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv1_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv1_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormcache1_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormcache1_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-aead6b501acd>\u001b[0m in \u001b[0;36mConv_Block\u001b[1;34m(step, f, b, myin, dropout, GN, ga, be)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdconv_prev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconv_prev\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mdconv_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdgamma1_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbeta1_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroupnorm_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdconv_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormcache2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mdconv1_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf1_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb1_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvolutionBackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdconv_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_prev1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[1;31m#pack data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mdconv1_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconv_prev1\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-244185b13ab8>\u001b[0m in \u001b[0;36mconvolutionBackward\u001b[1;34m(dconv_prev, conv_in, filt, s, pad)\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[1;31m#each entry of the dconv_prev will try to affect the idxs from which was made of.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[0mdfilt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdconv_prev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mconv_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0m_h\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                 \u001b[0mdconv_in\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0m_h\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdconv_prev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mfilt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mdb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdconv_prev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#, axis =1) ## AXIS?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values,accuracy_history = train(train_images, train_labels, 65, 0.008, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Forward step . . .\n",
      "Cost: 0.04   -   Accuracy: 96.45%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "with open (path+'/weights', 'rb') as fp:\n",
    "    params = pickle.load(fp)  \n",
    "fp.close()\n",
    "Validate(train_images[0:1,:,:,:], train_labels[0:1,:,:,:], params, 1) #GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Forward step . . .\n",
      "Cost: 0.02   -   Accuracy: 98.36%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "with open (path+'/weights', 'rb') as fp:\n",
    "    params = pickle.load(fp)  \n",
    "fp.close()\n",
    "Validate(train_images[1:2,:,:,:], train_labels[1:2,:,:,:], params, 1) #GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Forward step . . .\n",
      "Cost: 0.03   -   Accuracy: 97.22%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAPVElEQVR4nO3df2xd5X3H8fengQrWDjVeSWQliLRSxIqqEYqVUjEVB8iUZaVBSIwGdYQpYCEIEFZI7E1CyqSBB9JUAhGSRRmWymBRUpYIUNvgYU2TKooZpA0NNIxlECWNSzZUtj+6Jv3uj3tyc69x8LXv+XHt5/OSrPOcc319vrL98fOcH36OIgIzm/s+UXUBZlYOh90sEQ67WSIcdrNEOOxmiXDYzRLRVtglrZL0lqS3JfXnVZSZ5U8zvc4uaR7wc2AlcAh4BVgbET/Lrzwzy8sZbbx3OfB2RLwDIOkZYA1w2rBL8h08NutccsklVZfQsoMHD/L+++9rstfaCfsi4L2G9UPAl9v4emYdaWxsrOoSWtbT03Pa19oJ+2R/PT7Sc0vqA/ra2I+Z5aCdsB8CzmtYXwwcnvhJETEEDIGH8WZVauds/CvAUkmfk/RJ4BvA7nzKMrO8zbhnj4jjkjYAPwDmAU9ExBu5VWZmuWpnGE9EvAC8kFMtZlagtsJuNhfN1TkefLusWSIcdrNEOOxmiXDYzRLhsJslwmE3S4QvvZkxdy+3NXLPbpYIh90sER7GW5JSGLZP5J7dLBEOu1kiHHazRDjsZolw2M0S4bCbJcKX3iwZKV5ua+Se3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCl95sTkv9clujKXt2SU9IGpe0r2Fbl6Q9kg5ky/nFlmlm7WplGP8ksGrCtn5gJCKWAiPZupl1sCmH8RHxL5KWTNi8BujN2sPAKLA5x7rMZuSZZ56puoSONdMTdAsj4ghAtlyQX0lmVoTCT9BJ6gP6it6PmX28mYb9qKTuiDgiqRsYP90nRsQQMAQgyadGLXd33nlnvX399ddXWElnm+kwfjewLmuvA3blU46ZFaWVS29PAz8CLpB0SNJ6YBBYKekAsDJbN7MO1srZ+LWneenKnGsxswKpzDuMfMxuRfBdcqf09PQwNjamyV7zvfFmiXDYzRLhsJslwmE3S4TDbpYIh90sEZ68wmad0dHRqkuYldyzmyXCYTdLhIfxNis89thj9fbll19eYSWzl3t2s0Q47GaJ8DDeOtbg4Kn/nL711lsrrGRucM9ulgiH3SwRDrtZInzMbh1j586dTevXXnttRZXMTe7ZzRLhsJslwsN4+4jGedgffvjhlt7TeJkMYGBgYNLPGxoaalq/5ZZbplmdzZR7drNEOOxmiXDYzRLheeONLVu2NK3fd999FVVi7Wpr3nhJ50l6SdJ+SW9Iuivb3iVpj6QD2XJ+3oWbWX5aGcYfB74VEV8ALgVul3Qh0A+MRMRSYCRbN7MO1cqz3o4AR7L2h5L2A4uANUBv9mnDwCiwuZAqLXebN5/6UXnYnoZpnaCTtAS4GHgZWJj9ITj5B2FB3sWZWX5avqlG0qeBncDGiPiVNOk5gMne1wf0zaw8M8tLSz27pDOpBf2piPhetvmopO7s9W5gfLL3RsRQRPRERE8eBZvZzEx56U21LnwY+K+I2Niw/SHgWEQMSuoHuiJi0xRfy5feOoQfczw3fdylt1aG8ZcBfwb8VNLr2ba/BAaB7ZLWA+8C1+VRrJkVo5Wz8f8KnO4A/cp8yzGzovi/3hLhYbv53nizRDjsZolw2M0S4bCbJcJhN0uEw26WCF96m8N8uc0auWc3S4TDbpYID+PnGA/d7XTcs5slwmE3S4TDbpYIH7PPQg899FC9fc8991RYic0m7tnNEuGwmyXCw/hZwJfTLA/u2c0S4bCbJcLD+A7lobvlzT27WSIcdrNEOOxmifAxewfxcboVacqeXdJZkn4saa+kNyRtybZ3Sdoj6UC2nF98uWY2U60M438NXBERFwHLgFWSLgX6gZGIWAqMZOtm1qGmDHvU/E+2emb2EcAaak93JVteU0iFZpaLVp/PPi97gus4sCciXgYWRsQRgGy5oLgyzaxdLYU9Ik5ExDJgMbBc0hdb3YGkPkljksZmWqSZtW9al94i4gNgFFgFHJXUDZAtx0/znqGI6ImInjZrNbM2THnpTdK5wG8i4gNJZwNXAX8L7AbWAYPZcleRhc4mL7zwQr194sSJpteOHz9eb19zjU9zWHlauc7eDQxLmkdtJLA9Ip6T9CNgu6T1wLvAdQXWaWZtmjLsEfET4OJJth8DriyiKDPLn++gm6Ft27bV27fddluFlZi1xvfGmyXCYTdLhIfxM+Shu8027tnNEuGwmyXCYTdLhI/Zp2H37t1Vl2A2Y+7ZzRLhsJslwsP4jzE0NNS0fvXVV1dUiVn73LObJcJhN0uEw26WCB+zT/D888/X26tXr66wErN8uWc3S4TDbpaI5IfxfuSSpcI9u1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WiJbDnj22+TVJz2XrXZL2SDqQLecXV6aZtWs6PftdwP6G9X5gJCKWAiPZupl1qJbuoJO0GPgT4G+Av8g2rwF6s/YwtUc5b863vOI1PnEV/M8vRXjxxRfr7Ynz+D3yyCMtfY0HH3yw3r733nvzKSwxrfbs3wY2Ab9t2LYwIo4AZMsFOddmZjmaMuySvgaMR8SrM9mBpD5JY5LGZvJ+M8tHK8P4y4CvS1oNnAWcI+m7wFFJ3RFxRFI3MD7ZmyNiCBgCkOT/OjGrSCvPZx8ABgAk9QL3RMQ3JT0ErAMGs+WuAusszOjoaNO6j9nzd9VVV9Xbx44da3pNUr29devW036NTZs21dtdXV1Nr61fv77dEpPQznX2QWClpAPAymzdzDrUtP6fPSJGqZ11JyKOAVfmX5KZFUFlTt4wG47ZH3/88Xrbw8P8NQ7bi/DSSy81rff29ha6v07T09PD2NjYpN9k3y5rlgiH3SwRyc9BN9HNN99cb5999tlNr91www1ll2PTtGLFiqZ1zzF4int2s0Q47GaJcNjNEuFLbwUbHh5uWr/xxhsrqqRc27Ztq7c3bNhQYSWnpPBoL196MzOH3SwVHsaXrKpLQTt27Gha37dvX729ZcuWptc2btxYby9atKjeXrZsWdPnnThxot7ev39/02t33333zIstwVy9JOdhvJk57GapcNjNEuFj9goV/b0v+j/MZrP777+/aX1gYKCiSvLlY3Yzc9jNUuFhfIX6+5ufq/HAAw+0/TUbh6ODg54prFVz5VKch/Fm5rCbpcLDeLMJZvOQ3sN4M3PYzVLhsJslwhNOmk3w9NNPN62vXbu2okry1erz2Q8CHwIngOMR0SOpC/hHYAlwEPjTiPjvYso0s3ZNZxi/IiKWRURPtt4PjETEUmAkWzezDtXOMH4N0Ju1h6k9A25zm/WYVW7i8wH27t1bb8/muxJb7dkD+KGkVyX1ZdsWRsQRgGy5oIgCzSwfrfbsl0XEYUkLgD2S3mx1B9kfh74pP9HMCtVSzx4Rh7PlOPAssBw4KqkbIFuOn+a9QxHR03Csb2YVmPJ2WUmfAj4RER9m7T3AX1N7NvuxiBiU1A90RcSmKb7W7L0P0YzOv5X2426XbWUYvxB4Npv15AzgHyLi+5JeAbZLWg+8C1yXV8Fmlr8pwx4R7wAXTbL9GLXe3cxmAd9BZzYNE+f1e/LJJ+vtdevWlVzN9PjeeLNEOOxmiXDYzRLhY3azNtx000319vnnn19v9/b2ll/MFNyzmyXCYTdLhIfxZjlZsWJFvX3HHXc0vbZ169ayy/kI9+xmiXDYzRLheePNSlBWzjxvvJk57GapcNjNEuFLb2YlaPxvuaomwHDPbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhS29mJZs4aWVZl+Lcs5slwmE3S4TDbpaIlsIu6TOSdkh6U9J+SV+R1CVpj6QD2XJ+0cWa2cy12rM/DHw/In6f2qOg9gP9wEhELAVGsnUz61BThl3SOcBXge8ARMT/RcQHwBpgOPu0YeCaooo0m8sk1T+K1ErP/nngl8DfS3pN0uPZo5sXRsQRgGy5oMA6zaxNrYT9DOBLwGMRcTHwv0xjyC6pT9KYpLEZ1mhmOWgl7IeAQxHxcra+g1r4j0rqBsiW45O9OSKGIqInInryKNjMZqaV57P/QtJ7ki6IiLeoPZP9Z9nHOmAwW+4qtFKzOarxsc9FavV22TuApyR9EngH+HNqo4LtktYD7wLXFVOimeWhpbBHxOvAZMPwK/Mtx8yK4nnjzTpIu3n0vPFm5rCbpcJhN0uEJ68w6yCPPvpovb1hw4Zcv7Z7drNEOOxmiSj70tsvgf8EPgu8X9qOT891NHMdzTqhjunWcH5EnDvZC6WGvb5TaawT7pV3Ha6j0+vIswYP480S4bCbJaKqsA9VtN+JXEcz19GsE+rIrYZKjtnNrHwexpslotSwS1ol6S1Jb0sqbTZaSU9IGpe0r2Fb6VNhSzpP0kvZdNxvSLqriloknSXpx5L2ZnVsqaKOhnrmZfMbPldVHZIOSvqppNdPTqFWUR2FTdteWtglzQO2AX8MXAislXRhSbt/Elg1YVsVU2EfB74VEV8ALgVuz74HZdfya+CKiLgIWAasknRpBXWcdBe16clPqqqOFRGxrOFSVxV1FDdte0SU8gF8BfhBw/oAMFDi/pcA+xrW3wK6s3Y38FZZtTTUsAtYWWUtwO8A/wZ8uYo6gMXZL/AVwHNV/WyAg8BnJ2wrtQ7gHOA/yM6l5V1HmcP4RcB7DeuHsm1VqXQqbElLgIuBl6uoJRs6v05totA9UZtQtIrvybeBTcBvG7ZVUUcAP5T0qqS+iuoodNr2MsM+2ewZSV4KkPRpYCewMSJ+VUUNEXEiIpZR61mXS/pi2TVI+howHhGvlr3vSVwWEV+idph5u6SvVlBDW9O2T6XMsB8CzmtYXwwcLnH/E7U0FXbeJJ1JLehPRcT3qqwFIGpP9xmldk6j7DouA74u6SDwDHCFpO9WUAcRcThbjgPPAssrqKOtadunUmbYXwGWSvpcNkvtN4DdJe5/ot3UpsCGkqbCVu35Pt8B9kfE31VVi6RzJX0ma58NXAW8WXYdETEQEYsjYgm134d/johvll2HpE9J+t2TbeCPgH1l1xERvwDek3RBtunktO351FH0iY8JJxpWAz8H/h34qxL3+zRwBPgNtb+e64Hfo3Zi6EC27Cqhjj+kdujyE+D17GN12bUAfwC8ltWxD7gv217696Shpl5OnaAr+/vxeWBv9vHGyd/Nin5HlgFj2c/mn4D5edXhO+jMEuE76MwS4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZon4f1LAYaMceBm8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "with open (path+'/weights', 'rb') as fp:\n",
    "    params = pickle.load(fp)  \n",
    "fp.close()\n",
    "Validate(train_images[2:3,:,:,:], train_labels[2:3,:,:,:], params, 1) #GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validate(test_images[1:2,:,:,:], test_labels[1:2,:,:,:], params_values);\n",
    "Validate(test_images[0:1,:,:,:], test_labels[0:1,:,:,:], params, 1) #GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Forward step . . .\n",
      "Cost: 0.29   -   Accuracy: 75.01%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Validate(test_images[1:2,:,:,:], test_labels[1:2,:,:,:], params, 1) #GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(accuracy_history[:45], label=\"Dice Coefficient\")\n",
    "#plt.plot(accuracy_history2, label=\"Pixel-Wise CE\")\n",
    "#plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "#plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Conversion . .  .\n",
      "Starting . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "############### From Python To C weight encryption ####################\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "## read and extrada data from file\n",
    "print(\"Initializing Conversion . .  .\")\n",
    "path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "with open (path+'/weights', 'rb') as fp:\n",
    "    params = pickle.load(fp)  \n",
    "fp.close()\n",
    "### Unpacking ###\n",
    "[filters, bias, f_dc, out_fb, GN_params] = params\n",
    "[ga, be] = GN_params\n",
    "\n",
    "[f1,f2,f3,f4,f5,f6,f7,f8,f9] = filters\n",
    "[b1,b2,b3,b4,b5,b6,b7,b8,b9]= bias \n",
    "[fb6_dc, fb7_dc, fb8_dc, fb9_dc] = f_dc\n",
    "[out_f, out_b] = out_fb\n",
    "\n",
    "#List --> Numpy\n",
    "filters = np.array(filters)\n",
    "bias = np.array(bias)\n",
    "f_dc = np.array(f_dc)\n",
    "out_f = np.array(out_f)\n",
    "out_b = np.array(out_b)\n",
    "ga=np.array(ga)\n",
    "be = np.array(be)\n",
    "\n",
    "print(\"Starting . . .\")\n",
    "#################\n",
    "#Validate(train_images[2:3,:,:,:], train_labels[2:3,:,:,:], params, 1)\n",
    "\n",
    "## Now encode the info to a different binary file\n",
    "path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "\n",
    "from array import array\n",
    "output_file = open(path+'/weights_encrypted.bin', 'wb')\n",
    "\n",
    "for i in range(9):# 9*2 filters\n",
    "    float_array = array('f', filters[i][0].flatten())# f#_1\n",
    "    float_array.tofile(output_file)\n",
    "    float_array = array('f', filters[i][1].flatten())# f#_2\n",
    "    float_array.tofile(output_file)\n",
    "float_array = array('f', out_f.flatten())#out_f\n",
    "float_array.tofile(output_file)\n",
    "## save bias\n",
    "for i in range(9):# 9*2 bias\n",
    "    float_array = array('f', bias[i][0].flatten()) #b#_1\n",
    "    float_array.tofile(output_file)\n",
    "    float_array = array('f', bias[i][1].flatten()) #b#_2\n",
    "    float_array.tofile(output_file)\n",
    "float_array = array('f', out_b.flatten()) #out_b \n",
    "float_array.tofile(output_file)\n",
    "#save fb_dc\n",
    "for i in range(4):\n",
    "    float_array = array('f', f_dc[i][0].flatten())# 4 dc filters\n",
    "    float_array.tofile(output_file)\n",
    "for i in range(4):\n",
    "    float_array = array('f', f_dc[i][1].flatten())# 4 dc bias\n",
    "    float_array.tofile(output_file)\n",
    "\n",
    "for i in range(9): #9*2 gamma\n",
    "    float_array = array('f', ga[i][0].flatten()) #ga#_1  ,shape: b.shape[0]//2\n",
    "    float_array.tofile(output_file)   \n",
    "    float_array = array('f', ga[i][1].flatten()) #ga#_1\n",
    "    float_array.tofile(output_file) \n",
    "for i in range(9): #9*2 beta\n",
    "    float_array = array('f', be[i][0].flatten()) #be#_1  ,shape: b.shape[0]//2\n",
    "    float_array.tofile(output_file)   \n",
    "    float_array = array('f', be[i][1].flatten()) #be#_1\n",
    "    float_array.tofile(output_file)     \n",
    "#close file\n",
    "print(\"Done!\")\n",
    "output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "################ Resizing Tool(Its used before convertion to .pgm) ###############\n",
    "def resize(path=None):\n",
    "\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\salt\n",
    "        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt2')\n",
    "    ####### TARGET DIMENSIONS ########\n",
    "    target_dim=64                  \n",
    "    ##################################\n",
    "    def resize_images(path, target_dim):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/images/\"\n",
    "        dest_folder =path + \"/images_resized/\"\n",
    "        for f in os.listdir(folder):\n",
    "            cv2.imwrite(dest_folder+f, cv2.resize(cv2.imread(folder+f, cv2.IMREAD_GRAYSCALE),(target_dim, target_dim)))\n",
    "\n",
    "    def resize_labels(path, target_dim):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        folder = path + \"/labels/\"\n",
    "        dest_folder =path + \"/labels_resized/\"\n",
    "        for f in os.listdir(folder):\n",
    "            cv2.imwrite(dest_folder+f, cv2.resize(cv2.imread(folder+f, cv2.IMREAD_GRAYSCALE),(target_dim, target_dim)))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    resize_images(path,target_dim)\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    resize_labels(path,target_dim)\n",
    "    #print(\"Test Images  : Loading . . .\")\n",
    "    #test_images = _t_images(path,dim)\n",
    "    #print(\"Test Labels  : Loading . . .\")\n",
    "    #test_labels = _t_labels(path,dim)\n",
    "    print(\"Done!\")\n",
    "    return # , test_images, test_labels\n",
    "resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from .h5 file completed!\n",
      "Now encrypting to binary files  for Python and C support. . .\n",
      "Calculating Forward step . . .\n",
      "Cost: 0.40   -   Accuracy: 66.97%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2debhdRZn1V0kSwQEQhQQIBGgmg8oUGQSZJ2nU1rYRBJsWmoDMgggIKHxAA9ICzSAaBkEaGZVBUAFjQAYFEghjmAVJSJgHkdmu7497duVXi3tOAknOTfd51/Pw5L239lC79i5uVa1a6005ZwUCgf/7eN9AVyAQCHQH0dkDgR5BdPZAoEcQnT0Q6BFEZw8EegTR2QOBHsEsdfaU0hYppQdSSg+nlA6cXZUKBAKzH+m98uwppXkkPShpU0mTJd0maduc832zr3qBQGB2YdAsnLuGpIdzzo9KUkrpAklflNS2s88333x5/vnnlyS9/fbbVdngwYNL/NZbb9WVHDSo37J55523Ou7NN9/s93pexut1qscbb7xRlb3vfdMHQjyv070+8IEPVGX/8z//U+L3v//9Vdmrr75a4nnmmafE3h48js/idUkplXi++earjuOzeRnrzzq+/vrr1XF8FtZXkv7+97/3ey+e42i+jQZsY77r1157rTquU1uxHmybTu/M30und8268PvwP6Iz+82xvg5e0997c94rr7yi119/PakfzEpnX1zSE/h5sqQ1O50w//zza5tttpEkPffcc1XZ0KFDSzx16tSqbJFFFinxU089VeJll122Ou4vf/lLiRdbbLG2Zbye14Nljz32WFXGjvvss8+WeNFFF217r5VXXrkq44f/D//wD1XZ+PHjS7zAAguUeNq0adVxEydOLPHHPvaxtvUfMmRIiVdaaaXqOD7bJz7xiarsiSemv9ZlllmmxPfee291HJ/lQx/6UFX28ssvl/iRRx4pMf9HJdUddbPNNqvK+NwrrrhiiSdNmlQdx/9JTJkypSp76aWXSjx8+PASs52k+pmXXnrpqozfiL/ru+++u8T8PrxDf/SjHy0xvx2p/lZZX/7PWqr/h+T1f+GFFyRJv/rVr9QOc3yBLqU0OqU0PqU03v+PHAgEuodZ+cs+RdIS+Hl463cVcs5jJI2RpBEjRuTm/9D3339/ddzGG29c4jvvvLMq22ijjUp89dVXl3jbbbetjjvnnHNK/PWvf70qO/fcc0u8ww47lPjHP/5xddw3v/nNEv/gBz+oykaPHl3iU045pcR77rlnddzFF19c4n/913+tysaOHVviLbbYoir729/+VuLPf/7zJd5ll12q4y655JISH3/88VXZfvvtV+Kzzz67xFtvvXV13GWXXVbiLbfcsiq76qqrSrzhhhuW2IfIo0aNKvFvf/vbquwrX/lKiX/5y1+W+B//8R+r4/g+/+mf/qkqu/7660v8xS9+scQ+ZfjqV79aYr4XSdpnn31K/MMf/rDE3/3ud6vjzjrrrBJvv/32VdnPfvazEm+33XZV2WmnnVZifldHH310ddyBB05fv/7JT35Slf3Lv/xLiWe2rXy01/xl9xEFMSt/2W+TtFxKaemU0hBJ20i6YhauFwgE5iDe81/2nPPbKaU9JF0taR5JZ+Wc753BaYFAYIAwK8N45Zx/LenXs6kugUBgDuI98+zvBYsvvnhu5p933XVXVcbVyhdffLEq46rvEktMXybw1UqucjZzmAZc8eTc0xcNSS/5yitpI66MMpbqlXTSMVI9p/rrX/9alX3kIx8pMemwW2+9tTqOq8XOJnBlmivMzk7w+r6SzhVtPtvCCy9cHUf65/nnn6/KuPLN9/nhD3+4Oo7t7RQgaSjO050ae/jhh9vWkesgvBfZAqlmg/wabIPHH3+8KltyySVLzPf+6KOPVsfx23HabKGFFiox17JWWGGF6ji+T2dybrzxRknSgw8+qFdffbVf6i22ywYCPYLo7IFAj2CW5uzvFu973/vKMJNDVqkefvowipstOPz/zGc+Ux3305/+tMRHHXVUVUa6avPNNy8xKRdJ2nvvvUvsFAnppFNPPbXEhxxySHUcr+l00kUXXVTi/fffvyr7wx/+UOJNN920xGPGjKmOIwW47777VmW85hFHHFHivfbaqzru17+evtSy9tprV2V//OMfS0z6x+vB93LhhRdWZXzuk08+ucSkFCXpzDPPLPHOO+9clV1xxXRyh/Tg7bffXh130kknlfjyyy+vynjeMcccU+Jjjz22Oo7v7J//+Z+rMlKY559/flVGOmydddbp9xxJ+vd///e212CbcFPMl770peq4m2++ucTcMCVNn45OnjxZ7RB/2QOBHkF09kCgRxCdPRDoEXSVeltkkUVys7XRqQ9SVD7voNiD83mnrkhruUKLawJe1u4anRRrnY4jtffBD36wKuM2R1IuUk1LdXovvOaECROqspEjR5aY7egKQQphSDtJNZ1HWs4pRlKTTmHyfqTlnE4iRdWpbPnlly+x06q8F+kvqf7OGDu963Nggt+mKyFJGVO95t8mz3PKmPRgpzqR9vP1qmYN5tFHH9Vrr70W1Fsg0MuIzh4I9Ai6Sr0NGTKk7Kx65plnqjIOTX14SxqH1NsGG2xQHUdKw5VLLCPFc/rpp1fH/du//VuJSdVItVKKdNJuu+1WHXfiiSe2LWM9nJYjbUQK0BVlX/jCF0p88MEHV2VUvX3/+98vMZ9Lqqmhb3zjG1XZb37zmxKTAqT6S5J23HHHEp9xxhlty370ox+VeL311quO47SGlKhUU6lUtpFGlaSddtqpxFSNSdIee+zRbz0OPfTQ6rhvf/vbJT7yyCOrMh7rZaT9eA1SrJKKj4MkjRs3ripbd911S9yObpSkSy+9tMSrrLJKVdZMbZ5++mm1Q/xlDwR6BNHZA4EeQVdX44cOHZob8T839Uv1MN53SFFUQZskF/BTSOFlvuLcwFdGucrubeNCjQbuS8bzOvnpOSPBlW/ey3cbcmX3ySefrMo4BaKFl7cH60Uxh1TbY3HVl4ITSfrkJz9ZYl9R5sp6I9KQ3jmM57TM7aAeeOCBEpOF8TblyveCCy5YlS233HIl5uo+vyOptpdy0RDbw981RTlkjVzswvZ3IQ9B5sKFWGRQOPSXpk9tJk+erDfeeCNW4wOBXkZ09kCgRxCdPRDoEXSdelt88cUlvXM3FudCrsKiyd999023paf6S6qpCVc1kQr58pe/XGKaVEo1jeNUE80jSePsvvvu1XGktVxB9d///d8lphmiVCuoqHj605/+VB1Hg0K3d+a8lzTR9773veq4ww8/vMROeXGHGuv4n//5n9VxpOycpmT9Odf3e912220lpjJMqulN3svpNdaRaj6pbn8aQ3AuL0n33HNPibkLUZLOO++8Ertqj9QtTU7d+JKGp3zPkrT++uuX+Pe//32JP/vZz1bHXXPNNSV2++/GrttNRIj4yx4I9AiiswcCPYKuUm/Dhg3LzVDYd/pQbMChjFQP65kJwwUtpLLcV40iFgoMnDLqlIqH9CD97lx8QWrIPehYDy8jDcg6uiCCVJNTSBSkPPTQQyV2Koj0ndOSPI8ZbXzKwJ18HHJL9W5D7hqkt7pUm16MGDGiKqOQh9+pU6A8zmmzW265pcT06fdn4VCalJ9f073l6InItndvwKWWWqrEnLpI9dSL/cLb44477ijxJptsUpU1bRzUWyAQiM4eCPQKorMHAj2CrlJvgwYNKts53QSA2xxdKUa6htSbC/ivvPLKErtZ3y9+8YsSk0IjJSLV6iqn3kj/cB7qOedI1VDtJNVKLlJoknTBBReUmOaWVKFJ9bzXc+aRkiFl5z7jzHHn82i2FevB55Jqw0nPzkq1HOfAzNsn1fNXN+AkXUrjS28PzrfZhpJ00EEHlfi6664rMdVwUk2HudEo67jWWmtVZVSp8ZldTfm1r32txL4mRfXjDTfcUOJPfepT1XEsc3qwod7c2IOY4V/2lNJZKaWnU0r34HcLpZSuTSk91Pr3I52uEQgEBh4zM4w/W9IW9rsDJY3NOS8naWzr50AgMBdjpqi3lNJSkq7MOX+i9fMDkjbIOU9NKS0q6bqc8wodLiFJWnTRRXNjatAMOxqQKqN/uiQtu+yyJebOp6lTp1bHUU3kijJPO9TfOZL00ksvldgpL1JjPM9VWITTd6SNOtE4pNecRiTt5zupqIIjZUQ6TaoVWj6l4nOSFvI2pRrxwQcfrMo49eK0gEo5qU7P7emGSVOyTq5UZPvz/Um1Px1TSPl74b2btOL9HevDZLYjd685rUoFolPGpG5JvQ0bNqw6jnSeD+OvvfZaSX3vf3ZTb0Nzzk1Pmyapf/1oIBCYazDLq/G5b2jQdniQUhqdUhqfUhrviziBQKB7eK+r8U+llBbFML6t8VXOeYykMZK0xBJL5GbY4x2fw2JfSafAgCYDLhTgajE90KTax40ru77CzFXTyy67rCrjqikFNKyfVKfwceEEz/O0USzjKrizAvSdc5EMPeg4tOZUSKrZhC9+8YtVGVewySa4rxqFK1dddVVVttVWW5WYO8F82kE2xNmJn//85/1e74c//GF13Le+9a0SM+WVJB1wwAElpjCI/nxSnYbKBTn8Ro4++uiqjKmyyAq4IGfNNdcssQth+B2zzD0KyUIw1ZQ0ffg/S6vxbXCFpIav2UHS5R2ODQQCcwFmhno7X9IfJa2QUpqcUtpJ0jGSNk0pPSRpk9bPgUBgLsYMh/E5523bFG08m+sSCATmILqqeiP1NmXKlKqMc3budJKk1VZbrcSke3x+wnUAT3fEn2mc4WmLCKaMkmqKirGbEJJ28dRQpGdccUeqhTSXU02sv9Nh3InYSX1HFZwbibBNOA/1tFz0Lmc6YalWefG9OL3GdQVSY/4zvw+nRElleRnfIXMVeFpw1tFVgEy7RKpNqmk53tvfC9vbaT8+56RJk0rsux5pXuHz+d/97nelrq+//nqo3gKBXkZ09kCgRzBgQhin3rjDbdddd63KmAaHO8FGjRpVHUfagkYFUk290ZeMKZekmpbjzi+ppsNIXTllRC88+t1JtXCCQhKpppo4THNxB8UkpPm8/tyh97nPfa46jjTa1ltvXZWdddZZJea74DP7ecxmKtWUI3MEuLkEhTxu1nD99deXmFST14Mehe4pSGETvQEphpLqd+a+gRdffHHb87jbc+ONpy9j0Stfqg1YJk6cWJVxysNndqEX28Cpt2Z3nadVI+IveyDQI4jOHgj0CKKzBwI9gq5Tb03qYOatkmrKiPMWqd5iyXmd5x7jNZzaI2XH9QKn16hO8hxr7XKKudKKdBuVW17mtB/pMc69OKeT6jmw00SkBNtRV1JN/7iBI5+nE73GtnODRa6tcG3CKSmaePr7pOKOBpHeHqQwO5WRIu2UZ8/fC/uIv+t2+f+cLmWuN6f9SH3y23Rq+ZVXXimx03KNGeW0adPCcDIQ6HVEZw8EegRdpd4GDx5c0tC6YQKHUe6JRlUWh7BUeEk1fULKRar9u0hdkVaRatql2ZXUgB5jpHjcZ46UndNyVFB5HakAo/ruuOOOq46jsuukk06qyujfx1RTrgZjHd1Dj3QSKR7fncb2IKUoSSeeeGKJaajhaZk5ZPYpCc1JOGU47bTTquN22WWXEjuVSlqOaaN8BxrrTz98qX5n/j6p9uukpmymr9I7Pei4S5HX8zRofJ9OpTaeejQ2ccRf9kCgRxCdPRDoEcw1QhiuyvrwedVVVy0xV1s5pJfqFVAXmTTZY6V6ldPFF1wZ9V1hXA1t548m1VMSFz3wGj4s5mo8r+lTHl7DV3ZZL4pOnFkgml2NDbji3M7TTqqHo0suuWRVRstvpuzyelD84+9shRWm2xredNNNbe9FIQzv5eB797bnSj3bV6rfofsN8l3zPO9XZG/ce5DPw2v4e6Egx738miH+M888ozfffDNW4wOBXkZ09kCgRxCdPRDoEXR1zr7EEkvkfffdV1K9o0iqd3j5XIU0A8+jh7xUmy+6Yoi78ng9GgJINZ3kZVTSkapxGuSSSy4psSvKOtE/pA470VpUV7nKi+aXNKrca6+9quN4TdJ8Ut1WVBY6rUVaztV3H//4x0tMNZ+nXeL8lapCqd6FxzUXNzdZb731Stz4pzegYvL222/vt+5e5mpKriFtsMEGbctoHOnmnDRRHTduXNs6su35XFL9ffic/bDDDpPUt7bx0ksvxZw9EOhlRGcPBHoEAyaEcfqB5hX04pbq4TrpGKYOkmraxdMRMSMmKRinajhN8LRLpMBIy7lhQKfUUO080aSaluK9nNrjrjOvI+9HusfB4zrRSaR7XHxx1113ldi99kj7kU5qdlA2oPjFh6akIilCoqhJqof77o/P98l3zcyyfh5TMEn1e3HKmCm7KAbydGOshwtc2CZ/+ctfSux+d2wD+jJK0z3lp0yZEkKYQKDXEZ09EOgRRGcPBHoEXZ2zL7nkknn//feXVM8FpXrbqs/rSHdwS2UnX22nw7jdkqo3N3Okqsm37ZJ6I4Xm+dyYk4tKKKlWtlGRJbXPEXf66adXx1Fl56o3Uls0jvT8ZRdeeGGJv/GNb1RlpA6ZY43P5WVHHXVU2zoee+yxJXZFI3OxuZEkaSi2laf0JlXmdaSKkXSY5+cbP358idddd92qrJ2yTaq/EX4f/l2xzGnKTTbZpMRse6dEeR6VctL03HW/+93v9Pzzz7+3OXtKaYmU0riU0n0ppXtTSnu3fr9QSunalNJDrX/bb74OBAIDjpkZxr8tab+c80hJa0naPaU0UtKBksbmnJeTNLb1cyAQmEvxrofxKaXLJZ3S+m8DpG2+Lue8Qqdzhw0blhvfbVesMT0Oh1RSrXT79Kc/XWKn1zopl3gN0iCeJoqU0QILLFCVMXVTO4WaVFNeVGRJNW3m55Gy4/Vp4iDVOwz9GqTAqNbyFFWEX4OqN7YHlYl+TfcUpBEFqb1O6bBcEce24tTODRo4tXNajp6CBL83qX5nnuaKz+2egqTHSI25mpJwFSO/QU5vXdF46623lphTKGm6WcZzzz2nt956a9apt5TSUpJWlXSLpKE55+YrnCZpaJvTAoHAXICZ7uwppQ9J+oWkfXLOlTVn7hse9DtESCmNTimNTymN75REMRAIzFnMVGdPKQ1WX0c/L+fcLEM/1Rq+q/Xv0/2dm3Mek3MelXMe1c52NxAIzHnM0HAy9U3ozpQ0Ked8PIqukLSDpGNa/17ez+n1zQYNKnMcn/vw58bNpgEVSnSS8ePuueeeEtPdRqqVUqRPnF4jpeEKKp43duzYErsSiud5zrlONA6VaDTZdBqH6jCn5UhttTOwlGrq0E0UmadszTXX7Pf3Uu0H7/Ug5XX88dM/m9GjR1fHUbXnefGo2iM9SPWXVNNynnOA9We+PzeVpCHpwQcfXJVx+7a/a96PZU4P8rtiPaSaJqb7j2+J5TtzM8q7775bUq38dMyMu+w6kr4u6e6UUpOR7rvq6+QXpZR2kvS4pK3bnB8IBOYCzLCz55xvlNTv6p6kjdv8PhAIzGXo6g66YcOG5e23315Sre6RatqpGZI04E65kSNHlrhJedOABge+Q4+qJlJvvluPlCCvJ9VqKJ5HU0apc2ooGiw6XUVKjbSZ00RMEeR0GM+j8orTH6mm1Jwe5DX5bK6i65TKit8VVXSeqpv0krcV6Su2gRtTkrpyI0m+T7Yvn1+q28rryPbw75YmnKyXm5WSAuy0dsV7u+qN6a3dnOXMM8+U1EdLhuFkINDjiM4eCPQIujqMHz58eN5zzz0lvdO8gkMb9ydfffXVS8xVexpZSLXYxcUMNLpgGdMgSfXKqK/s0iuMQhL3kuMKP8+R6nRTvgpOoQNX4+nhJtXpmtyDrpkmeZmnmrryyitL7N5v7VJUuRcez2uGkQ24Gv+Tn/ykxM37b3DGGWeU2IVBP/rRj0q86667lviEE06ojmt8DaV3MhcUAFEI4zvQ2B7eVvTeo5ecVLMy/HZ4Pan2FPRp6lprrVViMh7cLSrVTA77hDSdQbjuuuv0wgsvxDA+EOhlRGcPBHoE0dkDgR5BV+fsQ4cOzc28zFVvpEyYJ0yqaS7uKuqknKOaSqpNK2ka6FQNlUudqLdOKjKaSjqd1Km9SbWQgnEFH6kmrwd/fvHFF0vsz0mq01VYVKmxvr7rkapAzwNAKovnOVVIOMVIeow035///OfqONJcnerINvX3wPryG/BrOi1HE0saiLJ9pVrF6Io4PicViPyOpNok033vm/WNyPUWCASiswcCvYKZ2Rs/+242aFDZheXDKA5f3D98lVVWKTF3KTllxF1zK620UlU2YcKEEpOqoSGAVAtoKI6QavqEggUXR1x99dUldrELy1wk006o4ZQXaaPLLrusKiMNSJqPVJ6f53QSqSaKUzz9E6/pZZtvvnmJSR025iUNKO7w99mkIZZqStHpNb4XF+TsvvvuJWbbs35STc162iUKYfy7uuWWW0rMofW9995bHcdv2vMdkHqbOHFiiblbVKq/x+WXX74qa+g8T1lGxF/2QKBHEJ09EOgRRGcPBHoEXafeGj9xz6dF2oUmFK3zSsxUwD4vIr02adKkqozz/kceeaTENKL0siWXXLIqa6d682ch3fPyy5WDV0UTed4wlpHi8RTWpLm8jGsarIebNJICc8Ua1W1UvXleOVJIruQiDcXzOplsujKP16Saz+m1TiaePI/t4dQslZVuOLn00kuX2Nd4SAVzCzjVjVKtlvPt4KT6SMO5co7fNNNDS9JPf/pTSX3fRuR6CwR6HNHZA4EeQVeH8YsvvnjebbfdJL3TC507jFy0/4lPfKLETIvru4jGjRtXYle9MTXwGmusUWJ600k17eJDNlJspLWcuiLF415nTO/j59G7jmo50lNSTVH9+te/rsqovKLKy/3deJ7XkVQZKS9Pz7T11tOdyJhqSqo940ihubKNyrwmnXd/51G9xraXan+3U089tSrbeeedS3zooYeW+Mgjj6yOo+KQqaukmnpzb0PuauM00neBMmW4T99Io/E7HTFiRHUcaTnf3dk8zyylfwoEAv83EJ09EOgRdHUYv8gii+TGGIAiDakWY7h/HNMCcdXURSaEe4xx2MN7uyiBq+C+GsrzuOrbSVThIhbWi1MXqV4F5yq+rz7z3p6iqt3Krq9Ss46+Gs93QWENz5Hq5/bVba6kt/OSk+p36KmhWGfWwz3z+M68jAIgrva7UIU/ex35LM5qkM3p5NfH78DTOpFB4bvwdFj8/ty45eSTT5bUtxofQphAoMcRnT0Q6BFEZw8EegRdVb0NHjy4zFfcTIHzvxVXXLEqo2KIhhVM7SNJN998c4lduUQTSKZCciME3stT6bRL77PxxnWuDKrXXG1G00DSZFJNh1HZRipPqtVyrnLiNXk9V3nxPDfF5HlU7bmJIp/NaTmaNpLKczNHqu+8HqwjqUM3AuW7Pvvss6sy0ooHHHBAib/97W9Xx9Hcco899qjKSMFuuOGGVRm/R+6qJIUmScsss0yJPc8AlXTcvecUNMt8Pn/XXXdJeicVS8zwL3tKad6U0q0ppTtTSvemlA5v/X7plNItKaWHU0oXppSGzOhagUBg4DAzw/g3JG2Uc15Z0iqStkgprSXpWEkn5JyXlfSCpJ3mXDUDgcCs4l1RbymlD0i6UdI3JV0laVjO+e2U0tqSDss5b97p/IUXXjg3u8ackiItwl1JUk2bDR8+vMQUW0g1RdLJHMPqVP3MerlfGmkiDqO4q8/Pc1qLdfT6k+ojzUKfM6lOJeRDvRdeeKHf83zXFsvcc420EQUc3lakuZympFiHXmpOjZFuY92lmm5rR8NJNXXlYhrSaJyyub8b6U0fIpM67JQ2itfw743flYuv+F1RNORUJN+Fe8qfdtppkvqmCLMkhEkpzdPK4Pq0pGslPSLpxZxz8+STJS3e7vxAIDDwmKnOnnP+e855FUnDJa0hacUZnFKQUhqdUhqfUhrv/1cPBALdw7ui3nLOL0oaJ2ltSQumlJox0nBJU9qcMybnPCrnPIoWyIFAoLuYIfWWUlpY0ls55xdTSvNJ2lR9i3PjJH1F0gWSdpB0efurtG42aFCZ23WaW2222WZVGX/+zW9+U2JXSe2///4lPvbYY6symhTuuOOOJXbVGykvUnlSTbswx5dTRixzw0kq2Py8dpQd88pJ0mGHHdbvOVJNNVEd9v3vf786rlM+uksvvbTExxxzTImdAiTN53VkHjsq/Vx9R2Ub88NJtRKNlJ3fi1QqqU2pfmejR48usaveqJL0vHX8rrwdSc+SgnUKjPd2w0m2I7fj+pZbmqT4Ok6zHuG5C4mZ4dkXlXROSmke9Y0ELso5X5lSuk/SBSmlIyXdIenMThcJBAIDixl29pzzXZJW7ef3j6pv/h4IBP4XoKuqt4UXXjg3vuaeRodUhZtGkGYgNeG78LhryX2+aJZBHzv3iKP6yVVpBCk1+pxJnRVlpIm87UlfkYbyenRSvfH6Xi+incLO68XY7+XKRYIppEhl+b34bK42c2VaA29TrgU5XcU2IKXr/oI0PvFdcjSN4Lcj1b5wNK9wcxbuoHO1JuvP9+7fMD0XfXrYUG+hegsEAtHZA4FeQdfTPzU7vtyul0M2eptJ9co00y5tsskm1XEnnHBCiemBJtWroQcffHCJfTWbK8I33XRTVcZVU67Crr322tVxN954Y4k7pXhyAQ3TPHFVnQyE18NXn3ke7+X16JSiigIU3ossg1SzJF4PrvBzVf3zn/98dRyFMC7WISvAejgrQM84CpSkWrx03HHHldiZHA6t+a1I0t57713ir3/961UZ003Rr4/iH6l+156yiymx7r///hIzLZQkPfbYYyVeeeWVq7LGAt3TcBHxlz0Q6BFEZw8EegTR2QOBHkHXqbdG9ea0DZVFbk7A+Sbn9jRGlGqllaffIW1BD29X2NGj3tVgpIYYO5VCqsmNGEl5+Xmk7HhvV5RRY+AKMNJSndI/sczrwZRSpJC8Tan28zpSYbbsssv2ez2pppeo6pJq33R+L76zjM/m9aASjbSkp7LiGtLqq69elX/i9rIAABwgSURBVNET3+f6/FbpX89UzlJtEOlrHzRRvf3220vs6rgHH3ywxL720awT/fnPf9Zrr70W1Fsg0MuIzh4I9Ai6Sr0NGTKkmE/47jcOYT21zS677FJi0mGetmjPPfcs8UEHHdT2Gkwl5MMypguieEaSdt111xJTcEDRh1QP09xnjkIYF4WQkmGKpyZDZwNSPBSZSLUohPTPd7/73eo4ppryISHryDYm7SnV0yvSa1ItNOlE87GO/s5IvTU7LyXp3HPPrY6jnxwFPlLdHvTQcyqS9eU5Uu1P5yItvmtOAd0bkDRa4xfXwDOyNthpp9r8iVMDf2fN9I3GJo74yx4I9AiiswcCPYLo7IFAj6Cr1NuwYcPyDjvsIOmdJo2kWXyOynke5/pOBXFOQ5WRl33mM58psW+JparJ/b1J2ZFaaqfOkjrnafMyXofHOcXINvB78306dUjMrOqNqjE3t6SZglOAVL11ohv5nG7mOHTo0BJzLuq0GVVjbhLKtmOdllhiieo4UpZurMktqL6llymnuXZwxBFHVMdxGza3U0s11dlse+2vHtwKvOmmm1ZlDYU8bdq0WTOcDAQC//sRnT0Q6BF0Pf1T453lw0/SbaeeempVNmrUqBJzJxx/L9U7jpyWo9KNKiY3QiBFd+KJJ1ZlVDxRoUaaTOqcGor0lQ/FSDWRliMVJknNLkTpnSmZ+NwscwqwEx3GMho5uKKMNJR7+ZFOYplTXvRq8zLSm4ccckiJneaj+vGPf/xj23rccMMNJfa0XPyuSKFJ9Xfm5hX0guO7dnOW1VZbrcQ+LSOtyDRangaNO+2cAmw8Fz0XARF/2QOBHkF09kCgR9DV1fjFF188N7vQuKlfqldsOdySanHDKqusUmIfsnCV1v3MuHLM1WxfHeYqfqc0VBymeRvSJtvTAHGnoK8+c+Wb9Xe/fU49/DkpkmF7+Io7vdq8DbjqzvPc340pjZwZYbopvltP+0XREN+RVL93lrl/HIfuq65ae6PSl3DkyJEldqHKRhttVGJ/Z3xPZAikWujE1fPx48dXx5FtcsEPs79OmDCh33Ok+nvktECaPvWaPHmyXn/99ViNDwR6GdHZA4EeQXT2QKBH0FXq7f3vf3+hD3x+xnnYAQccUJXRTIA775wiIY3jdBhNAUiluBpsr732KvEpp5xSlVH1Rlpuv/32q45jeqJtt922KuPuQDfFvOiii0pM003u0pJqg0KmT5KkZoeiVJsh+r1I87lqj9dkPZzyIgXo6ju+w04qwHbKNqmm3vg+/Zm/853vlNgNF1nG6/E9S7XikOpJqd7V5tTb448/XmKu6dAcUqrn357+ietE/IZpeCHVxqNOyzX0ZrvU5NK7+MveStt8R0rpytbPS6eUbkkpPZxSujClNGRG1wgEAgOHdzOM31vSJPx8rKQTcs7LSnpB0k79nhUIBOYKzBT1llIaLukcSUdJ2lfS5yU9I2lYzvntlNLakg7LOW/e4TIaOnRoboa17s3GYf1DDz1UlTGtzjrrrFNiDq8kab755mOdqzLSIqSrmL5HqkUJnVJDsf6k06R6h1Qn8YifR5A2c9FQOy88qU6nxPp3Euuw3aSaHqM3oB9HkPKTapHP/PPPX2LfWUZxCu/l9+P1PQMw70UqT6oFS6QOnVblsNiH2fRod9qs3e49fqeSdPfdd5eYgiqp9gNk+if32uMuPx/GN1PH+++/X6+++uosUW8nSvqOpKZVPyrpxZxzQ0BOlrR4fycGAoG5AzPs7CmlrSQ9nXOeMKNj25w/OqU0PqU03vehBwKB7mFmVuPXkfSFlNKWkuaVNL+k/5K0YEppUOuv+3BJU/o7Oec8RtIYqW8YP1tqHQgE3jXe1XbZlNIGkr6dc94qpXSxpF/knC9IKf1Y0l055x91On/EiBG5UZ9xDiPVcy3O8aRaTfTEE0+U2Oc+NPLztLvcNsktlb5tkvOzs88+uyqj0SPpMKfXSA1tt912VRkNFv08qttINZEyktqrpKSaKmOZU5GsI59Lqmk0qu9Ik0m1IYPneqOSrpO5JdWDrr4jHcZ7ee47Gkq4QpBtRerQFYcXX3xxiV19x2uS9pTqrd2shxtOUmXna1Kcf3ONwQ02uJXWzUIapei1116r559/frZvlz1A0r4ppYfVN4c/cxauFQgE5jDe1aaanPN1kq5rxY9KWmP2VykQCMwJdD39UzOccX80Kot8aM1dSxxm33PPPdVxVF49+uijVRlVQrw3aQ+ppj6c1uJ5VKIx7ZRUK6O8fTvRV2wD0kuueqNKzevIa5Buc787pkLyNuAQkRSm02uk+VwRR4qNx7lxA6dvnhKMz836eoon3suHt6RI+X240o+KQ19IpkrSd8bx2ajCdFq1E6XG52SqLNZJqv31ll9++aqsSc89fvx4vfzyy6F6CwR6GdHZA4EeQVeFMPPNN18ZhnNlUaqHKEzPJNXiCa64u2CBq9ZHH310VcYhP33JuEov1eID36FHjzsKWnzFvVPWzzPOOKPETDUl1amLuFrsIhOuTPsKOVfPTz755BJ7KiGmNKLAR5JOOOGEEu+zzz4ldovvHXfcscQ/+9nPqjKuWlOc4qwARUOeDour4Ntss02JXQhDBsLbiuedeeb0NeTvfe971XFsK2+P0047rcRHHXVUVXbeeeeVeKuttioxn0uSttxyyxJT7OJ1pOmFMxdcqfepTMNS+dSWiL/sgUCPIDp7INAjiM4eCPQIukq9LbLIIvmrX/2qpJqKkKRnn322xL67jmYTNKzw+QmpJqctSPGQqqHvt9dj6aWXrsomT55cYtJEpF/8mm6wSCrLaTj+TOqNtJNUP5unO2p3nh9HtZnP/2gWyTJv007KPNJVjDuZbLJOUr2Tks/l12hXJ6mmC1kPVzR2emd8v/4uXKnX33393q6cYxvwm+Y8X6pVdcxhIE3PETBp0iT97W9/C+otEOhlRGcPBHoEXaXehgwZUvl0EYsttliJXaTw6U9/usT0/PKhDGkX+qNJ0kknnVTi//iP/yixGxXQjICiG6lOv0Pq8JOf/GR1HGkoF5lccMEFJSZlJEnjxo0rMYU8ntKIWWi9bP311y8xKapm+tSAdBJTXkm19x7pwXPPPbc6ju1PgY/fj2mo/L2QXvOUXTyPNJSnvOI7Y+oqqaZtmT113XXXrY7jeS6E6VT/djSrtxXr78ImimQooFlrrbWq4zid9To200r/Zon4yx4I9AiiswcCPYLo7IFAj6Dr1FvjUe4KJ9IpTr2RbqPHNrfOSjVN9NRTT1VlpHFI0Xm+OBpEOiVFWo75uXxbLVVvnbbcunc+zQpITdIEU6opwOHDh1dlVHmRbnMlF9+7q+qcAmsHKu7c4JNUGe/ltBnVYa5EozqMikNvDz6zK/hIsZF+9e+D79O/Tb7PJ598sipjXUjpOgXIMlf+kb4jLefXuO2220q89tprV2V33HGHJGnq1Kl64403gnoLBHoZ0dkDgR5B11M277bbbpJqBY9U7zByeo7eZPfdd1+JSTNJNb3m6Y5+8IMflHiPPfYo8be+9a3qOCq7mqFRg80226zEVMvR116S/vCHP5R4jTVqMx+mmzr88MOrMnreUfnnnmukatz3nimtSSd52iV6rlFFJ033M/N6UDUm1ao3Unl+XqdUU3xm9+Rrlw6LSjOppsP4XFKtSCTtyTaUap88T0NFBZtTmPTQYzuSkpPaq++kuq1Yx/XWW686ju3o1NsRRxwhKcwrAoGAorMHAj2Drg7jhw4dWoQwnv6JHmY33XRTVcahKT26fNWUq7ku2uBzUnDCHXlSLYjwFWzu8qPQwVdXuaruaYZ4rAthuJLM1WwX2nDK47bbFKRwldc96Nje/g1wpZp18pV0+r25sIR17PR7trE/J6/Psk5sgV+fbcB7dUqb5e3Bd+2sA6/D+nqaKzIj/r2QHeqUSOXBBx8sMb0YpenGJ1OmTInV+ECg1xGdPRDoEURnDwR6BF1VvQ0ePLjsVPJ5EeeoO+ywQ1VGFRx3nVEFJNVzfVc1HX/88f1ef8yYMdVxVC6RypOkvfbaq8RMn8v0VFI9T+cag1RTQ57u6KCDDioxDRGdeiOdRINCqVZKcYfh6quvXh3HtnKKp5160JVtpNGYDktqr4hzw0mmeHLKi2Uzqxrz9E88j0aPNIeUauqNFKtUqxGZ4kmSxo4dW2J+B7yeVLexK/NYF55HdaNUP3e7HXS+M5CYqc6eUnpM0l8l/V3S2znnUSmlhSRdKGkpSY9J2jrn/EK7awQCgYHFuxnGb5hzXiXn3Pw5PVDS2JzzcpLGtn4OBAJzKWaKemv9ZR+Vc34Wv3tA0gY556kppUUlXZdzXqHdNSRp2LBhufETdx8u0hYuhKE5BIUqLiShKMGpIFIkpP1c7EJqxSkelvF63oYUXPhOQaYgctqPNBrpHqfXSBM51USPNNKI3Hko1dMLT1/FNqFQqFOKJxfT0MeNdXTqivSjpwTjNUn7efoknkcaS6rbkd+He8nx+3PalnV04RQpNZ7n3wQFNN6O7Tz6/FnYphRUSdOnBpMnT55l6i1LuialNCGlNLr1u6E556mteJqkof2fGggE5gbM7ALdujnnKSmlRSRdm1K6n4U555xS6neI0Pqfw2jpnX+hAoFA9zBTf9lzzlNa/z4t6VL1pWp+qjV8V+vfp9ucOybnPCrnPKpTBtNAIDBnMcO/7CmlD0p6X875r614M0n/T9IVknaQdEzr38vbX6UPgwcPLnNWn59xLueKJNI/PG/kyJHVcddff32J3bSSZRtssEGJjzzyyOo4Um/MhyZJ++23X4mpojvkkEOq47itcc0116zKaHrovvTMA0fVHhVTUk0vOcVDaouU0aGHHlodx5TWNAeRaoqK6qomLXADUlSnn356VUZ68/zzzy+x58Ujvek51ngeFXH+XjrlnGMZ73XAAQdUx1Ftxjx1Um3cedhhh1VlpN7YHp7rjbQiVZFSrd6kueVGG21UHcf3QhNWaXoqaRqsOGZmGD9U0qWtzjhI0s9zzr9NKd0m6aKU0k6SHpe0dYdrBAKBAcYMO3vO+VFJK/fz++ckbfzOMwKBwNyIrqreFl100dwMq6ZOnVqVkU667rrrqjIOM0eMGFFiVxZRMeT0CZVoVMe57xkpO/rE+/2oLnPfM3qHudqMKixvA1JDpP08VRapMae8+DOfzdMR0bvOvcZJDXHaRJ82r5erGOktx7UaV7bxGv4spDdJQ/kUkNQVKTS/dzt/Pr+XX4PqSi9rRw96CinWw9WavAZpUDdxYWoo3/XY7MycNm2a3nzzzVC9BQK9jOjsgUCPIDp7INAj6LrqraHefC7L+c7Xvva1qoxGfpznLr/88tVxVKL5nObmm28uMfOoNQ4fDWgQ+eMf/7htPaiWGz16dHUcaRwv41zf609FXCd68MADp8sQqJSTpOOOO67EpBvdcJJGla6Io9EmlYW+lkKVF80hpTpvG6krN5XkM7vqjeo7Uor8vSR9+ctfLrEr83g/ljmdyWt6Dr5f/epXbetI6pMqRra9VCvYSNdJNU1MutSVbVdddVWJ6d4kTV938e+ZiL/sgUCPIDp7INAj6Cr1tthii+XGI9uNGEn3uCED1VtUwHlqJaqhXMRPs0jSWk7BkL4jTSb1mfk1oOqIxhtSrXAi5SfVaii/PikYPhvr7tdwioeUF6/nCj5STZ3SHVG150orKsCcNuN0hXSVm1ay/b2Mxoyk3lw1xvb36SGfkxSdtwep2k7KPKdq2xlVeuomUmpuKknNCN8FFZ5SnfbLh/HN7sYnn3wyDCcDgV5HdPZAoEfQ1dX4QYMGlaGJ73DjcMsFLptsskmJudHfV7O5asoVWkl66KGHSkyfNq5wSvUq+O9///uqjL52THfkHnRcjacQQ6rFJExDJU0XM0h1SqkTTjihOo5CIV+NP+qoo/qNuUovSbfffnuJXaxD77rVVlutxD5tWnHFFUtMvzipXpmmoMVFTmQ1XAjDduQKuaea2nvvvfu9l1SnazrllFNK7G1PNsG/HaYEc3blmmuuKTG/A9ZdqlkBiqGkeqWefoMu5qJIxoUwzRDfd1sS8Zc9EOgRRGcPBHoE0dkDgR5B16m3nXfeWVJNI0g15XDbbbdVZZ/61KdKzPm2U3SkZNxwknNg0idO93AtwVVenFOTMnLzTK45eF4vmky6aQTNKEkdOjVG1Vcno0eaKjrFSEWftxXbkfV1n34+t39HvCapQze37JT7jipAvidX2PE8p7x4nj8nQeWiU2Ok6ZyWowKR7d2pX/m7cPVmA1fY0XCEfUKavgMwcr0FAoHo7IFAr6Cr1Ns888xTPNW500uqqTdPe0Nvr/vvn25s66IE0lpOW5B6Y9nEiROr4zjcv/POO6sypsm94YYbSuwUIEUVFN1INX3itByHuKTDKPCR6h2FTh2SKqMvnNNa9EHzMrYVh4vcGSjV1JvviKS/HvMArLTSStVxl156aYk9tRLTJFFY4ymemIaKPm2StOWWW5b4iiuu6Pf3Ut0en/3sZ6uyTuIUioY4xaTQSKq/Ky/jO+P37R6Ft956a9uyZqejT/mI+MseCPQIorMHAj2C6OyBQI+gq9TbsGHD8vbbby+pVpBJtXrIFUk8tlPqW5ow0JxPqudazHvm9Bfnnh//+MerMs61SMtxe6nUPm2yJC2zzDIldiqIZVSNueqNZa6Momc9lWI+l+M6g/uYcysm1y08DfbDDz9cYt/izHk/lYq+RrLwwguX2PPicV7Kb4CqPC/j3NivSQUi20mq1yb8nfGaEyZMqMq4vsRnW2GFOu0hvznf6sptyFQWOm1L01CnGJt1hQceeECvvvpqUG+BQC8jOnsg0CPo6jB+xIgRuUm747uguFvK0xBzOM0dYr7TicMe36XEMg45fUcXKUE3peBuNe5i8+M4ZHafdE5RfIcUd1JR6edGHBy6exlVTxzCdkrL7DQoh9aM/VvhO/NpAs+jUtHTLXOHHlNdS/UOPaaY5hRBqr8P98DnkJ9txd2KUt1u/l74rr2t+M74zXlKaD6bl7Uz2PBvh9M3fxdnnnmmpD76+bnnnnvvw/iU0oIppUtSSvenlCallNZOKS2UUro2pfRQ69+PzPhKgUBgoDCzw/j/kvTbnPOK6ksFNUnSgZLG5pyXkzS29XMgEJhLMcNhfEppAUkTJS2TcXBK6QFJG+Scp7ZSNl+Xc16h3XWkvvRPTZZUruRK9bCKgpPWeSWmSMOH8fy5Uxoger/5ELzTMIrgNXz1ljvtXKzD1VYX0HA1nlMGN/rgzjXP2kk/Mw77fGWX7cGdWV5/7jpzi2+e56myOKznjj9/Fg6DyR54nVnmLAbZCi9rJy7y74NDaU/Lxfo//XSdmZzTIZb5cJ/1572kWlzD2IVYFHB5aqhzzjlHUt9uxVdeeeU9D+OXlvSMpJ+mlO5IKZ3RSt08NOfctMo09WV7DQQCcylmprMPkrSapNNyzqtK+ptsyN76i9/vECGlNDqlND6lNL6dlC8QCMx5zExnnyxpcs75ltbPl6iv8z/VGr6r9e/T/Z2ccx6Tcx6Vcx7lFsCBQKB7mJn87NNSSk+klFbIOT+gvpzs97X+20HSMa1/L5/Rteadd96ys8jnI5yDuDKK8zzOSd14gvNop/a444jrFE7RdTJ8IAXDeZfPEzlfoyLLr0nfdemddFADzhm9/j7PJTXJ9vAdY6y/7yIkXUXKyM0iucZAqlCqd7VxPu8+93wvvgbD9ROurbjfPr3i3cyDu844T/e0z3wvru6jsYVTjO3oR6cRuf7gu9/4/ZCa9PUYPpuvwTRqORpcOGZW4rqnpPNSSkMkPSrpG+obFVyUUtpJ0uOStu5wfiAQGGDMVGfPOU+UNKqfoo37+V0gEJgL0XUhzHbbbSdJuuWWW6qy9ddfv8R/+tOfqjIKIjh096ESh2I+XORwl0N1p9c41HP6hMNuDoO9DVkPH+JzCOe72ijU4HDM68hhpQ8JeW9Sb95WXD/xISEpKg53OYWSavqUdZLq9l9yySVL7NRbJ+837sJj2zttRrrKyzjk5wKx019sR/de57E+/OduRtbR3wufjXSdVH8jbB/35ON5vtjdZG+dVeotEAj8H0B09kCgRxCdPRDoEQxYrrdm22x/+NKXvlT9TEqD8zjOSSVp+PDhJfbUupzLcW5F6kSq55pO43COzbka6R2pnmv59krSVW7gwfk2t2y6eQXnqD5X5lyOZT7XpJmCq7BIvXEO6WsTI0aMKLGnpuZ5fGe+hsH5vK8dsD1Yf6coOR/2uTjfJ9dgvB5UI/p6D+fKTumyjvzm+C36eZ3WN/hsTgHyW/L5fNM+nai3+MseCPQIorMHAj2CrlJvKaVn1LcB52OSnp3B4XMac0MdpKiHI+pR493WY0TOeeH+Crra2ctNUxqfc+5vk05P1SHqEfXoZj1iGB8I9AiiswcCPYKB6uxjBui+xNxQBynq4Yh61Jht9RiQOXsgEOg+YhgfCPQIutrZU0pbpJQeSCk9nFLqmhttSumslNLTKaV78LuuW2GnlJZIKY1LKd2XUro3pbT3QNQlpTRvSunWlNKdrXoc3vr90imlW1rv58KWf8EcR0ppnpa/4ZUDVY+U0mMppbtTShNTSuNbvxuIb2SO2bZ3rbOnlOaRdKqkz0kaKWnblNLIzmfNNpwtaQv73UBYYb8tab+c80hJa0navdUG3a7LG5I2yjmvLGkVSVuklNaSdKykE3LOy0p6QdJOc7geDfZWnz15g4Gqx4Y551VAdQ3ENzLnbNtzzl35T9Lakq7GzwdJOqiL919K0j34+QFJi7biRSU90K26oA6XS9p0IOsi6QOSbpe0pvo2bwzq733NwfsPb33AG0m6UlIaoHo8Julj9ruuvhdJC0j6s1prabO7Ht0cxi8uibl5Jrd+N1AYUCvslNJSklaVdMtA1KU1dJ6oPqPQayU9IunFnHPjDtKt93OipO9IaozkPjpA9ciSrkkpTUgpjW79rtvvZY7atscCnTpbYc8JpJQ+JOkXkvbJOVfyq27VJef895zzKur7y7qGpBVncMpsR0ppK0lP55wnzPDgOY91c86rqW+auXtKaT0Wdum9zJJt+4zQzc4+RRJ1kMNbvxsozJQV9uxGSmmw+jr6eTnnXw5kXSQp5/yipHHqGy4vmFJqNKLdeD/rSPpCSukxSReobyj/XwNQD+Wcp7T+fVrSper7H2C338ss2bbPCN3s7LdJWq610jpE0jaSrpjBOXMSV6jPAluaSSvsWUXqE6KfKWlSzvn4gapLSmnhlNKCrXg+9a0bTFJfp/9Kt+qRcz4o5zw857yU+r6H3+ect+t2PVJKH0wpfbiJJW0m6R51+b3knKdJeiKl1KRRa2zbZ0895vTChy00bCnpQfXNDw/u4n3PlzRV0lvq+7/nTuqbG46V9JCk30laqAv1WFd9Q7C71Jc/b2KrTbpaF0mfknRHqx73SPpe6/fLSLpV0sOSLpb0/i6+ow0kXTkQ9Wjd787Wf/c23+YAfSOrSBrfejeXSfrI7KpH7KALBHoEsUAXCPQIorMHAj2C6OyBQI8gOnsg0COIzh4I9AiiswcCPYLo7IFAjyA6eyDQI/j/zYPHmTCrk2gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############### From Keras To C weight encryption ####################\n",
    "import h5py\n",
    "\n",
    "def isgroup(obj):\n",
    "    if isinstance(obj, h5py.Group):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isdataset(obj):\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_DatasetsfromGroup(datasets, obj):\n",
    "    if isgroup(obj):\n",
    "        for key in obj:\n",
    "            x = obj[key]\n",
    "            #print(x)\n",
    "            get_DatasetfromGroup(datasets, x)\n",
    "    else:\n",
    "        datasets.append(obj)\n",
    "\n",
    "def getweightsforlayer(layername, filename):\n",
    "    weights = []\n",
    "    with h5py.File(filename, mode='r') as f:\n",
    "        for key in f:\n",
    "            if layername in key:\n",
    "                obj= f[key]\n",
    "                datasets = []\n",
    "                get_DatasetsfromGroup(datasets, obj)\n",
    "                \n",
    "                for dataset in datasets:\n",
    "                    w = np.array(dataset)\n",
    "                    weights.append(w)\n",
    "    return weights\n",
    "\n",
    "path = os.path.join(os.path.expanduser('~/eclipse-workspace/'), 'Utilities')\n",
    "weights = getweightsforlayer(\"conv2d\",path+'/Keras_Weights.h5')\n",
    "#for w in weights:\n",
    "    #print(w.shape)\n",
    "print(\"Reading from .h5 file completed!\")\n",
    "print(\"Now encrypting to binary files  for Python and C support. . .\")\n",
    "#Extraction from keras .h5 file completed, Now we are going to save them as encrypted binary for C support\n",
    "counter=0;\n",
    "filters = []\n",
    "bias = []\n",
    "fb_dc=[]\n",
    "temp = []\n",
    "\n",
    "######  Filters  #######\n",
    "for i in range(1,37,4):\n",
    "    temp1 = weights[i].reshape(weights[i].shape[3],weights[i].shape[2],weights[i].shape[0],weights[i].shape[1])\n",
    "    #print((weights[i]).reshape(weights[i].shape[3],weights[i].shape[2],weights[i].shape[0],weights[i].shape[1]).shape)\n",
    "    #filters[counter].append(temp)\n",
    "    temp2 =  (weights[i+2]).reshape(weights[i+2].shape[3],weights[i+2].shape[2],weights[i+2].shape[0],weights[i+2].shape[1]) #f2\n",
    "    #print(filters[counter][0])\n",
    "    #print(filters[counter][1])\n",
    "    f = [temp1, temp2]\n",
    "    filters.append(f)\n",
    "out_f = weights[37].reshape(weights[37].shape[3],weights[37].shape[2],weights[37].shape[0],weights[37].shape[1])\n",
    "\n",
    "\n",
    "##### BIAS ######\n",
    "for i in range(0,36,4):\n",
    "    temp1 = weights[i] #b1\n",
    "    temp2 =  weights[i+2] #b2\n",
    "    b = [temp1 , temp2]\n",
    "    bias.append(b)\n",
    "out_b = weights[36]\n",
    "\n",
    "for i in range(39,46,2):\n",
    "    f_dc = (weights[i]).reshape(weights[i].shape[2],weights[i].shape[3],weights[i].shape[0],weights[i].shape[1])\n",
    "    b_dc = weights[i-1]\n",
    "    temp = [f_dc, b_dc]\n",
    "    fb_dc.append(temp)\n",
    "    \n",
    "## Packing ##\n",
    "out_fb = [out_f,out_b]\n",
    "params = [filters, bias, fb_dc, out_fb, 0] \n",
    "\n",
    "Validate(train_images[1:2,:,:,:], train_labels[1:2,:,:,:], params, 0) #GN\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#path = os.path.join(os.path.expanduser('~/eclipse-workspace/'), 'Utilities')\n",
    "#with open (path+'/Keras_Weights.h5', 'rb') as fp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
