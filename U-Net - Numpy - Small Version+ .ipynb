{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "#import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load from /home/USER/data/mnist or elsewhere; download if missing.\"\"\"\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "\n",
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\salt\n",
    "        path = os.path.join(os.path.expanduser('~/'), 'data', 'salt')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    #os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\"\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "    print(\"All files are ready to gzip!\")\n",
    "    \"\"\"\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        folder = path + \"/images/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(32, 32)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,32,32).astype('float32')#/255\n",
    "        return pixels[:1,:,:,:]\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        \n",
    "        folder = path + \"/labels/\"\n",
    "        onlyfiles = [cv2.resize(cv2.cvtColor(image.imread(folder+f), cv2.COLOR_RGB2GRAY),(32, 32)) for f in os.listdir(folder)]\n",
    "        pixels = np.array(onlyfiles).reshape(-1,1,32,32).astype('float32') #/255\n",
    "        return pixels[:1,:,:,:]\n",
    "    print(\"Train Images : Loading . . .\")\n",
    "    train_images = _images(path)\n",
    "    print(\"Train Labels : Loading . . .\")\n",
    "    train_labels = _labels(path)\n",
    "    \"\"\"\"\n",
    "    print(\"Test Images  : Loading . . .\")\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    print(\"Test Labels  : Loading . . .\")\n",
    "    test_labels = _labels(os.path.join(path, files[3])) \n",
    "    \"\"\"\n",
    "    print(\"Done!\")\n",
    "    return train_images, train_labels #, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images : Loading . . .\n",
      "Train Labels : Loading . . .\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels= mnist()  #, test_images, test_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 32, 32)\n",
      "(1, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "ch = 1 #Number of channels\n",
    "#train_images=cv2.resize(train_images[0,0,:,:], (64,64)).reshape(1,1,64,64)\n",
    "#train_labels=cv2.resize(train_labels[0,0,:,:], (64,64)).reshape(1,1, 64,64)\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "\"\"\"\n",
    "temp = np.zeros((train_images.shape[0],1,128,128))\n",
    "for i in range(train_images.shape[0]):\n",
    "    #print(cv2.resize(train_images[i,0,:,:], (128,128)).shape)\n",
    "    temp[i,0,:,:]=cv2.resize(train_images[i,0,:,:], (128,128)).reshape(1,1,128,128)\n",
    "#print(train_images.shape)\n",
    "train_images= train_labels = temp\n",
    "print(train_labels.shape) \n",
    "#print(train_images.T.shape)\n",
    "#print(train_labels.reshape((train_images.shape[0], 10)).shape)\n",
    "\n",
    "##### Getting Ready for the Conv Layers #####\n",
    "#train_images = train_images.reshape(train_images.shape[0], ch, 28, 28).squeeze()\n",
    "#test_images = test_images.reshape(test_images.shape[0], ch, 28, 28).squeeze()\n",
    "\n",
    "#############################################\n",
    "\"\"\"\n",
    "#y = train_images[1].reshape(1,28,28)\n",
    "#print(y.squeeze().shape)\n",
    "'''\n",
    "temp = []\n",
    "#train_labels = train_labels.sum(1)\n",
    "for i in range(int(len(train_labels[:]))):\n",
    "    temp.append(list(train_labels[i][:]).index(1))\n",
    "    \n",
    "    \n",
    "train_labels = np.array(temp.copy())\n",
    "#print(train_labels[0:5])\n",
    "'''\n",
    "#plt.imshow(train_images[0].squeeze(), cmap='Greys_r');\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_labels[0].squeeze(), cmap=plt.get_cmap('gray'), vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Convolution Architecture - Downsampling/Upsampling  ##################\n",
    "\n",
    "def init_filters(layers, init_n_f,trim ):\n",
    "    filters = []\n",
    "    bias = []\n",
    "    f_dc = []\n",
    "    trimf = trim\n",
    "    trimb = trim*5\n",
    "    n_f = init_n_f #initial number of filters/kernels\n",
    "    ch_in = 1      #input channels\n",
    "    for i in range(layers):\n",
    "        if(i != 0):\n",
    "            n_f = n_f*2 #16,32,64,128,256\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "    \n",
    "    #Deconvolution filters    \n",
    "    for i in range(1,layers):\n",
    "        n_f = n_f//2 #128,64,32,16\n",
    "        #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "        fdc = np.random.randn(n_f,ch_in,2,2)*trimf #upsampling filter, its result will be conc with conv4 output so the channels will be doubled again\n",
    "        bdc = np.random.randn(fdc.shape[0],1)* trimb\n",
    "        f1 = (n_f, ch_in, 3, 3)\n",
    "        f1 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b1 = np.random.randn(f1.shape[0],1)* trimb\n",
    "        ch_in = n_f\n",
    "        f2 = (n_f, ch_in, 3, 3)\n",
    "        f2 = np.random.randn(n_f, ch_in, 3, 3) *trimf\n",
    "        b2 = np.random.randn(f2.shape[0],1)* trimb\n",
    "        f = [f1, f2]\n",
    "        b = [b1, b2]\n",
    "        dc = [fdc, bdc]\n",
    "        filters.append(f)\n",
    "        bias.append(b)\n",
    "        f_dc.append(dc)\n",
    "        \n",
    "    \n",
    "    return filters, bias, f_dc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Activation Functions ###\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## UTILITIES #############\n",
    "\n",
    "\n",
    "def conv(image, params, s = 1, pad = 1 ): # s = 1 (conv stride)\n",
    "    #f1 shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "    [f, b] = params\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((image.shape[0],image.shape[1]+2*pad ,image.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = image\n",
    "        image = tmp    \n",
    "        \n",
    "    f_num = f.shape[0]\n",
    "    f_depth = f.shape[1] #f1 = 1 , f2 = 8\n",
    "    f_size = f.shape[2] \n",
    "        \n",
    "\n",
    "    h_range = int((image.shape[1] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f_size) / s) + 1     # (W - F + 2P) / S  \n",
    "    np_o = np.zeros((f_num, h_range, w_range))\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                np_o[z, _h, _w] = np.sum(np.multiply(image[:, _h*s : _h*s + f_size, _w*s : _w*s + f_size] , f[z, :, :, :])) + b[z]\n",
    "    \n",
    "    return np_o\n",
    "\n",
    "def convolutionBackward(dconv_prev, conv_in, filt, s = 1, pad = 1 ):\n",
    "    f_num, n_c, f, _ = filt.shape\n",
    "    \n",
    "    _ ,h , w = dconv_prev.shape\n",
    "    dfilt = np.zeros(filt.shape)\n",
    "    if(pad >= 1):\n",
    "        tmp = np.zeros((conv_in.shape[0],conv_in.shape[1]+2*pad ,conv_in.shape[2]+2*pad))\n",
    "        tmp[:,pad:-pad,pad:-pad] = conv_in\n",
    "        conv_in = tmp\n",
    "    \n",
    "    dconv_in = np.zeros(conv_in.shape)\n",
    "    db = np.zeros((f_num,1))\n",
    "\n",
    "    for z in range(f_num): # Number of filters\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                #each entry of the dconv_prev will try to affect the idxs from which was made of.\n",
    "                dfilt[z] += dconv_prev[z, _h, _w] * conv_in[:, _h*s : _h*s + f, _w*s : _w*s + f]\n",
    "                dconv_in[:, _h*s : _h*s + f, _w*s : _w*s + f] += dconv_prev[z, _h, _w] * filt[z]  \n",
    "        db[z] = np.sum(dconv_prev[z])  #, axis =1) ## AXIS?\n",
    "    \n",
    "    if(pad >=1 ):\n",
    "        dconv_in = dconv_in[:, pad:-pad, pad:-pad]  # Cropping\n",
    "        \n",
    "    return dconv_in, dfilt, db\n",
    "\n",
    "\n",
    "def convTransp(image, params, s = 1, pad = 1):\n",
    "    #s is always 1, upsample kernel = 2\n",
    "    #zero insertions between pixels s_downsampled -1 = 2-1 = 1\n",
    "    #required padding in order to double my dimensions with the given data:\n",
    "    #(i-1)*2 + k -2p = output size, where our padding is k - p -1 = 2-0-1=1(we assume p=0)\n",
    "    input_s = image.shape[1]\n",
    "    target_dim = input_s*2 #final dim, after conv\n",
    "    required_pad = 1 #always for filter 2x2 ,stride 1, zero insertion 1 and main target to double dim\n",
    "    #make our new custom input\n",
    "    size = input_s*2 +1\n",
    "    new_in = np.zeros((image.shape[0], size, size))\n",
    "    for i in range(1, target_dim, 2):\n",
    "        for j in range(1, target_dim, 2):\n",
    "                new_in[:, i, j] = image[:, i//2, j//2]\n",
    "    #now we do a normal convolution(pad = 0)\n",
    "    res = conv(new_in, params, 1, 0) #thats the final result with target_dim\n",
    "    return res, new_in # we will need new_in so we wont calc it again for the backprop\n",
    "    \n",
    "def convTranspBackward(dconv_prev, new_in, filt, s = 1):\n",
    "    #First, we do a backward convolution on new_in,d_conv_prev,\n",
    "    #then we will choose form the d_conv_new the entries that match the initial 'smaller' input image\n",
    "    #by selecting the odd matrix cells 1,3,5... because we had applied a standard pad=1,zero inser=1\n",
    "    dconv_in, dfilt, db = convolutionBackward(dconv_prev, new_in, filt,1,0)\n",
    "    #Now its time to choose the right entries to build the gradients of the initial input image\n",
    "    dim = dconv_in.shape[1]\n",
    "    final_dim = (new_in.shape[1] - 2)//2 + 1 #based on dimen of image before final conv that gives the result,..\n",
    "    #e.g. for new_in 7x7 that is going to convoluted with a 2x2 kernel and give a 6x6 upsampled from 3x3 init image\n",
    "    # now from this 7x7 --> apply the formula above,we get the 3x3 dimension number\n",
    "    res = np.zeros((dconv_in.shape[0], final_dim, final_dim))\n",
    "    for i in range(1, dim, 2):\n",
    "        for j in range(1, dim, 2):\n",
    "                res[:, i//2, j//2] = dconv_in[:, i, j]\n",
    "    return res, dfilt, db\n",
    "    \n",
    "    \n",
    "def maxpool(image, f=2 , s=2):\n",
    "    \n",
    "    h_range = int((image.shape[1] - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w_range = int((image.shape[2] - f) / s) + 1     # (W - F + 2P) / S \n",
    "    out = np.zeros((image.shape[0], h_range, w_range))\n",
    "    \n",
    "    for z in range(image.shape[0]): # Number of channels\n",
    "        for _h in range(h_range):      \n",
    "            for _w in range(w_range):\n",
    "                out[z, _h, _w] = np.max(image[z, _h*s : _h*s + f, _w*s : _w*s + f])\n",
    "    return out\n",
    "\n",
    "def nanargmax(arr):\n",
    "    #print(arr.shape)\n",
    "    try:\n",
    "        idx = np.nanargmax(arr)\n",
    "        #print (idx)\n",
    "    except:\n",
    "        idx = 0\n",
    "    idxs = np.unravel_index(idx, arr.shape)\n",
    "    return idxs \n",
    "\n",
    "def maxpoolBackward(dpool, conv, f=2 , s=2):\n",
    "    num_c, h, w = conv.shape\n",
    "    h = int((h - f) / s) + 1     # (W - F + 2P) / S  \n",
    "    w = int((w - f) / s) + 1     # (W - F + 2P) / S \n",
    "    \n",
    "    dout = np.zeros(conv.shape)\n",
    "    #print(conv.shape)\n",
    "    for z in range(num_c): # Number of channels\n",
    "        for _h in range(h):      \n",
    "            for _w in range(w):\n",
    "                (a, b) = nanargmax(conv[z, _h*s : _h*s + f, _w*s : _w*s + f]) #Getting the indexes from the max value in this area\n",
    "                #put it on the new array\n",
    "                dout[z, _h + a, _w + b] = dpool[z, _h, _w]\n",
    "    \n",
    "    \n",
    "    return dout\n",
    "\n",
    "\n",
    "def reshape(img, reshape_dim):\n",
    "    pad = reshape_dim - img.shape[1]\n",
    "    if(pad == 0):\n",
    "        return img\n",
    "    res = np.zeros((img.shape[0], reshape_dim, reshape_dim))\n",
    "    if(pad > 1):\n",
    "        res[:, pad//2:-(pad//2), pad//2:-(pad//2)] = img\n",
    "    else:\n",
    "        res[:, 0:-(pad), 0:-(pad)] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop(img, crop_dim): #TODO : look at it..future upgrade to downsample..maybe\n",
    "    start = img.shape[1]//2 - crop_dim//2\n",
    "    return img[:,(start):(start +crop_dim),(start):(start +crop_dim)]\n",
    "\n",
    "    \n",
    "    \n",
    "def crop2half(img):\n",
    "    #return gradients for decoder side and gradients for encoder side\n",
    "    n_ch = img.shape[0]//2\n",
    "    return img[n_ch:n_ch*2 ,:,:], img[0:n_ch,:,:]\n",
    "    \n",
    "def concat(img1_true, img2):\n",
    "    n_ch = img1_true.shape[0]\n",
    "    dim = img1_true.shape[1]\n",
    "    if(img2.shape[1] != dim):\n",
    "        img2 = crop(img2, dim)\n",
    "        print(\"Warning: Extra crop needed and handled!(%d --> %d)\" %(dim, img2.shape[1]))\n",
    "    res = np.zeros((n_ch*2, dim, dim))\n",
    "    res[0:n_ch,:,:] = img2\n",
    "    res[n_ch:n_ch*2 ,:,:] = img1_true\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cost Calculations ######\n",
    "def NLLLoss(logs, targets):\n",
    "    out = np.zeros(logs.shape)\n",
    "    mylen = logs.shape[0]*logs.shape[1]*logs.shape[1]\n",
    "    #print(len(targets))\n",
    "    #logs.shape (dim x dim) like target\n",
    "    for i in range(logs.shape[1]):\n",
    "        for j in range(logs.shape[2]):\n",
    "            if(targets[:,i,j] >= logs[:,i,j]):#Gray and above\n",
    "                out[:,i,j] = logs[:,i,j]/targets[:,i,j] \n",
    "            else:\n",
    "                out[:,i,j] = (1 - logs[:,i,j])/(1 - targets[:,i,j]) # e.g if logs[i,j]= 0.4 and we want(target) 0 --> 1-0.4=0.6 prob. for zero \n",
    "    #or\n",
    "    #out = targets*logs + ((-1*(targets-1)) - (-1*(targets-1))*logs)\n",
    "    res =out.sum()/mylen\n",
    "    return -np.log(res),res\n",
    "\n",
    "def get_cost_value(Y_hat, Y):\n",
    "    # number of examples\n",
    "    m = Y_hat.shape[1]\n",
    "    \n",
    "    # calculation of the cost according to the formula\n",
    "    cost = -1 / m * (np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))\n",
    "    return np.squeeze(cost) ### ATTENTION!\n",
    "\n",
    "def normalize(output):\n",
    "    output[output<-10]=-4\n",
    "    output[output>10] = 4\n",
    "    return output\n",
    "\n",
    "###### Accuracy Calculation ######\n",
    "\n",
    "# an auxiliary function that converts probability into class\n",
    "def convert_prob_into_class(probs):\n",
    "    probs_ = np.copy(probs)\n",
    "    probs_[probs_ > 0.5] = 1\n",
    "    probs_[probs_ <= 0.5] = 0\n",
    "    return probs_\n",
    "\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat)\n",
    "    return (Y_hat_ == Y).all(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  TRAIN  ######\n",
    "#import torch`\n",
    "import time\n",
    "time.time()\n",
    "\n",
    "\n",
    "def train(X, Y, epochs, learning_rate, dropout, verbose=True, callback=None):\n",
    "    # initiation of neural net parameters\n",
    "    #params_values = init_layers(nn_architecture, 2)\n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    #f1,f2,f3,f4,f5,fd1,fd2,fd3,fd4\n",
    "    trim= 0.000001\n",
    "    filters,bias, f_dc = init_filters(4,16,trim) #Double the channel-filter 4 times  (up to 256 and back again)\n",
    "    ##Final 1x1 filter\n",
    "    trimf = trim\n",
    "    trimb = trim*5\n",
    "    out_f = np.random.randn(1,16,1,1)*trimf\n",
    "    out_b = np.random.randn(out_f.shape[0],1)*trimb  \n",
    "    out_fb = [out_f, out_b]\n",
    "    #filter shape : (num_filters,input channels, f_h, f_w)\n",
    "    #image shape: (channels, height, width)\n",
    "\n",
    "    v_adam =  [] #filter1,filter2\n",
    "    s_adam =  [] \n",
    "    bv_adam = [] #bias1,bias2\n",
    "    bs_adam = []\n",
    "    fdc_v_adam=[] #filter,bias\n",
    "    fdc_s_adam=[]\n",
    "    #format: [v1,v2,v3,v4,v5,vd1,vd2,vd3,vd4] ,same for the rest, each of these include a tuple for the 2 conv filter\n",
    "    #[s1,s2,s3,s4,s5,sd1,sd2,vs3,sd4]\n",
    "    # upsampling filters : [v1_dc,v2_dc,v3_dc]  \n",
    "\n",
    "            \n",
    "\n",
    "    # performing calculations for subsequent iterations\n",
    "    \n",
    "    \n",
    "    [f1,f2,f3,f4,f5,f6,f7] = filters\n",
    "    [b1,b2,b3,b4,b5,b6,b7]= bias \n",
    "    \n",
    "    f1_dc = f_dc[0][0]\n",
    "    b1_dc = f_dc[0][1]\n",
    "    f2_dc = f_dc[1][0]\n",
    "    b2_dc = f_dc[1][1]\n",
    "    f3_dc = f_dc[2][0]\n",
    "    b3_dc = f_dc[2][1]\n",
    "    \n",
    "    prev_cost = 1000\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # step forward\n",
    "        \n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        batch = 1\n",
    "        print(\"Epoch: {%d}\" %(e+1))\n",
    "        for c in range(0, X.shape[0], batch):\n",
    "            print('Batch: {}'.format(int(c/batch +1)))\n",
    "            #### Reset Gradients (Every batch) ####\n",
    "            beta1= 0.9  #0.9\n",
    "            beta2= 0.99 #0.99\n",
    "            #lr = learning_rate\n",
    "            batch_size= batch\n",
    "            if(X.shape[0] - c < batch):#means that there is a smaller(<32) part left\n",
    "                batch = X.shape[0] - c\n",
    "            X_t = X[c:(c + batch)]  # shape:(m, ch, h, w)\n",
    "            Y_t = Y[c:(c + batch)]\n",
    "            cost = 0\n",
    "            accuracy = 0\n",
    "            \n",
    "            #Special setup for LR\n",
    "            if(e<4):\n",
    "                lr=0.03\n",
    "            ####TODO:Possible solution for unstable future results(from ~1x10-5 --> 0.98 possibility and back again),\n",
    "            #is to reduce dynamically the learning rate(this problem can also be reduced by making trims even smaller)\n",
    "            \n",
    "            if(e < 20):\n",
    "                \n",
    "                df =  []\n",
    "                db =  []\n",
    "                dfb=  []\n",
    "                for i in filters:\n",
    "                    v1 = np.zeros(i[0].shape)\n",
    "                    v2 = np.zeros(i[1].shape)\n",
    "                    s1 = np.zeros(i[0].shape)\n",
    "                    s2 = np.zeros(i[1].shape)\n",
    "                    v_a = [v1, v2]\n",
    "                    s_a = [s1, s2]\n",
    "                    v_adam.append(v_a)\n",
    "                    s_adam.append(s_a)\n",
    "\n",
    "                    df1_t = np.zeros(i[0].shape)\n",
    "                    df2_t = np.zeros(i[1].shape)\n",
    "                    f_temp = [df1_t, df2_t]\n",
    "                    df.append(f_temp)\n",
    "\n",
    "                for i in bias:\n",
    "                    bv1 = np.zeros(i[0].shape)\n",
    "                    bv2 = np.zeros(i[1].shape)\n",
    "                    bs1 = np.zeros(i[0].shape)\n",
    "                    bs2 = np.zeros(i[1].shape)    \n",
    "                    bv_a = [bv1, bv2]\n",
    "                    bs_a = [bs1, bs2]\n",
    "                    bv_adam.append(bv_a)\n",
    "                    bs_adam.append(bs_a)\n",
    "\n",
    "\n",
    "                    db1_t = np.zeros(i[0].shape)\n",
    "                    db2_t = np.zeros(i[1].shape)\n",
    "                    b_temp = [db1_t, db2_t]\n",
    "                    db.append(b_temp)\n",
    "\n",
    "                for i in f_dc:\n",
    "                    fdc_v1 = np.zeros(i[0].shape)\n",
    "                    bdc_v2 = np.zeros(i[1].shape)\n",
    "                    fdc_s1 = np.zeros(i[0].shape)\n",
    "                    bdc_s2 = np.zeros(i[1].shape)    \n",
    "                    fdc_v_a = [fdc_v1, bdc_v2]\n",
    "                    fdc_s_a = [fdc_s1, bdc_s2]\n",
    "                    fdc_v_adam.append(fdc_v_a)\n",
    "                    fdc_s_adam.append(fdc_s_a)\n",
    "\n",
    "\n",
    "                    df1_t = np.zeros(i[0].shape)\n",
    "                    db1_t = np.zeros(i[1].shape)\n",
    "                    fb_temp = [df1_t, db1_t]\n",
    "                    dfb.append(fb_temp)\n",
    "\n",
    "\n",
    "                #Final layer 1x1 filter setup\n",
    "\n",
    "                v_out_f = np.zeros(out_f.shape)\n",
    "                s_out_f = np.zeros(out_f.shape)\n",
    "                bv_out_b = np.zeros(out_b.shape)\n",
    "                bs_out_b = np.zeros(out_b.shape)\n",
    "\n",
    "\n",
    "\n",
    "                dout_f = np.zeros(out_f.shape)\n",
    "                dout_b = np.zeros(out_b.shape)\n",
    "\n",
    "            ######################################\n",
    "\n",
    "\n",
    "            #timestamp1 = time.time()\n",
    "\n",
    "\n",
    "            [df1,df2,df3,df4,df5,df6,df7] = df\n",
    "            [db1,db2,db3,db4,db5,db6,db7] = db \n",
    "            [dfb1_dc, dfb2_dc, dfb3_dc]    = dfb\n",
    "            \n",
    "            \n",
    "            for b in range(batch):\n",
    "                \n",
    "                print('Image: {}/{}'.format((b+1),batch))\n",
    "                #################### TODO: BLOCK IMPLEMENTATION - FUTURE UPDATE ######################\n",
    "                    \n",
    "                    \n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ######################## Forward Propagation Convolution Part  ##########################\n",
    "\n",
    "                \n",
    "                ########### 1st Big Layer ###########    (with zero padding ='same',so with stride =1 we get same dim as the input)\n",
    "                params = [f1[0], b1[0]]  \n",
    "                conv1_1 = conv(X_t[b], params, 1)   #conv1 shape = (num_channels, h, w), padding = 1 (same output dim)\n",
    "                conv1_1[conv1_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f1[1], b1[1]]\n",
    "                conv1_2 = conv(conv1_1, params, 1)\n",
    "                conv1_2[conv1_2<=0] = 0 #Relu\n",
    "                ##################################### conv1_2: 32x32x16\n",
    "                \n",
    "                pl1 = maxpool(conv1_2, 2, 2) #   pl1 : (32-2)/2+1  = 16 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 2nd Big Layer ###########\n",
    "                params = [f2[0], b2[0]]  \n",
    "                conv2_1 = conv(pl1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv2_1[conv2_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f2[1], b2[1]]\n",
    "                conv2_2 = conv(conv2_1, params, 1)\n",
    "                conv2_2[conv2_2<=0] = 0 #Relu             \n",
    "                #####################################  16x16x32\n",
    "                \n",
    "                pl2 = maxpool(conv2_2, 2, 2) #   pl1 : (16-2)/2+1  = 8 \n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "                \n",
    "                ########### 3rd Big Layer ###########\n",
    "                params = [f3[0], b3[0]]  \n",
    "                conv3_1 = conv(pl2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv3_1[conv3_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f3[1], b3[1]]\n",
    "                conv3_2 = conv(conv3_1, params, 1)\n",
    "                conv3_2[conv3_2<=0] = 0 #Relu             \n",
    "                #####################################  8x8x64\n",
    "                         \n",
    "                pl3 = maxpool(conv3_2, 2, 2) #   pl1 : (8-2)/2+1  = 4   4x4x64\n",
    "                ## ADD DROPOUT HERE(on pl1)\n",
    "            \n",
    "                ########### 4th Big Layer ###########\n",
    "                params = [f4[0], b4[0]]  \n",
    "                conv4_1 = conv(pl3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv4_1[conv4_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f4[1], b4[1]]\n",
    "                conv4_2 = conv(conv4_1, params, 1)\n",
    "                conv4_2[conv4_2<=0] = 0 #Relu              \n",
    "                #####################################  4x4x128\n",
    "                \n",
    "                ##################################### \n",
    "                ##################################### \n",
    "                #####################################\n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[0][0], f_dc[0][1]] # deconv filter, deconv bias\n",
    "                dc1, new_in1 = convTransp(conv4_2, params, 1, 0)   #result:   =  8x8x64 , \n",
    "                #Concat dc1 with conv3_2 \n",
    "                c1 = concat(dc1, conv3_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          8x8x128     \n",
    "                params = [f5[0], b5[0]]  \n",
    "                conv5_1 = conv(c1, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv5_1[conv5_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f5[1], b5[1]]\n",
    "                conv5_2 = conv(conv5_1, params, 1)\n",
    "                conv5_2[conv5_2<=0] = 0 #Relu   \n",
    "                #####################################    8x8x64\n",
    "                \n",
    "                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[1][0], f_dc[1][1]] # deconv filter, deconv bias\n",
    "                dc2, new_in2 = convTransp(conv5_2, params, 1, 0)   #result:   =  16x16x32 , \n",
    "                #Concat dc2 with conv1_2 \n",
    "                c2 = concat(dc2, conv2_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 1st Big dc Layer ###########          16x16x64     \n",
    "                params = [f6[0], b6[0]]  \n",
    "                conv6_1 = conv(c2, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv6_1[conv6_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f6[1], b6[1]]\n",
    "                conv6_2 = conv(conv6_1, params, 1)\n",
    "                conv6_2[conv6_2<=0] = 0 #Relu   \n",
    "                #####################################    16x16x32\n",
    "                \n",
    "                                #Deconvolution/Upsampling\n",
    "                # insert zeros : s-1 = 1, padding = k - p -1 = 2-0(what i want)-1=1 ,  s'=1(always) --> (i-1)*s+k-2p = \n",
    "               \n",
    "                params = [f_dc[2][0], f_dc[2][1]] # deconv filter, deconv bias\n",
    "                dc3, new_in3 = convTransp(conv6_2, params, 1, 0)   #result:   =  32x32x16 , \n",
    "                #Concat dc2 with conv1_2 \n",
    "                c3 = concat(dc3, conv1_2) # 1st one is the right one size  \n",
    "                \n",
    "                ########### 3rd Big dc Layer ###########          32x32x32  \n",
    "                params = [f7[0], b7[0]]  \n",
    "                conv7_1 = conv(c3, params, 1)   #conv1 shape = (num_channels, h, w)\n",
    "                conv7_1[conv7_1<=0] = 0 #Relu\n",
    "\n",
    "                params = [f7[1], b7[1]]\n",
    "                conv7_2 = conv(conv7_1, params, 1)\n",
    "                conv7_2[conv7_2<=0] = 0 #Relu   \n",
    "                #####################################    32x32x16\n",
    "                \n",
    "                \n",
    "                ############################# Last Layer conv(1x1) --> 32x32x1 ##########################\n",
    "                params = [out_f, out_b]\n",
    "                output = conv(conv7_2, params, 1, 0) #output.shape: 32x32x1\n",
    "                \n",
    "                \n",
    "                #output = normalize(output)\n",
    "                ## Sigmoid ##\n",
    "                Y_hat = sigmoid(output)\n",
    "                #print(Y_hat[:,5:9,13:16])\n",
    "                #label crop is needed\n",
    "                #Y_t_b = crop(Y_t[b], Y_hat.shape[1])\n",
    "                #Y_hat[:,20:25,20:23] = 0.001\n",
    "                plt.imshow(Y_hat.squeeze(), cmap=plt.get_cmap('gray'), vmin=0, vmax=1);\n",
    "                cost_,accuracy_ = NLLLoss(Y_hat, Y_t[b])\n",
    "                cost += cost_\n",
    "                accuracy += accuracy_\n",
    "                #print(cost/(b+1), prev_cost)\n",
    "                #if(((cost-prev_cost)>0.2)and((e+1) == epochs)):\n",
    "                #    e=e-1\n",
    "                #    print(\"\\n\\n-------------Epoch skipped!--------------\\n\\n\")\n",
    "                #    continue\n",
    "                #prev_cost = cost\n",
    "                \n",
    "                #accuracy += get_accuracy_value(Y_hat, Y_t[b])\n",
    "                #print(accuracy/(b+1))\n",
    "                #########################################################################################\n",
    "                #########################################################################################\n",
    "                ################################# Backward Propagation ##################################\n",
    "                \n",
    "                \n",
    "                #Pixel-wise sub, we we can get the diff(Y includes the 2 classes 0 and 1)\n",
    "                \n",
    "                dA_prev = (Y_hat - Y_t[b]) #- (np.divide(Y_t[b], Y_hat) - np.divide(1 - Y_t[b], 1 - Y_hat))#Y_hat - Y_t[b]\n",
    "                #print(Y_hat[:,20:25,19:23])\n",
    "                print(dA_prev[:,20:25,19:23])\n",
    "                #print(Y_hat[:,5:9,13:16])\n",
    "                dZ_prev = sigmoid_backward(dA_prev, output)\n",
    "                conv_s =1 \n",
    "                dconv7_2, dout_f_, dout_b_ = convolutionBackward(dZ_prev, conv7_2, out_f, conv_s) #\n",
    "                #pack data\n",
    "\n",
    "                    \n",
    "                #Y_hat[:,5:9,13:16]\n",
    "\n",
    "                \n",
    "                dconv7_2[conv7_2<=0] = 0             \n",
    "                dconv7_1, df7_2, db7_2 = convolutionBackward(dconv7_2, conv7_1, f7[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv7_1[conv7_1<=0] = 0\n",
    "                conc_dconv7, df7_1, db7_1 = convolutionBackward(dconv7_1, c3, f7[0], conv_s) #\n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv7, dconv1_2 = crop2half(conc_dconv7)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv6_2, df3_dc, db3_dc = convTranspBackward(dconv7, new_in3, f_dc[2][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv6_2[conv6_2<=0] = 0\n",
    "                dconv6_1, df6_2, db6_2 = convolutionBackward(dconv6_2, conv6_1, f6[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv6_1[conv6_1<=0] = 0\n",
    "                conc_dconv6, df6_1, db6_1 = convolutionBackward(dconv6_1, c2, f6[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                ###### we get the concat gradients ######\n",
    "                #crop the half matrix, we need the second half with the gradients(according to the concat thats the output of the transposed conv)\n",
    "                #### we split the gradients and push them back to their sources  ####\n",
    "                dconv6, dconv2_2 = crop2half(conc_dconv6)  #we will later add gradients of dconv1_2(came from backprop concat) with the extra gradients of its next layer\n",
    "                #conv8_2 is not needed for input,we know how to select the right gradients            \n",
    "                #dconv1_2 = reshape(dconv1_2, conv1_2.shape[1])\n",
    "                dconv5_2, df2_dc, db2_dc = convTranspBackward(dconv6, new_in2, f_dc[1][0], conv_s)\n",
    "                #pack data\n",
    "                \n",
    "                dconv5_2[conv5_2<=0] = 0\n",
    "                dconv5_1, df5_2, db5_2 = convolutionBackward(dconv5_2, conv5_1, f5[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv5_1[conv5_1<=0] = 0\n",
    "                conc_dconv5, df5_1, db5_1 = convolutionBackward(dconv5_1, c1, f5[0], conv_s) #\n",
    "                \n",
    "                dconv5, dconv3_2 = crop2half(conc_dconv5)\n",
    "                dconv4_2, df1_dc, db1_dc = convTranspBackward(dconv5, new_in1, f_dc[0][0], conv_s)\n",
    "                \n",
    "                dconv4_2[conv4_2<=0] = 0\n",
    "                dconv4_1, df4_2, db4_2 = convolutionBackward(dconv4_2, conv4_1, f4[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv4_1[conv4_1<=0] = 0\n",
    "                dpl3, df4_1, db4_1 = convolutionBackward(dconv4_1, pl3, f4[0], conv_s) #\n",
    "                \n",
    "                dconv3_2 += maxpoolBackward(dpl3, conv3_2, f=2 , s=2)\n",
    "                \n",
    "                \n",
    "                dconv3_2[conv3_2<=0] = 0\n",
    "                dconv3_1, df3_2, db3_2 = convolutionBackward(dconv3_2, conv3_1, f3[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv3_1[conv3_1<=0] = 0\n",
    "                dpl2, df3_1, db3_1 = convolutionBackward(dconv3_1, pl2, f3[0], conv_s) #\n",
    "                \n",
    "                dconv2_2 += maxpoolBackward(dpl2, conv2_2, f=2 , s=2)\n",
    "                \n",
    "                dconv2_2[conv2_2<=0] = 0\n",
    "                dconv2_1, df2_2, db2_2 = convolutionBackward(dconv2_2, conv2_1, f2[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv2_1[conv2_1<=0] = 0\n",
    "                dpl1, df2_1, db2_1 = convolutionBackward(dconv2_1, pl1, f2[0], conv_s) #\n",
    "                \n",
    "                dconv1_2 += maxpoolBackward(dpl1, conv1_2, f=2 , s=2)\n",
    "                \n",
    "                dconv1_2[conv1_2<=0] = 0\n",
    "                dconv1_1, df1_2, db1_2 = convolutionBackward(dconv1_2, conv1_1, f1[1], conv_s) #\n",
    "                #pack data\n",
    "                dconv1_1[conv1_1<=0] = 0\n",
    "                _, df1_1, db1_1 = convolutionBackward(dconv1_1, X_t[b], f1[0], conv_s) #\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                #[df1,df2,df3,df4,df5,df6,df7] = df\n",
    "                #[db1,db2,db3,db4,db5,df6,df7] = db \n",
    "                #dfb1_dc,dfb2_dc, dfb3_dc     = dfb\n",
    "\n",
    "                \n",
    "                df1[0] += df1_1\n",
    "                df1[1] += df1_2\n",
    "                df2[0] += df2_1\n",
    "                df2[1] += df2_2\n",
    "                df3[0] += df3_1\n",
    "                df3[1] += df3_2\n",
    "                df4[0] += df4_1\n",
    "                df4[1] += df4_2\n",
    "                df5[0] += df5_1\n",
    "                df5[1] += df5_2\n",
    "                df6[0] += df6_1\n",
    "                df6[1] += df6_2\n",
    "                df7[0] += df7_1\n",
    "                df7[1] += df7_2\n",
    "                \n",
    "                db1[0] += db1_1\n",
    "                db1[1] += db1_2\n",
    "                db2[0] += db2_1\n",
    "                db2[1] += db2_2\n",
    "                db3[0] += db3_1\n",
    "                db3[1] += db3_2\n",
    "                db4[0] += db4_1\n",
    "                db4[1] += db4_2\n",
    "                db5[0] += db5_1\n",
    "                db5[1] += db5_2\n",
    "                db6[0] += db6_1\n",
    "                db6[1] += db6_2\n",
    "                db7[0] += db7_1\n",
    "                db7[1] += db7_2\n",
    "\n",
    "                dfb1_dc[0] += df1_dc\n",
    "                dfb1_dc[1] += db1_dc\n",
    "                dfb2_dc[0] += df2_dc\n",
    "                dfb2_dc[1] += db2_dc\n",
    "                dfb3_dc[0] += df3_dc\n",
    "                dfb3_dc[1] += db3_dc\n",
    "\n",
    "                dout_f += dout_f_\n",
    "                dout_b += dout_b_\n",
    "\n",
    "\n",
    "      \n",
    "            \n",
    "      \n",
    "            \n",
    "            \n",
    "            ############## Adam Optimization ################\n",
    "            #changing the main structures(which are also updated)\n",
    "            #TODO: Future update - remove uneccessary memory loads/stores, v,s dont need to be saved \n",
    "            for i in range(len(filters)):\n",
    "                v_adam[i][0] = beta1*v_adam[i][0] + (1-beta1)*df[i][0]/batch_size #f1\n",
    "                s_adam[i][0] = beta2*s_adam[i][0] + (1-beta2)*(df[i][0]/batch_size)**2 #f1\n",
    "                filters[i][0] -= lr*v_adam[i][0]/np.sqrt(s_adam[i][0] + 1e-7)\n",
    "                \n",
    "                \n",
    "                v_adam[i][1] = beta1*v_adam[i][1] + (1-beta1)*df[i][1]/batch_size #f2\n",
    "                s_adam[i][1] = beta2*s_adam[i][1] + (1-beta2)*(df[i][1]/batch_size)**2  #f2\n",
    "                filters[i][1] -= lr*v_adam[i][1]/np.sqrt(s_adam[i][1] + 1e-7)\n",
    "                \n",
    "            for i in range(len(bias)):\n",
    "                bv_adam[i][0] = beta1*bv_adam[i][0] + (1-beta1)*db[i][0]/batch_size #b1\n",
    "                bs_adam[i][0] = beta2*bs_adam[i][0] + (1-beta2)*(db[i][0]/batch_size)**2  #b1\n",
    "                bias[i][0] -= lr*bv_adam[i][0]/np.sqrt(bs_adam[i][0] + 1e-7)\n",
    "                \n",
    "                bv_adam[i][1] = beta1*bv_adam[i][1] + (1-beta1)*db[i][1]/batch_size #b2\n",
    "                bs_adam[i][1] = beta2*bs_adam[i][1] + (1-beta2)*(db[i][1]/batch_size)**2  #b2\n",
    "                bias[i][1] -= lr*bv_adam[i][1]/np.sqrt(bs_adam[i][1] + 1e-7)\n",
    "            \n",
    "            for i in range(len(f_dc)):\n",
    "                fdc_v_adam[i][0] = beta1*fdc_v_adam[i][0] + (1-beta1)*dfb[i][0]/batch_size #f1\n",
    "                fdc_s_adam[i][0] = beta2*fdc_s_adam[i][0] + (1-beta2)*(dfb[i][0]/batch_size)**2  #f1\n",
    "                f_dc[i][0] -= lr*fdc_v_adam[i][0]/np.sqrt(fdc_s_adam[i][0] + 1e-7)\n",
    "                \n",
    "                fdc_v_adam[i][1] = beta1*fdc_v_adam[i][1] + (1-beta1)*dfb[i][1]/batch_size #b2\n",
    "                fdc_s_adam[i][1] = beta2*fdc_s_adam[i][1] + (1-beta2)*(dfb[i][1]/batch_size)**2  #b2\n",
    "                f_dc[i][1] -= lr*fdc_v_adam[i][1]/np.sqrt(fdc_s_adam[i][1] + 1e-7)    \n",
    "            \n",
    "            v_out_f = beta1*v_out_f + (1 - beta1)*dout_f/batch_size #f\n",
    "            s_out_f = beta2*s_out_f + (1 - beta2)*(dout_f/batch_size)**2  #f\n",
    "            out_fb[0] -= lr*v_out_f/np.sqrt(s_out_f + 1e-7)\n",
    "            \n",
    "            bv_out_b = beta1*bv_out_b + (1 - beta1)*dout_b/batch_size #b\n",
    "            bs_out_b = beta2*bs_out_b + (1 - beta2)*(dout_b/batch_size)**2  #b\n",
    "            out_fb[1] -= lr*bv_out_b/np.sqrt(bs_out_b + 1e-7)\n",
    "            \n",
    "            '''\n",
    "                        for i in range(len(filters)):\n",
    "                filters[i][0] -= lr*df[i][0]\n",
    "                bias[i][0] -= lr*db[i][0]\n",
    "            \n",
    "            \n",
    "            f_dc[0][0] -= lr*df1_dc\n",
    "            f_dc[0][1] -= lr*db1_dc\n",
    "            \n",
    "            out_fb[0] -= lr*dout_f\n",
    "            out_fb[1] -= lr*dout_b\n",
    "            #Updating Conv Part\n",
    "            \n",
    "\n",
    "            #print(Yh)\n",
    "            #print(t)\n",
    "            #print(\"Batch:{}\".format(c+12))\n",
    "            \n",
    "           \n",
    "            f1 -= (learning_rate) * (df1/batch)\n",
    "            f2 -= (learning_rate) * (df2/batch)\n",
    "            b1 -= (learning_rate) * (db1/batch)\n",
    "            b2 -= (learning_rate) * (db2/batch)\n",
    "            filter_params = [f1, f2, b1, b2]\n",
    "                \n",
    "            # updating FC Part\n",
    "            #params_values = update(params_values, grads_values, nn_architecture, learning_rate)\n",
    "            grads_values['dW1'] = dW1#/(batch)\n",
    "            grads_values['dW2'] = dW2#/(batch)\n",
    "            grads_values['db1'] = dB1#/(batch)\n",
    "            grads_values['db2'] = dB2#/(batch)\n",
    "                   \n",
    "            for layer_idx, layer in enumerate(nn_architecture, 1):\n",
    "                \n",
    "                params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)]        \n",
    "                params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)]\n",
    "\n",
    "            '''\n",
    "            #print(\"Cost : {:.5f}\".format(cost/batch))\n",
    "            #print(\"Accuracy : {:.5f}%\".format((accuracy*100)/batch))\n",
    "            \n",
    "        #END OF LOOP - EPOCH\n",
    "        #timestamp2 = time.time()\n",
    "        #print (\"This took %.2f seconds\" %(timestamp2 - timestamp1))\n",
    "        if(verbose):\n",
    "            print(\"Epoch: {:5d}   -   cost: {:.2f}   -   Accuracy: {:.2f}%\".format(e+1, cost/batch, (accuracy*100)/batch))\n",
    "        #if(callback is not None):\n",
    "        #    callback(i, params_values)\n",
    "    #pack filters\n",
    "    params_values = [filters, bias, f_dc, out_fb]\n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: {1}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.49999938 0.49999938 0.49999938 0.49999938]\n",
      "  [0.49999938 0.49999938 0.49999938 0.49999938]\n",
      "  [0.49999938 0.49999938 0.49999938 0.49999938]\n",
      "  [0.49999938 0.49999938 0.49999938 0.49999938]\n",
      "  [0.49999938 0.49999938 0.49999938 0.49999938]]]\n",
      "Epoch:     1   -   cost: 0.65   -   Accuracy: 52.08%\n",
      "Epoch: {2}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.4924977 0.4924977 0.4924977 0.4924977]\n",
      "  [0.4924977 0.4924977 0.4924977 0.4924977]\n",
      "  [0.4924977 0.4924977 0.4924977 0.4924977]\n",
      "  [0.4924977 0.4924977 0.4924977 0.4924977]\n",
      "  [0.4924977 0.4924977 0.4924977 0.4924977]]]\n",
      "Epoch:     2   -   cost: 0.64   -   Accuracy: 52.52%\n",
      "Epoch: {3}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.4845238 0.4845238 0.4845238 0.4845238]\n",
      "  [0.4845238 0.4845238 0.4845238 0.4845238]\n",
      "  [0.4845238 0.4845238 0.4845238 0.4845238]\n",
      "  [0.4845238 0.4845238 0.4845238 0.4845238]\n",
      "  [0.4845238 0.4845238 0.4845238 0.4845238]]]\n",
      "Epoch:     3   -   cost: 0.64   -   Accuracy: 52.98%\n",
      "Epoch: {4}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.47561095 0.47561095 0.47561095 0.47561095]\n",
      "  [0.47561095 0.47561095 0.47561095 0.47561095]\n",
      "  [0.47561095 0.47561095 0.47561095 0.47561095]\n",
      "  [0.47561095 0.47561095 0.47561095 0.47561095]\n",
      "  [0.47561095 0.47561095 0.47561095 0.47561095]]]\n",
      "Epoch:     4   -   cost: 0.63   -   Accuracy: 53.49%\n",
      "Epoch: {5}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.46373188 0.46373188 0.46373188 0.46373188]\n",
      "  [0.46373188 0.46373188 0.46373188 0.46373188]\n",
      "  [0.46373188 0.46373188 0.46373188 0.46373188]\n",
      "  [0.46373188 0.46373188 0.46373188 0.46373188]\n",
      "  [0.46373188 0.46373188 0.46373188 0.46373188]]]\n",
      "Epoch:     5   -   cost: 0.61   -   Accuracy: 54.17%\n",
      "Epoch: {6}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.44321243 0.44321243 0.44321243 0.44321243]\n",
      "  [0.44321243 0.44321243 0.44321243 0.44321243]\n",
      "  [0.44321243 0.44321243 0.44321243 0.44321243]\n",
      "  [0.44321243 0.44321243 0.44321243 0.44321243]\n",
      "  [0.44321243 0.44321243 0.44321243 0.44321243]]]\n",
      "Epoch:     6   -   cost: 0.59   -   Accuracy: 55.31%\n",
      "Epoch: {7}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.37449384 0.37449384 0.37449384 0.37449384]\n",
      "  [0.37449384 0.37449384 0.37449384 0.37449384]\n",
      "  [0.37449384 0.37449384 0.37449384 0.37449384]\n",
      "  [0.37449384 0.37449384 0.37449384 0.37449384]\n",
      "  [0.37449384 0.37449384 0.37449384 0.37449384]]]\n",
      "Epoch:     7   -   cost: 0.53   -   Accuracy: 58.82%\n",
      "Epoch: {8}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.11260474 0.11260961 0.11261241 0.11261176]\n",
      "  [0.11261096 0.11261262 0.11261165 0.11260756]\n",
      "  [0.11261296 0.11261112 0.11260692 0.11260068]\n",
      "  [0.11260965 0.11260521 0.11259931 0.1125928 ]\n",
      "  [0.11260209 0.11259672 0.11259106 0.11258597]]]\n",
      "Epoch:     8   -   cost: 0.36   -   Accuracy: 69.76%\n",
      "Epoch: {9}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.2474937  0.25189312 0.25456091 0.25544031]\n",
      "  [0.25292031 0.25476449 0.25543503 0.25475108]\n",
      "  [0.25528818 0.25545194 0.25459864 0.25194104]\n",
      "  [0.25527415 0.25399112 0.25118246 0.24621491]\n",
      "  [0.25255398 0.24934463 0.2444798  0.23802202]]]\n",
      "Epoch:     9   -   cost: 0.42   -   Accuracy: 66.03%\n",
      "Epoch: {10}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.13910601 0.13246402 0.12726753 0.12579998]\n",
      "  [0.13057064 0.1268008  0.12585521 0.12874285]\n",
      "  [0.12583838 0.12615213 0.12933561 0.13514718]\n",
      "  [0.12721626 0.13094456 0.13647463 0.14280843]\n",
      "  [0.13397294 0.13906154 0.14446103 0.14919828]]]\n",
      "Epoch:    10   -   cost: 0.39   -   Accuracy: 67.95%\n",
      "Epoch: {11}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.40568659 0.41024686 0.39778633 0.36797014]\n",
      "  [0.40948121 0.39504079 0.36719291 0.33230219]\n",
      "  [0.38727484 0.36029885 0.32888261 0.30105116]\n",
      "  [0.34699095 0.32021699 0.29732941 0.28312133]\n",
      "  [0.30792166 0.29139611 0.28160258 0.27933505]]]\n",
      "Epoch:    11   -   cost: 0.46   -   Accuracy: 63.10%\n",
      "Epoch: {12}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.28402541 0.31525777 0.32654826 0.31487097]\n",
      "  [0.3211477  0.32725418 0.31440812 0.27373282]\n",
      "  [0.32572977 0.30854536 0.26817912 0.20517221]\n",
      "  [0.29287387 0.2507658  0.19333959 0.13448161]\n",
      "  [0.22011513 0.16922638 0.12177646 0.08710597]]]\n",
      "Epoch:    12   -   cost: 0.29   -   Accuracy: 75.07%\n",
      "Epoch: {13}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.30403322 0.36434959 0.38983044 0.37928792]\n",
      "  [0.37640842 0.38983112 0.37787312 0.32201406]\n",
      "  [0.39130911 0.37002613 0.31068344 0.20676211]\n",
      "  [0.35150314 0.28324842 0.18272249 0.08993243]\n",
      "  [0.23388554 0.14455625 0.07140565 0.03186815]]]\n",
      "Epoch:    13   -   cost: 0.23   -   Accuracy: 79.07%\n",
      "Epoch: {14}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[0.32516421 0.40384808 0.43222292 0.42895945]\n",
      "  [0.41922879 0.434148   0.42862638 0.3788341 ]\n",
      "  [0.43531953 0.42353819 0.36802179 0.23288307]\n",
      "  [0.40819366 0.33445622 0.19963063 0.07086757]\n",
      "  [0.26734525 0.14178952 0.04894981 0.01239159]]]\n",
      "Epoch:    14   -   cost: 0.39   -   Accuracy: 67.71%\n",
      "Epoch: {15}\n",
      "Batch: 1\n",
      "Image: 1/1\n",
      "[[[2.24903522e-01 3.76706900e-01 4.31202831e-01 4.28487946e-01]\n",
      "  [4.06569995e-01 4.35430703e-01 4.27681294e-01 3.40369344e-01]\n",
      "  [4.35520467e-01 4.23300171e-01 3.29100407e-01 1.17721428e-01]\n",
      "  [4.01381830e-01 2.80752385e-01 8.86665037e-02 7.31882574e-03]\n",
      "  [1.73469385e-01 4.18558088e-02 3.52482266e-03 1.34506974e-04]]]\n",
      "Epoch:    15   -   cost: 0.64   -   Accuracy: 52.89%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Training ######\n",
    "#train_images, train_labels, test_images, test_labels\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "params_values = train(train_images, train_labels, 15, 0.001, True) #0.05 stable LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-d1175c062e01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m###### Prediction ######\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mYt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtemp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "###### Prediction ######\n",
    "Yt = test_labels.T\n",
    "temp1 = []\n",
    "for i in range(Yt.shape[1]):\n",
    "        for j in range(Yt.shape[0]):\n",
    "            if(Yt[j][i]==1):\n",
    "                temp1.append(j)\n",
    "Yt=np.array(temp1)\n",
    "Y_test_hat, _ = full_forward_propagation(np.transpose(test_images), params_values, NN_ARCHITECTURE)#multiple?!\n",
    "\n",
    "Yht = np.array(Y_test_hat.T)\n",
    "#x_log=np.log( np.exp(Yh) / np.sum(np.exp(Yh), axis = 1) )  #(60000,10) , we need to add along columns so we get sum of 1 on every example-row\n",
    "num = np.exp(Yht)\n",
    "den = np.sum(np.exp(Yht), axis = 1)\n",
    "for i in range(Yht.shape[0]): #60000\n",
    "                #for j in range(Yh.shape[1]): #10\n",
    "                Yht[i][:] = np.log(num[i][:] / den[i])  \n",
    "\n",
    "#cost = get_cost_value(Yht, Yt)\n",
    "\n",
    "#cost_history.append(cost)\n",
    "accuracy = get_accuracy_value(Y_test_hat, test_labels.T)\n",
    "#accuracy_history.append(accuracy)\n",
    "print(\"Accuracy: {:.5f}%\".format( accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
